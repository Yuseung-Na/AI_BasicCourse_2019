{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiVariable Classification 구현_CrossEntropy ver\n",
    "#### 주의해서 볼 함수는 sigmoid,  loss_func,  predict 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종출력은 y = sigmoid(Wx+b) 이며, 손실함수는 cross-entropy 로 나타냄\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data = (예습시간, 복습시간)\n",
    "# t_data = 1 (Pass), 0 (Fail)\n",
    "\n",
    "x_data = [ [2, 4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7] ]\n",
    "t_data = [0, 0, 0, 0, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.78777337]\n",
      " [0.9559968 ]] , W.shape =  (2, 1) , b =  [0.11868164] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(2,1)  \n",
    "b = np.random.rand(1)  \n",
    "\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    \n",
    "    delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) ) \n",
    "\n",
    "# 손실함수 값 계산 함수\n",
    "# 입력변수 x, t : numpy type\n",
    "def error_val(x, t):\n",
    "    delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) ) \n",
    "\n",
    "# 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "# 입력변수 test_data : numpy type\n",
    "def predict(test_data):\n",
    "    \n",
    "    z = np.dot(test_data, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y >= 0.5:\n",
    "        result = 1  # True\n",
    "    else:\n",
    "        result = 0  # False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  40.98626644276797\n",
      "step =  0 error value =  30.542417062652888\n",
      "step =  1000 error value =  1.3788796832571937\n",
      "step =  2000 error value =  0.9654651872091095\n",
      "step =  3000 error value =  0.7853023375711337\n",
      "step =  4000 error value =  0.6774090835365838\n",
      "step =  5000 error value =  0.6023800628206787\n",
      "step =  6000 error value =  0.545587332330889\n",
      "step =  7000 error value =  0.500245388136067\n",
      "step =  8000 error value =  0.4627309075859041\n",
      "step =  9000 error value =  0.43090825044786896\n",
      "step =  10000 error value =  0.40342022418749096\n",
      "step =  11000 error value =  0.3793505660643608\n",
      "step =  12000 error value =  0.358049318380275\n",
      "step =  13000 error value =  0.3390364715241446\n",
      "step =  14000 error value =  0.3219458225703187\n",
      "step =  15000 error value =  0.3064906238867267\n",
      "step =  16000 error value =  0.2924416003833731\n",
      "step =  17000 error value =  0.2796122988403132\n",
      "step =  18000 error value =  0.26784896580687645\n",
      "step =  19000 error value =  0.25702333193370347\n",
      "step =  20000 error value =  0.24702732833499275\n",
      "step =  21000 error value =  0.23776912835521258\n",
      "step =  22000 error value =  0.22917012421531366\n",
      "step =  23000 error value =  0.22116257927618654\n",
      "step =  24000 error value =  0.21368777894456964\n",
      "step =  25000 error value =  0.20669455638033027\n",
      "step =  26000 error value =  0.20013810441566543\n",
      "step =  27000 error value =  0.19397900907481058\n",
      "step =  28000 error value =  0.18818245675769915\n",
      "step =  29000 error value =  0.18271757898433058\n",
      "step =  30000 error value =  0.17755690714314445\n",
      "step =  31000 error value =  0.17267591596102758\n",
      "step =  32000 error value =  0.1680526390835309\n",
      "step =  33000 error value =  0.16366734367565175\n",
      "step =  34000 error value =  0.15950225364087867\n",
      "step =  35000 error value =  0.15554131312622807\n",
      "step =  36000 error value =  0.15176998359199803\n",
      "step =  37000 error value =  0.14817506898890265\n",
      "step =  38000 error value =  0.1447445645840872\n",
      "step =  39000 error value =  0.14146752577360341\n",
      "step =  40000 error value =  0.1383339538570707\n",
      "step =  41000 error value =  0.1353346962641719\n",
      "step =  42000 error value =  0.13246135914104504\n",
      "step =  43000 error value =  0.12970623054388924\n",
      "step =  44000 error value =  0.12706221276729707\n",
      "step =  45000 error value =  0.12452276256367661\n",
      "step =  46000 error value =  0.1220818382007483\n",
      "step =  47000 error value =  0.11973385246181109\n",
      "step =  48000 error value =  0.11747363082503268\n",
      "step =  49000 error value =  0.11529637416830188\n",
      "step =  50000 error value =  0.11319762543907869\n",
      "step =  51000 error value =  0.11117323980613883\n",
      "step =  52000 error value =  0.10921935787672764\n",
      "step =  53000 error value =  0.10733238161841614\n",
      "step =  54000 error value =  0.10550895267251309\n",
      "step =  55000 error value =  0.10374593278694967\n",
      "step =  56000 error value =  0.1020403861311167\n",
      "step =  57000 error value =  0.10038956328501457\n",
      "step =  58000 error value =  0.09879088672107057\n",
      "step =  59000 error value =  0.09724193761891382\n",
      "step =  60000 error value =  0.09574044387276313\n",
      "step =  61000 error value =  0.0942842691675473\n",
      "step =  62000 error value =  0.09287140301457436\n",
      "step =  63000 error value =  0.09149995164992344\n",
      "step =  64000 error value =  0.09016812970976566\n",
      "step =  65000 error value =  0.08887425260656101\n",
      "step =  66000 error value =  0.08761672953826431\n",
      "step =  67000 error value =  0.0863940570701809\n",
      "step =  68000 error value =  0.08520481323564369\n",
      "step =  69000 error value =  0.08404765210719997\n",
      "step =  70000 error value =  0.08292129879527861\n",
      "step =  71000 error value =  0.08182454483557804\n",
      "step =  72000 error value =  0.08075624393050342\n",
      "step =  73000 error value =  0.07971530801333018\n",
      "step =  74000 error value =  0.07870070360699752\n",
      "step =  75000 error value =  0.07771144845218339\n",
      "step =  76000 error value =  0.07674660838171947\n",
      "step =  77000 error value =  0.07580529442063891\n",
      "step =  78000 error value =  0.07488666009314968\n",
      "step =  79000 error value =  0.07398989891946703\n",
      "step =  80000 error value =  0.07311424208719622\n",
      "step =  81000 error value =  0.07225895628315154\n",
      "step =  82000 error value =  0.07142334167294945\n",
      "step =  83000 error value =  0.07060673001674063\n",
      "step =  84000 error value =  0.0698084829105605\n",
      "step =  85000 error value =  0.06902799014360901\n",
      "step =  86000 error value =  0.06826466816265508\n",
      "step =  87000 error value =  0.06751795863552822\n",
      "step =  88000 error value =  0.06678732710636069\n",
      "step =  89000 error value =  0.06607226173576546\n",
      "step =  90000 error value =  0.06537227211981857\n",
      "step =  91000 error value =  0.06468688818213715\n",
      "step =  92000 error value =  0.06401565913383006\n",
      "step =  93000 error value =  0.06335815249654345\n",
      "step =  94000 error value =  0.06271395318420796\n",
      "step =  95000 error value =  0.0620826626393594\n",
      "step =  96000 error value =  0.061463898020333856\n",
      "step =  97000 error value =  0.06085729143590684\n",
      "step =  98000 error value =  0.0602624892240994\n",
      "step =  99000 error value =  0.05967915127231504\n",
      "step =  100000 error value =  0.059106950375955626\n",
      "\n",
      "Elapsed Time =>  0:00:36.959157\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2  # 1e-2, 1e-3 은 손실함수 값 발산\n",
    "\n",
    "# x_data, t_data 는 list 이므로 numpy로 바꾸어주어야 함\n",
    "\n",
    "input_xdata = np.array(x_data)\n",
    "input_tdata = np.array(t_data).reshape(len(t_data), 1)\n",
    "\n",
    "f = lambda x : loss_func(input_xdata, input_tdata)\n",
    "\n",
    "print(\"Initial error value = \", error_val(input_xdata, input_tdata) )\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in  range(100001):  \n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(input_xdata, input_tdata) )\n",
    "        \n",
    "        \n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15447241] 0\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([3, 17])\n",
    "\n",
    "(real_val, logical_val) = predict(test_data)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00071321] 0\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([5, 8])\n",
    "\n",
    "(real_val, logical_val) = predict(test_data)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999642] 1\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([7, 21])\n",
    "\n",
    "(real_val, logical_val) = predict(test_data)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59979436] 1\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([12, 0])\n",
    "\n",
    "(real_val, logical_val) = predict(test_data)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[2.40866577]\n",
      " [1.15137872]] , b =  [-28.49938086]\n"
     ]
    }
   ],
   "source": [
    "print('W = ', W, ', b = ', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
