{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "(191124)CNN_example3_2conv_3X3_SAME.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcEVJdRCeXO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "9da8bfe1-ad61-49e5-962f-09160e4d16d5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
        "\n",
        "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
        "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
        "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
        "\n",
        "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
        "\n",
        "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
        "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
        "\n",
        "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
        "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
        "print(\"test image shape = \", np.shape(mnist.test.images))\n",
        "print(\"test label shape = \", np.shape(mnist.test.labels))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            " 55000 10000 5000\n",
            "\n",
            "train image shape =  (55000, 784)\n",
            "train label shape =  (55000, 10)\n",
            "test image shape =  (10000, 784)\n",
            "test label shape =  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMI0w-KUeXO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper-Parameter\n",
        "learning_rate = 0.001  # 학습율\n",
        "epochs = 30            # 반복횟수\n",
        "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJX7CkOFeXPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력과 정답을 위한 플레이스홀더 정의\n",
        "X = tf.placeholder(tf.float32, [None, 784])  \n",
        "\n",
        "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28X28X1 (black/white)\n",
        "\n",
        "\n",
        "T = tf.placeholder(tf.float32, [None, 10])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aThyxBVeXPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1번째 컨볼루션 층\n",
        "W2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))  \n",
        "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
        "\n",
        "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
        "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z2 = tf.nn.relu(C2+b2)\n",
        "\n",
        "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
        "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUEChtlgeXPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2번째 컨볼루션 층, 3X3X32 개 필터\n",
        "W3 = tf.Variable(tf.random_normal([3, 3, 32, 32], stddev=0.01))  \n",
        "b3 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
        "\n",
        "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 32 \n",
        "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z3 = tf.nn.relu(C3+b3)\n",
        "\n",
        "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 32\n",
        "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB9boOK0eXPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7X7 크기를 가진 64개의 activation map을 flatten 시킴\n",
        "A3_flat = P3_flat = tf.reshape(A3, [-1, 7*7*32])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvpTuu89eXPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 출력층\n",
        "W4 = tf.Variable(tf.random_normal([7*7*32, 10], stddev=0.01))\n",
        "b4 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "# 출력층 선형회귀  값 Z4, 즉 softmax 에 들어가는 입력 값\n",
        "Z4 = logits = tf.matmul(A3_flat, W4) + b4    # 선형회귀 값 Z4\n",
        "\n",
        "y = A4 = tf.nn.softmax(Z4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEvwMjVeXPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z4, labels=T) )\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwYNZP2qeXPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
        "predicted_val = tf.equal( tf.argmax(A4, 1), tf.argmax(T, 1) )\n",
        "\n",
        "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
        "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
        "\n",
        "# index list 출력\n",
        "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
        "\n",
        "# 예측값 처리\n",
        "predicted_list = tf.argmax(A4, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woyijCk2eXPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03955f1e-1305-4ca3-f7df-2edb79d5ca89"
      },
      "source": [
        "index_label_prediction_list = []\n",
        "\n",
        "with  tf.Session()  as sess:\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    for i in range(epochs):    # 100 번 반복수행\n",
        "        \n",
        "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
        "\n",
        "        for step in range(total_batch):\n",
        "            \n",
        "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
        "      \n",
        "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
        "        \n",
        "            if step % 100 == 0:\n",
        "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
        "    \n",
        "    end_time = datetime.now() \n",
        "    \n",
        "    print(\"\\nelapsed time = \", end_time - start_time) \n",
        "    \n",
        "    # Accuracy 확인\n",
        "    test_x_data = mnist.test.images    # 10000 X 784\n",
        "    test_t_data = mnist.test.labels    # 10000 X 10\n",
        "    \n",
        "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
        "    \n",
        "    print(\"\\nAccuracy = \", accuracy_val)\n",
        "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
        "    print(\"index_label.shape = \", index_label.shape)\n",
        "    \n",
        "    index_label_list = list(index_label)\n",
        "    print(\"length of index_label_list = \", len(index_label_list))\n",
        "    print(\"false label count = \", index_label_list.count([0]))\n",
        "        \n",
        "    # numpy type 으로 디버그\n",
        "    temp_list = [] \n",
        "    \n",
        "    for index in range(len(index_label)):\n",
        "        \n",
        "        if index_label[index] == 0:\n",
        "            \n",
        "            temp_list.append(index)\n",
        "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
        "            temp_list.append(predicted_list_val[index])\n",
        "            \n",
        "            index_label_prediction_list.append(temp_list)\n",
        "            \n",
        "            temp_list = []\n",
        "            \n",
        "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs =  0 , step =  0 , loss_val =  2.9115894\n",
            "epochs =  0 , step =  100 , loss_val =  0.98685867\n",
            "epochs =  0 , step =  200 , loss_val =  0.53891706\n",
            "epochs =  0 , step =  300 , loss_val =  0.4815405\n",
            "epochs =  0 , step =  400 , loss_val =  0.2759106\n",
            "epochs =  0 , step =  500 , loss_val =  0.19478565\n",
            "epochs =  1 , step =  0 , loss_val =  0.22804813\n",
            "epochs =  1 , step =  100 , loss_val =  0.09696249\n",
            "epochs =  1 , step =  200 , loss_val =  0.06451018\n",
            "epochs =  1 , step =  300 , loss_val =  0.04389954\n",
            "epochs =  1 , step =  400 , loss_val =  0.1187175\n",
            "epochs =  1 , step =  500 , loss_val =  0.08694203\n",
            "epochs =  2 , step =  0 , loss_val =  0.089399755\n",
            "epochs =  2 , step =  100 , loss_val =  0.11906373\n",
            "epochs =  2 , step =  200 , loss_val =  0.048755113\n",
            "epochs =  2 , step =  300 , loss_val =  0.024307437\n",
            "epochs =  2 , step =  400 , loss_val =  0.10604084\n",
            "epochs =  2 , step =  500 , loss_val =  0.10037061\n",
            "epochs =  3 , step =  0 , loss_val =  0.045691766\n",
            "epochs =  3 , step =  100 , loss_val =  0.01740729\n",
            "epochs =  3 , step =  200 , loss_val =  0.12255663\n",
            "epochs =  3 , step =  300 , loss_val =  0.043614637\n",
            "epochs =  3 , step =  400 , loss_val =  0.04930193\n",
            "epochs =  3 , step =  500 , loss_val =  0.045738745\n",
            "epochs =  4 , step =  0 , loss_val =  0.047998857\n",
            "epochs =  4 , step =  100 , loss_val =  0.056465987\n",
            "epochs =  4 , step =  200 , loss_val =  0.0812173\n",
            "epochs =  4 , step =  300 , loss_val =  0.0787168\n",
            "epochs =  4 , step =  400 , loss_val =  0.09489893\n",
            "epochs =  4 , step =  500 , loss_val =  0.048657812\n",
            "epochs =  5 , step =  0 , loss_val =  0.047108084\n",
            "epochs =  5 , step =  100 , loss_val =  0.01232484\n",
            "epochs =  5 , step =  200 , loss_val =  0.10505246\n",
            "epochs =  5 , step =  300 , loss_val =  0.09303858\n",
            "epochs =  5 , step =  400 , loss_val =  0.010607201\n",
            "epochs =  5 , step =  500 , loss_val =  0.07833518\n",
            "epochs =  6 , step =  0 , loss_val =  0.014677371\n",
            "epochs =  6 , step =  100 , loss_val =  0.024145728\n",
            "epochs =  6 , step =  200 , loss_val =  0.022883466\n",
            "epochs =  6 , step =  300 , loss_val =  0.08564902\n",
            "epochs =  6 , step =  400 , loss_val =  0.019323394\n",
            "epochs =  6 , step =  500 , loss_val =  0.028627165\n",
            "epochs =  7 , step =  0 , loss_val =  0.0130815795\n",
            "epochs =  7 , step =  100 , loss_val =  0.0842727\n",
            "epochs =  7 , step =  200 , loss_val =  0.004634616\n",
            "epochs =  7 , step =  300 , loss_val =  0.02012192\n",
            "epochs =  7 , step =  400 , loss_val =  0.0248129\n",
            "epochs =  7 , step =  500 , loss_val =  0.03424121\n",
            "epochs =  8 , step =  0 , loss_val =  0.024673305\n",
            "epochs =  8 , step =  100 , loss_val =  0.011957381\n",
            "epochs =  8 , step =  200 , loss_val =  0.006914564\n",
            "epochs =  8 , step =  300 , loss_val =  0.010437724\n",
            "epochs =  8 , step =  400 , loss_val =  0.044889912\n",
            "epochs =  8 , step =  500 , loss_val =  0.005954609\n",
            "epochs =  9 , step =  0 , loss_val =  0.009692834\n",
            "epochs =  9 , step =  100 , loss_val =  0.0022459587\n",
            "epochs =  9 , step =  200 , loss_val =  0.03966126\n",
            "epochs =  9 , step =  300 , loss_val =  0.037594322\n",
            "epochs =  9 , step =  400 , loss_val =  0.020917628\n",
            "epochs =  9 , step =  500 , loss_val =  0.05749993\n",
            "epochs =  10 , step =  0 , loss_val =  0.054040365\n",
            "epochs =  10 , step =  100 , loss_val =  0.018914506\n",
            "epochs =  10 , step =  200 , loss_val =  0.0245814\n",
            "epochs =  10 , step =  300 , loss_val =  0.0012236186\n",
            "epochs =  10 , step =  400 , loss_val =  0.02256317\n",
            "epochs =  10 , step =  500 , loss_val =  0.010030005\n",
            "epochs =  11 , step =  0 , loss_val =  0.008838992\n",
            "epochs =  11 , step =  100 , loss_val =  0.029673135\n",
            "epochs =  11 , step =  200 , loss_val =  0.012346553\n",
            "epochs =  11 , step =  300 , loss_val =  0.036306195\n",
            "epochs =  11 , step =  400 , loss_val =  0.009023446\n",
            "epochs =  11 , step =  500 , loss_val =  0.0069699413\n",
            "epochs =  12 , step =  0 , loss_val =  0.014703189\n",
            "epochs =  12 , step =  100 , loss_val =  0.009669124\n",
            "epochs =  12 , step =  200 , loss_val =  0.0178414\n",
            "epochs =  12 , step =  300 , loss_val =  0.008958941\n",
            "epochs =  12 , step =  400 , loss_val =  0.013731217\n",
            "epochs =  12 , step =  500 , loss_val =  0.033791445\n",
            "epochs =  13 , step =  0 , loss_val =  0.03458049\n",
            "epochs =  13 , step =  100 , loss_val =  0.0035389892\n",
            "epochs =  13 , step =  200 , loss_val =  0.0028250401\n",
            "epochs =  13 , step =  300 , loss_val =  0.023229726\n",
            "epochs =  13 , step =  400 , loss_val =  0.064352125\n",
            "epochs =  13 , step =  500 , loss_val =  0.030045237\n",
            "epochs =  14 , step =  0 , loss_val =  0.004179682\n",
            "epochs =  14 , step =  100 , loss_val =  0.0042492845\n",
            "epochs =  14 , step =  200 , loss_val =  0.0104032\n",
            "epochs =  14 , step =  300 , loss_val =  0.040840406\n",
            "epochs =  14 , step =  400 , loss_val =  0.0011748805\n",
            "epochs =  14 , step =  500 , loss_val =  0.032170363\n",
            "epochs =  15 , step =  0 , loss_val =  0.0023892163\n",
            "epochs =  15 , step =  100 , loss_val =  0.007701883\n",
            "epochs =  15 , step =  200 , loss_val =  0.013549246\n",
            "epochs =  15 , step =  300 , loss_val =  0.042918295\n",
            "epochs =  15 , step =  400 , loss_val =  0.010037466\n",
            "epochs =  15 , step =  500 , loss_val =  0.11345658\n",
            "epochs =  16 , step =  0 , loss_val =  0.035318583\n",
            "epochs =  16 , step =  100 , loss_val =  0.031685807\n",
            "epochs =  16 , step =  200 , loss_val =  0.012710511\n",
            "epochs =  16 , step =  300 , loss_val =  0.00384863\n",
            "epochs =  16 , step =  400 , loss_val =  0.025118563\n",
            "epochs =  16 , step =  500 , loss_val =  0.006926716\n",
            "epochs =  17 , step =  0 , loss_val =  0.010023644\n",
            "epochs =  17 , step =  100 , loss_val =  0.007951405\n",
            "epochs =  17 , step =  200 , loss_val =  0.003982468\n",
            "epochs =  17 , step =  300 , loss_val =  0.004701259\n",
            "epochs =  17 , step =  400 , loss_val =  0.015680365\n",
            "epochs =  17 , step =  500 , loss_val =  0.018434865\n",
            "epochs =  18 , step =  0 , loss_val =  0.0129312575\n",
            "epochs =  18 , step =  100 , loss_val =  0.0051143593\n",
            "epochs =  18 , step =  200 , loss_val =  0.107612774\n",
            "epochs =  18 , step =  300 , loss_val =  0.0026178055\n",
            "epochs =  18 , step =  400 , loss_val =  0.018524231\n",
            "epochs =  18 , step =  500 , loss_val =  0.0135622\n",
            "epochs =  19 , step =  0 , loss_val =  0.00838159\n",
            "epochs =  19 , step =  100 , loss_val =  0.010473603\n",
            "epochs =  19 , step =  200 , loss_val =  0.01621605\n",
            "epochs =  19 , step =  300 , loss_val =  0.0029587895\n",
            "epochs =  19 , step =  400 , loss_val =  0.0041798954\n",
            "epochs =  19 , step =  500 , loss_val =  0.002067555\n",
            "epochs =  20 , step =  0 , loss_val =  0.006234118\n",
            "epochs =  20 , step =  100 , loss_val =  0.0019904433\n",
            "epochs =  20 , step =  200 , loss_val =  0.0319653\n",
            "epochs =  20 , step =  300 , loss_val =  0.0016815476\n",
            "epochs =  20 , step =  400 , loss_val =  0.0029342931\n",
            "epochs =  20 , step =  500 , loss_val =  0.0015857123\n",
            "epochs =  21 , step =  0 , loss_val =  0.0030568945\n",
            "epochs =  21 , step =  100 , loss_val =  0.004354204\n",
            "epochs =  21 , step =  200 , loss_val =  0.0007547602\n",
            "epochs =  21 , step =  300 , loss_val =  0.0043338314\n",
            "epochs =  21 , step =  400 , loss_val =  0.0030791855\n",
            "epochs =  21 , step =  500 , loss_val =  0.005069332\n",
            "epochs =  22 , step =  0 , loss_val =  0.0076123243\n",
            "epochs =  22 , step =  100 , loss_val =  0.00817194\n",
            "epochs =  22 , step =  200 , loss_val =  0.012415609\n",
            "epochs =  22 , step =  300 , loss_val =  0.0018183726\n",
            "epochs =  22 , step =  400 , loss_val =  0.006874302\n",
            "epochs =  22 , step =  500 , loss_val =  0.04111723\n",
            "epochs =  23 , step =  0 , loss_val =  0.014263917\n",
            "epochs =  23 , step =  100 , loss_val =  0.0011820483\n",
            "epochs =  23 , step =  200 , loss_val =  0.010241228\n",
            "epochs =  23 , step =  300 , loss_val =  0.0014650306\n",
            "epochs =  23 , step =  400 , loss_val =  0.001791136\n",
            "epochs =  23 , step =  500 , loss_val =  0.009440878\n",
            "epochs =  24 , step =  0 , loss_val =  0.020845382\n",
            "epochs =  24 , step =  100 , loss_val =  0.0005428148\n",
            "epochs =  24 , step =  200 , loss_val =  0.021273572\n",
            "epochs =  24 , step =  300 , loss_val =  0.00015102525\n",
            "epochs =  24 , step =  400 , loss_val =  0.0030389207\n",
            "epochs =  24 , step =  500 , loss_val =  0.004843214\n",
            "epochs =  25 , step =  0 , loss_val =  0.0010964927\n",
            "epochs =  25 , step =  100 , loss_val =  0.003719964\n",
            "epochs =  25 , step =  200 , loss_val =  0.0017509058\n",
            "epochs =  25 , step =  300 , loss_val =  0.0058934796\n",
            "epochs =  25 , step =  400 , loss_val =  0.029532634\n",
            "epochs =  25 , step =  500 , loss_val =  0.0006769882\n",
            "epochs =  26 , step =  0 , loss_val =  0.00073227065\n",
            "epochs =  26 , step =  100 , loss_val =  0.007990595\n",
            "epochs =  26 , step =  200 , loss_val =  0.0005128\n",
            "epochs =  26 , step =  300 , loss_val =  0.001042695\n",
            "epochs =  26 , step =  400 , loss_val =  0.015841175\n",
            "epochs =  26 , step =  500 , loss_val =  0.0044156234\n",
            "epochs =  27 , step =  0 , loss_val =  0.0019853932\n",
            "epochs =  27 , step =  100 , loss_val =  0.0021611433\n",
            "epochs =  27 , step =  200 , loss_val =  0.01794957\n",
            "epochs =  27 , step =  300 , loss_val =  0.0011833617\n",
            "epochs =  27 , step =  400 , loss_val =  0.031047642\n",
            "epochs =  27 , step =  500 , loss_val =  0.0010741196\n",
            "epochs =  28 , step =  0 , loss_val =  0.016642265\n",
            "epochs =  28 , step =  100 , loss_val =  0.011324346\n",
            "epochs =  28 , step =  200 , loss_val =  0.0014431454\n",
            "epochs =  28 , step =  300 , loss_val =  0.0053182435\n",
            "epochs =  28 , step =  400 , loss_val =  0.003338737\n",
            "epochs =  28 , step =  500 , loss_val =  0.003330478\n",
            "epochs =  29 , step =  0 , loss_val =  0.0004936686\n",
            "epochs =  29 , step =  100 , loss_val =  0.0003684666\n",
            "epochs =  29 , step =  200 , loss_val =  0.0004172989\n",
            "epochs =  29 , step =  300 , loss_val =  0.0019358587\n",
            "epochs =  29 , step =  400 , loss_val =  0.010152873\n",
            "epochs =  29 , step =  500 , loss_val =  0.0005584488\n",
            "\n",
            "elapsed time =  0:01:26.573930\n",
            "\n",
            "Accuracy =  0.9876\n",
            "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
            "index_label.shape =  (10000,)\n",
            "length of index_label_list =  10000\n",
            "false label count =  124\n",
            "\n",
            "length of index_label_false_list 124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysJo9tWEeXPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "97a02a4b-954a-49dd-e9b2-3f3b64d39840"
      },
      "source": [
        "# index_label_prediction_list\n",
        "print(index_label_prediction_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[115, 4, 9], [211, 5, 3], [247, 4, 6], [259, 6, 0], [321, 2, 7], [340, 5, 3], [445, 6, 0], [449, 3, 5], [582, 8, 2], [583, 2, 7], [619, 1, 8], [646, 2, 1], [659, 2, 1], [813, 9, 8], [895, 0, 8], [947, 8, 9], [1014, 6, 5], [1039, 7, 2], [1112, 4, 6], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1247, 9, 5], [1319, 8, 0], [1393, 5, 3], [1520, 7, 2], [1527, 1, 5], [1641, 5, 6], [1709, 9, 5], [1790, 2, 7], [1901, 9, 4], [1903, 7, 2], [1982, 6, 8], [2035, 5, 3], [2053, 4, 9], [2070, 7, 9], [2098, 2, 0], [2118, 6, 0], [2129, 9, 8], [2130, 4, 9], [2135, 6, 1], [2185, 0, 8], [2195, 7, 2], [2293, 9, 2], [2406, 9, 4], [2454, 6, 5], [2462, 2, 0], [2488, 2, 4], [2578, 7, 2], [2597, 5, 3], [2654, 6, 1], [2720, 9, 4], [2770, 3, 7], [2836, 4, 2], [2896, 8, 0], [2930, 5, 1], [2939, 9, 5], [2953, 3, 5], [3030, 6, 0], [3060, 9, 7], [3073, 1, 2], [3336, 5, 7], [3441, 7, 2], [3457, 1, 6], [3520, 6, 4], [3534, 4, 8], [3558, 5, 0], [3597, 9, 3], [3727, 8, 9], [3742, 3, 9], [3751, 7, 2], [3762, 6, 8], [3806, 5, 8], [3808, 7, 8], [4007, 7, 9], [4027, 7, 4], [4199, 7, 9], [4201, 1, 7], [4238, 7, 3], [4248, 2, 8], [4269, 4, 6], [4350, 2, 8], [4497, 8, 7], [4507, 1, 2], [4536, 6, 5], [4571, 6, 8], [4740, 3, 5], [4838, 6, 8], [4956, 8, 4], [5068, 4, 7], [5201, 4, 9], [5246, 7, 2], [5331, 1, 6], [5457, 1, 4], [5749, 8, 2], [5937, 5, 3], [5955, 3, 8], [5973, 3, 9], [5997, 5, 9], [6555, 8, 9], [6558, 6, 5], [6560, 9, 5], [6571, 9, 7], [6597, 0, 7], [6651, 0, 8], [6783, 1, 6], [7800, 3, 2], [7821, 3, 2], [8316, 7, 2], [8527, 4, 9], [9009, 7, 2], [9015, 7, 2], [9540, 1, 8], [9634, 0, 2], [9642, 9, 7], [9679, 6, 2], [9692, 9, 7], [9698, 6, 2], [9729, 5, 6], [9768, 2, 0], [9770, 5, 0], [9792, 4, 9], [9850, 0, 6], [9904, 2, 8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6utH6zJeeSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "56122cfd-081b-4c0d-b67f-b25052725966"
      },
      "source": [
        "from google.colab import drive   # colab 사용시 mount 하기 위한 용도. local 에서는 불필요\n",
        "drive.mount('/content/gdrive/')  # colab 사용시 mount 하기 위한 용도. local 에서는 불필요"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsqMQL5JeXPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "8905a817-e01e-4668-ad4d-b83256829293"
      },
      "source": [
        "# check false data\n",
        "import os\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "save_count = 0\n",
        "\n",
        "# 현재 디렉토리 저장\n",
        "curr_dir = os.getcwd()\n",
        "\n",
        "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
        "now = datetime.now()\n",
        "algorithm_name = 'CNN_example3_'\n",
        "save_dir_name = algorithm_name + str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
        "\n",
        "colab_default_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "\n",
        "os.chdir(colab_default_dir)\n",
        "os.mkdir(save_dir_name)\n",
        "\n",
        "# change dir\n",
        "os.chdir(save_dir_name)\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for list_data in index_label_prediction_list:\n",
        "    \n",
        "    index_int = list_data[0]\n",
        "    label_int = list_data[1]\n",
        "    prediction_int = list_data[2]\n",
        "        \n",
        "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
        "    img = test_x_data[index_int].reshape(28,28)  \n",
        "    plt.imshow(img, cmap='gray')\n",
        "    \n",
        "    # 정답 문자열\n",
        "    label_str = str(label_int)\n",
        "    \n",
        "    # 예측값 문자열\n",
        "    prediction_str = str(prediction_int)\n",
        "    \n",
        "    # 정답과 오답을 나타내는 문자열\n",
        "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
        "    \n",
        "    # 저장 파일 이름 생성, str(index_int).png\n",
        "    save_image_name = str(index_int) + '.png'\n",
        "    \n",
        "    plt.title(label_prediction_str)\n",
        "    plt.savefig(save_image_name)\n",
        "    \n",
        "    save_count += 1\n",
        "    \n",
        "    if save_count % 10 == 0:\n",
        "        \n",
        "        print(save_count, 'image is saved now')\n",
        "\n",
        "    \n",
        "end_time = datetime.now()\n",
        "\n",
        "print('Elapsed save time => ', end_time - start_time)\n",
        "print('Total ', save_count, \" data is saved\")\n",
        "\n",
        "# 원래의 dir 로 복귀\n",
        "os.chdir(curr_dir)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 image is saved now\n",
            "20 image is saved now\n",
            "30 image is saved now\n",
            "40 image is saved now\n",
            "50 image is saved now\n",
            "60 image is saved now\n",
            "70 image is saved now\n",
            "80 image is saved now\n",
            "90 image is saved now\n",
            "100 image is saved now\n",
            "110 image is saved now\n",
            "120 image is saved now\n",
            "Elapsed save time =>  0:01:06.899797\n",
            "Total  124  data is saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wGta3JlGQhevwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6QAtG28eXPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}