{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "Bt2ciGRak9-I",
    "outputId": "2eb0ea69-62ec-45f2-b327-e0ed8262b443"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
    "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
    "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
    "\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
    "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1Doo13ik9-O"
   },
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 0.001  # 학습율\n",
    "epochs = 30            # 반복횟수\n",
    "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbHu2Xnek9-S"
   },
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "\n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28 X 28 X 1 (black/white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-YcxLO1k9-V"
   },
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층\n",
    "# 5X5 크기를 가지는 32개의 필터를 적용\n",
    "\n",
    "F2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  \n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
    "C2 = tf.nn.conv2d(A1, F2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWx5urPxk9-Y"
   },
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층\n",
    "F3 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev=0.01))  \n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[64]))   \n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 64 \n",
    "C3 = tf.nn.conv2d(A2, F3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 64\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNxBw9Fbk9-b"
   },
   "outputs": [],
   "source": [
    "# 3번째 컨볼루션 층\n",
    "F4 = tf.Variable(tf.random_normal([5, 5, 64, 128], stddev=0.01))  \n",
    "b4 = tf.Variable(tf.constant(0.1, shape=[128]))   \n",
    "\n",
    "# 3번째 컨볼루션 연산을 통해 7 X 7 X 64 => 7 X 7 X 128\n",
    "C4 = tf.nn.conv2d(A3, F4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "A4 = Z4 = tf.nn.relu(C4+b4)\n",
    "\n",
    "# pooling 없음 \n",
    "#A4 = P4 = tf.nn.max_pool(Z4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HoKyURwwk9-d"
   },
   "outputs": [],
   "source": [
    "# 5X5 크기를 가진 128개의 activation map을 flatten 시킴\n",
    "A4_flat = P4_flat = tf.reshape(A4, [-1, 128*7*7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RlJVYIgwk9-f"
   },
   "outputs": [],
   "source": [
    "# 256 개의 노드 완전연결\n",
    "W5 = tf.Variable(tf.random_normal([128*7*7, 256], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "Z5 = tf.matmul(A4_flat, W5) + b5\n",
    "\n",
    "A5 = tf.nn.relu(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vRk70vhk9-g"
   },
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W6 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "b6 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀  값 Z6, 즉 softmax 에 들어가는 입력 값\n",
    "Z6 = logits = tf.matmul(A5, W6) + b6    # 선형회귀 값 Z6\n",
    "\n",
    "y = A6 = tf.nn.softmax(Z6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prsLY0U6k9-j"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z6, labels=T) )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stkXP6Evk9-l"
   },
   "outputs": [],
   "source": [
    "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal( tf.argmax(A6, 1), tf.argmax(T, 1) )\n",
    "\n",
    "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "# 예측값 처리\n",
    "predicted_list = tf.argmax(A6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "s9t7mdaWk9-m",
    "outputId": "d93d9f98-7992-44e0-c4de-2ef84ec8964a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.631269\n",
      "epochs =  0 , step =  100 , loss_val =  1.2904603\n",
      "epochs =  0 , step =  200 , loss_val =  0.23803616\n",
      "epochs =  0 , step =  300 , loss_val =  0.058351517\n",
      "epochs =  0 , step =  400 , loss_val =  0.06977389\n",
      "epochs =  0 , step =  500 , loss_val =  0.10391089\n",
      "epochs =  1 , step =  0 , loss_val =  0.05201403\n",
      "epochs =  1 , step =  100 , loss_val =  0.07577262\n",
      "epochs =  1 , step =  200 , loss_val =  0.14123635\n",
      "epochs =  1 , step =  300 , loss_val =  0.09755898\n",
      "epochs =  1 , step =  400 , loss_val =  0.011494734\n",
      "epochs =  1 , step =  500 , loss_val =  0.1353237\n",
      "epochs =  2 , step =  0 , loss_val =  0.027268639\n",
      "epochs =  2 , step =  100 , loss_val =  0.03328884\n",
      "epochs =  2 , step =  200 , loss_val =  0.0047378954\n",
      "epochs =  2 , step =  300 , loss_val =  0.0074192714\n",
      "epochs =  2 , step =  400 , loss_val =  0.009130696\n",
      "epochs =  2 , step =  500 , loss_val =  0.033855036\n",
      "epochs =  3 , step =  0 , loss_val =  0.034037776\n",
      "epochs =  3 , step =  100 , loss_val =  0.05238978\n",
      "epochs =  3 , step =  200 , loss_val =  0.023777416\n",
      "epochs =  3 , step =  300 , loss_val =  0.025440795\n",
      "epochs =  3 , step =  400 , loss_val =  0.019971458\n",
      "epochs =  3 , step =  500 , loss_val =  0.0033083512\n",
      "epochs =  4 , step =  0 , loss_val =  0.0127855465\n",
      "epochs =  4 , step =  100 , loss_val =  0.0168629\n",
      "epochs =  4 , step =  200 , loss_val =  0.023422617\n",
      "epochs =  4 , step =  300 , loss_val =  0.0023946606\n",
      "epochs =  4 , step =  400 , loss_val =  0.071981385\n",
      "epochs =  4 , step =  500 , loss_val =  0.0015035653\n",
      "epochs =  5 , step =  0 , loss_val =  0.011087503\n",
      "epochs =  5 , step =  100 , loss_val =  0.002002679\n",
      "epochs =  5 , step =  200 , loss_val =  0.05756055\n",
      "epochs =  5 , step =  300 , loss_val =  0.00533942\n",
      "epochs =  5 , step =  400 , loss_val =  0.013463409\n",
      "epochs =  5 , step =  500 , loss_val =  0.032396346\n",
      "epochs =  6 , step =  0 , loss_val =  0.0070029628\n",
      "epochs =  6 , step =  100 , loss_val =  0.00584193\n",
      "epochs =  6 , step =  200 , loss_val =  0.0025023262\n",
      "epochs =  6 , step =  300 , loss_val =  0.048784174\n",
      "epochs =  6 , step =  400 , loss_val =  0.010331179\n",
      "epochs =  6 , step =  500 , loss_val =  0.032050833\n",
      "epochs =  7 , step =  0 , loss_val =  0.0007023305\n",
      "epochs =  7 , step =  100 , loss_val =  0.03717151\n",
      "epochs =  7 , step =  200 , loss_val =  0.0005412513\n",
      "epochs =  7 , step =  300 , loss_val =  0.0010426497\n",
      "epochs =  7 , step =  400 , loss_val =  0.0063061113\n",
      "epochs =  7 , step =  500 , loss_val =  0.04155101\n",
      "epochs =  8 , step =  0 , loss_val =  0.015464625\n",
      "epochs =  8 , step =  100 , loss_val =  0.0045951535\n",
      "epochs =  8 , step =  200 , loss_val =  0.0007066189\n",
      "epochs =  8 , step =  300 , loss_val =  0.04986652\n",
      "epochs =  8 , step =  400 , loss_val =  0.01764326\n",
      "epochs =  8 , step =  500 , loss_val =  0.0016659092\n",
      "epochs =  9 , step =  0 , loss_val =  0.00010701714\n",
      "epochs =  9 , step =  100 , loss_val =  0.005070575\n",
      "epochs =  9 , step =  200 , loss_val =  0.0034125056\n",
      "epochs =  9 , step =  300 , loss_val =  0.000865849\n",
      "epochs =  9 , step =  400 , loss_val =  0.0007097184\n",
      "epochs =  9 , step =  500 , loss_val =  0.005936749\n",
      "epochs =  10 , step =  0 , loss_val =  0.0011658779\n",
      "epochs =  10 , step =  100 , loss_val =  0.00031697672\n",
      "epochs =  10 , step =  200 , loss_val =  0.0014169317\n",
      "epochs =  10 , step =  300 , loss_val =  0.0063137854\n",
      "epochs =  10 , step =  400 , loss_val =  0.012529142\n",
      "epochs =  10 , step =  500 , loss_val =  0.0032781595\n",
      "epochs =  11 , step =  0 , loss_val =  0.021694424\n",
      "epochs =  11 , step =  100 , loss_val =  0.0008080246\n",
      "epochs =  11 , step =  200 , loss_val =  0.00014327327\n",
      "epochs =  11 , step =  300 , loss_val =  0.0013442965\n",
      "epochs =  11 , step =  400 , loss_val =  0.00016391747\n",
      "epochs =  11 , step =  500 , loss_val =  0.0004253668\n",
      "epochs =  12 , step =  0 , loss_val =  0.00021164093\n",
      "epochs =  12 , step =  100 , loss_val =  6.731078e-05\n",
      "epochs =  12 , step =  200 , loss_val =  0.0035938963\n",
      "epochs =  12 , step =  300 , loss_val =  0.02049334\n",
      "epochs =  12 , step =  400 , loss_val =  0.00028466227\n",
      "epochs =  12 , step =  500 , loss_val =  0.05313013\n",
      "epochs =  13 , step =  0 , loss_val =  6.617778e-05\n",
      "epochs =  13 , step =  100 , loss_val =  0.00029824\n",
      "epochs =  13 , step =  200 , loss_val =  0.0016991713\n",
      "epochs =  13 , step =  300 , loss_val =  0.013434929\n",
      "epochs =  13 , step =  400 , loss_val =  0.0013963244\n",
      "epochs =  13 , step =  500 , loss_val =  0.0030099088\n",
      "epochs =  14 , step =  0 , loss_val =  0.0001256615\n",
      "epochs =  14 , step =  100 , loss_val =  0.0003999663\n",
      "epochs =  14 , step =  200 , loss_val =  0.0064437203\n",
      "epochs =  14 , step =  300 , loss_val =  0.0029349457\n",
      "epochs =  14 , step =  400 , loss_val =  0.0013807096\n",
      "epochs =  14 , step =  500 , loss_val =  8.001638e-06\n",
      "epochs =  15 , step =  0 , loss_val =  0.00014914568\n",
      "epochs =  15 , step =  100 , loss_val =  0.0020702074\n",
      "epochs =  15 , step =  200 , loss_val =  2.181659e-05\n",
      "epochs =  15 , step =  300 , loss_val =  0.00058906176\n",
      "epochs =  15 , step =  400 , loss_val =  0.0022165193\n",
      "epochs =  15 , step =  500 , loss_val =  0.0016313284\n",
      "epochs =  16 , step =  0 , loss_val =  0.015907537\n",
      "epochs =  16 , step =  100 , loss_val =  8.7544024e-05\n",
      "epochs =  16 , step =  200 , loss_val =  0.00020924595\n",
      "epochs =  16 , step =  300 , loss_val =  0.0007404948\n",
      "epochs =  16 , step =  400 , loss_val =  3.376369e-05\n",
      "epochs =  16 , step =  500 , loss_val =  0.00013515106\n",
      "epochs =  17 , step =  0 , loss_val =  0.0014181242\n",
      "epochs =  17 , step =  100 , loss_val =  1.9755807e-05\n",
      "epochs =  17 , step =  200 , loss_val =  0.0036649138\n",
      "epochs =  17 , step =  300 , loss_val =  1.3571088e-05\n",
      "epochs =  17 , step =  400 , loss_val =  6.575651e-05\n",
      "epochs =  17 , step =  500 , loss_val =  0.008563799\n",
      "epochs =  18 , step =  0 , loss_val =  0.00052939437\n",
      "epochs =  18 , step =  100 , loss_val =  1.5338459e-05\n",
      "epochs =  18 , step =  200 , loss_val =  0.00010695029\n",
      "epochs =  18 , step =  300 , loss_val =  0.035129696\n",
      "epochs =  18 , step =  400 , loss_val =  0.00020239921\n",
      "epochs =  18 , step =  500 , loss_val =  0.004640928\n",
      "epochs =  19 , step =  0 , loss_val =  8.656036e-06\n",
      "epochs =  19 , step =  100 , loss_val =  0.0023007847\n",
      "epochs =  19 , step =  200 , loss_val =  0.011689202\n",
      "epochs =  19 , step =  300 , loss_val =  0.0039131157\n",
      "epochs =  19 , step =  400 , loss_val =  0.0011749753\n",
      "epochs =  19 , step =  500 , loss_val =  0.00024998636\n",
      "epochs =  20 , step =  0 , loss_val =  0.00051131356\n",
      "epochs =  20 , step =  100 , loss_val =  5.650004e-06\n",
      "epochs =  20 , step =  200 , loss_val =  0.0015622585\n",
      "epochs =  20 , step =  300 , loss_val =  1.0479997e-05\n",
      "epochs =  20 , step =  400 , loss_val =  0.0044659385\n",
      "epochs =  20 , step =  500 , loss_val =  0.001687545\n",
      "epochs =  21 , step =  0 , loss_val =  0.072706506\n",
      "epochs =  21 , step =  100 , loss_val =  6.714153e-06\n",
      "epochs =  21 , step =  200 , loss_val =  0.000108126886\n",
      "epochs =  21 , step =  300 , loss_val =  0.001052227\n",
      "epochs =  21 , step =  400 , loss_val =  0.005259099\n",
      "epochs =  21 , step =  500 , loss_val =  0.00024279898\n",
      "epochs =  22 , step =  0 , loss_val =  3.2653104e-05\n",
      "epochs =  22 , step =  100 , loss_val =  9.275024e-06\n",
      "epochs =  22 , step =  200 , loss_val =  0.0005487137\n",
      "epochs =  22 , step =  300 , loss_val =  1.0609601e-07\n",
      "epochs =  22 , step =  400 , loss_val =  5.387593e-05\n",
      "epochs =  22 , step =  500 , loss_val =  0.0003198243\n",
      "epochs =  23 , step =  0 , loss_val =  2.220975e-05\n",
      "epochs =  23 , step =  100 , loss_val =  0.026152456\n",
      "epochs =  23 , step =  200 , loss_val =  0.00078563637\n",
      "epochs =  23 , step =  300 , loss_val =  3.7942053e-05\n",
      "epochs =  23 , step =  400 , loss_val =  3.5463436e-06\n",
      "epochs =  23 , step =  500 , loss_val =  0.00031493182\n",
      "epochs =  24 , step =  0 , loss_val =  4.5885314e-05\n",
      "epochs =  24 , step =  100 , loss_val =  5.1974683e-07\n",
      "epochs =  24 , step =  200 , loss_val =  0.0004096674\n",
      "epochs =  24 , step =  300 , loss_val =  0.001525313\n",
      "epochs =  24 , step =  400 , loss_val =  3.363536e-05\n",
      "epochs =  24 , step =  500 , loss_val =  0.002792125\n",
      "epochs =  25 , step =  0 , loss_val =  0.00041922845\n",
      "epochs =  25 , step =  100 , loss_val =  2.792598e-05\n",
      "epochs =  25 , step =  200 , loss_val =  8.052494e-05\n",
      "epochs =  25 , step =  300 , loss_val =  1.6124914e-05\n",
      "epochs =  25 , step =  400 , loss_val =  2.6259193e-06\n",
      "epochs =  25 , step =  500 , loss_val =  0.00717371\n",
      "epochs =  26 , step =  0 , loss_val =  0.010615752\n",
      "epochs =  26 , step =  100 , loss_val =  0.00012362144\n",
      "epochs =  26 , step =  200 , loss_val =  0.000159556\n",
      "epochs =  26 , step =  300 , loss_val =  0.00044440807\n",
      "epochs =  26 , step =  400 , loss_val =  3.945813e-07\n",
      "epochs =  26 , step =  500 , loss_val =  4.977636e-05\n",
      "epochs =  27 , step =  0 , loss_val =  0.0001208442\n",
      "epochs =  27 , step =  100 , loss_val =  1.4718767e-05\n",
      "epochs =  27 , step =  200 , loss_val =  0.00021479363\n",
      "epochs =  27 , step =  300 , loss_val =  0.0018928549\n",
      "epochs =  27 , step =  400 , loss_val =  0.02837509\n",
      "epochs =  27 , step =  500 , loss_val =  0.0017146831\n",
      "epochs =  28 , step =  0 , loss_val =  4.2841053e-05\n",
      "epochs =  28 , step =  100 , loss_val =  8.5233916e-07\n",
      "epochs =  28 , step =  200 , loss_val =  0.0008186297\n",
      "epochs =  28 , step =  300 , loss_val =  0.00036208882\n",
      "epochs =  28 , step =  400 , loss_val =  1.1951644e-05\n",
      "epochs =  28 , step =  500 , loss_val =  1.4930646e-05\n",
      "epochs =  29 , step =  0 , loss_val =  8.940671e-06\n",
      "epochs =  29 , step =  100 , loss_val =  4.4590244e-05\n",
      "epochs =  29 , step =  200 , loss_val =  7.433616e-06\n",
      "epochs =  29 , step =  300 , loss_val =  6.7864574e-05\n",
      "epochs =  29 , step =  400 , loss_val =  0.00061815337\n",
      "epochs =  29 , step =  500 , loss_val =  5.0105267e-05\n",
      "\n",
      "elapsed time =  0:01:27.001261\n",
      "\n",
      "Accuracy =  0.9926\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  74\n",
      "\n",
      "length of index_label_false_list 74\n"
     ]
    }
   ],
   "source": [
    "index_label_prediction_list = []\n",
    "\n",
    "with  tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):    # 30 번 반복수행\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
    "\n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "      \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now() \n",
    "    \n",
    "    print(\"\\nelapsed time = \", end_time - start_time) \n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images    # 10000 X 784\n",
    "    test_t_data = mnist.test.labels    # 10000 X 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "        \n",
    "    # numpy type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_prediction_list.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "48THz29lk9-o",
    "outputId": "9ad66c3a-9075-4f09-cda7-74a15aa4b162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[340, 5, 3], [582, 8, 2], [659, 2, 1], [674, 5, 3], [947, 8, 9], [1014, 6, 5], [1033, 8, 1], [1112, 4, 6], [1182, 6, 5], [1232, 9, 4], [1247, 9, 5], [1260, 7, 1], [1527, 1, 5], [1790, 2, 7], [1901, 9, 4], [1982, 6, 5], [2035, 5, 3], [2070, 7, 1], [2118, 6, 1], [2129, 9, 8], [2130, 4, 9], [2135, 6, 1], [2293, 9, 4], [2414, 9, 4], [2462, 2, 8], [2597, 5, 3], [2654, 6, 1], [2720, 9, 4], [2939, 9, 5], [2953, 3, 5], [3060, 9, 3], [3369, 9, 1], [3422, 6, 0], [3475, 3, 7], [3520, 6, 4], [3534, 4, 8], [3558, 5, 0], [3559, 8, 5], [3727, 8, 3], [3730, 7, 9], [3808, 7, 2], [3831, 9, 8], [4065, 0, 2], [4176, 2, 7], [4497, 8, 7], [4571, 6, 8], [4620, 6, 2], [4699, 6, 1], [4740, 3, 5], [4761, 9, 4], [4814, 6, 0], [4823, 9, 4], [5165, 0, 6], [5654, 7, 2], [5937, 5, 3], [5955, 3, 8], [6532, 0, 5], [6576, 7, 1], [6597, 0, 7], [6651, 0, 8], [7928, 1, 0], [8061, 4, 9], [8094, 2, 8], [8246, 3, 5], [8316, 7, 2], [8326, 6, 2], [8408, 8, 5], [8527, 4, 9], [9634, 0, 1], [9664, 2, 7], [9669, 4, 5], [9729, 5, 6], [9792, 4, 9], [9850, 0, 6]]\n"
     ]
    }
   ],
   "source": [
    "# index_label_prediction_list\n",
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "0S9lQWHpamEJ",
    "outputId": "81ab4f08-0217-49a3-ff2d-b24b7d43ec68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive   # colab 사용시 mount 하기 위한 용도. local 에서는 불필요\n",
    "drive.mount('/content/gdrive/')  # colab 사용시 mount 하기 위한 용도. local 에서는 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "ZjMMkZkdk9-p",
    "outputId": "a8cdc3a9-93f0-4d75-a5b9-892adf200aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "Elapsed save time =>  0:00:17.908919\n",
      "Total  74  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu1kiHHazRDjsZolw2M0S8X+ngLzvGtD2yQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "\n",
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'CNN_example10_'\n",
    "save_dir_name = algorithm_name + str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "colab_default_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
    "\n",
    "os.chdir(colab_default_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_prediction_list:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GVrLMouk9-r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "(191124)CNN_example10_3conv_5X5_5X5_5X5_NoPooling_2FC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
