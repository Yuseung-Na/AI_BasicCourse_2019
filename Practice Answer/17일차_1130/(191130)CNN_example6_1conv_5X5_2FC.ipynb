{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "luwILl4ynxk1",
    "outputId": "eeb65714-0fb8-4fea-a4a7-fa968904332d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
    "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
    "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
    "\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
    "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIab0GlXnxlV"
   },
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 0.001  # 학습율\n",
    "epochs = 30            # 반복횟수\n",
    "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTkto0xZnxl3"
   },
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28X28X1 (black/white)\n",
    "\n",
    "\n",
    "T = tf.placeholder(tf.float32, [None, 10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYW3sDHanxmE"
   },
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 5X5X32 필터\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  \n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjAFuTjMnxmL"
   },
   "outputs": [],
   "source": [
    "# 완전연결층, 14X14X32 개 입력 출력은 256개 의 은닉층 개념\n",
    "A2_flat = P2_flat = tf.reshape(A2, [-1, 14*14*32])\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([14*14*32, 256], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "Z3 = tf.matmul(A2_flat, W3) + b3\n",
    "\n",
    "A3 = tf.nn.relu(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCaBjOsbnxme"
   },
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀  값 Z4, 즉 softmax 에 들어가는 입력 값\n",
    "Z4 = logits = tf.matmul(A3, W4) + b4\n",
    "\n",
    "y = A4 = tf.nn.softmax(Z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oq6IWw5Wnxms"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z4, labels=T) )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7inuydhnxnE"
   },
   "outputs": [],
   "source": [
    "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal( tf.argmax(A4, 1), tf.argmax(T, 1) )\n",
    "\n",
    "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "# 예측값 처리\n",
    "predicted_list = tf.argmax(A4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "on_D1VRvnxnW",
    "outputId": "7f17a9a1-35e1-484f-ae9a-a88c87db128b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.968786\n",
      "epochs =  0 , step =  100 , loss_val =  0.51975626\n",
      "epochs =  0 , step =  200 , loss_val =  0.28859043\n",
      "epochs =  0 , step =  300 , loss_val =  0.20512989\n",
      "epochs =  0 , step =  400 , loss_val =  0.21484914\n",
      "epochs =  0 , step =  500 , loss_val =  0.18027733\n",
      "epochs =  1 , step =  0 , loss_val =  0.0622185\n",
      "epochs =  1 , step =  100 , loss_val =  0.15747665\n",
      "epochs =  1 , step =  200 , loss_val =  0.036946896\n",
      "epochs =  1 , step =  300 , loss_val =  0.031739105\n",
      "epochs =  1 , step =  400 , loss_val =  0.1060856\n",
      "epochs =  1 , step =  500 , loss_val =  0.023751827\n",
      "epochs =  2 , step =  0 , loss_val =  0.047512464\n",
      "epochs =  2 , step =  100 , loss_val =  0.048095588\n",
      "epochs =  2 , step =  200 , loss_val =  0.09679649\n",
      "epochs =  2 , step =  300 , loss_val =  0.024054265\n",
      "epochs =  2 , step =  400 , loss_val =  0.033387907\n",
      "epochs =  2 , step =  500 , loss_val =  0.07000161\n",
      "epochs =  3 , step =  0 , loss_val =  0.007479651\n",
      "epochs =  3 , step =  100 , loss_val =  0.034041066\n",
      "epochs =  3 , step =  200 , loss_val =  0.019968227\n",
      "epochs =  3 , step =  300 , loss_val =  0.08882836\n",
      "epochs =  3 , step =  400 , loss_val =  0.03061694\n",
      "epochs =  3 , step =  500 , loss_val =  0.03783938\n",
      "epochs =  4 , step =  0 , loss_val =  0.019253686\n",
      "epochs =  4 , step =  100 , loss_val =  0.011512041\n",
      "epochs =  4 , step =  200 , loss_val =  0.07549915\n",
      "epochs =  4 , step =  300 , loss_val =  0.044363204\n",
      "epochs =  4 , step =  400 , loss_val =  0.12101867\n",
      "epochs =  4 , step =  500 , loss_val =  0.0044571264\n",
      "epochs =  5 , step =  0 , loss_val =  0.03350904\n",
      "epochs =  5 , step =  100 , loss_val =  0.017422115\n",
      "epochs =  5 , step =  200 , loss_val =  0.0076053184\n",
      "epochs =  5 , step =  300 , loss_val =  0.01814186\n",
      "epochs =  5 , step =  400 , loss_val =  0.06259067\n",
      "epochs =  5 , step =  500 , loss_val =  0.0047877906\n",
      "epochs =  6 , step =  0 , loss_val =  0.03312792\n",
      "epochs =  6 , step =  100 , loss_val =  0.0122718075\n",
      "epochs =  6 , step =  200 , loss_val =  0.03190306\n",
      "epochs =  6 , step =  300 , loss_val =  0.112569906\n",
      "epochs =  6 , step =  400 , loss_val =  0.0059848\n",
      "epochs =  6 , step =  500 , loss_val =  0.022013241\n",
      "epochs =  7 , step =  0 , loss_val =  0.043223668\n",
      "epochs =  7 , step =  100 , loss_val =  0.013929215\n",
      "epochs =  7 , step =  200 , loss_val =  0.013965227\n",
      "epochs =  7 , step =  300 , loss_val =  0.036268994\n",
      "epochs =  7 , step =  400 , loss_val =  0.0042466326\n",
      "epochs =  7 , step =  500 , loss_val =  0.06102151\n",
      "epochs =  8 , step =  0 , loss_val =  0.009691574\n",
      "epochs =  8 , step =  100 , loss_val =  0.029963985\n",
      "epochs =  8 , step =  200 , loss_val =  0.008723586\n",
      "epochs =  8 , step =  300 , loss_val =  0.0009487252\n",
      "epochs =  8 , step =  400 , loss_val =  0.003548736\n",
      "epochs =  8 , step =  500 , loss_val =  0.025819412\n",
      "epochs =  9 , step =  0 , loss_val =  0.0027549164\n",
      "epochs =  9 , step =  100 , loss_val =  0.010480929\n",
      "epochs =  9 , step =  200 , loss_val =  0.00038237066\n",
      "epochs =  9 , step =  300 , loss_val =  0.013446181\n",
      "epochs =  9 , step =  400 , loss_val =  0.0095296465\n",
      "epochs =  9 , step =  500 , loss_val =  0.043850824\n",
      "epochs =  10 , step =  0 , loss_val =  0.0012915077\n",
      "epochs =  10 , step =  100 , loss_val =  0.004804501\n",
      "epochs =  10 , step =  200 , loss_val =  0.0081947325\n",
      "epochs =  10 , step =  300 , loss_val =  0.06859257\n",
      "epochs =  10 , step =  400 , loss_val =  0.0047175186\n",
      "epochs =  10 , step =  500 , loss_val =  0.018890018\n",
      "epochs =  11 , step =  0 , loss_val =  0.005301405\n",
      "epochs =  11 , step =  100 , loss_val =  0.00074066885\n",
      "epochs =  11 , step =  200 , loss_val =  0.01752443\n",
      "epochs =  11 , step =  300 , loss_val =  0.04235605\n",
      "epochs =  11 , step =  400 , loss_val =  0.0012659004\n",
      "epochs =  11 , step =  500 , loss_val =  0.0011604121\n",
      "epochs =  12 , step =  0 , loss_val =  0.00025253926\n",
      "epochs =  12 , step =  100 , loss_val =  0.001370296\n",
      "epochs =  12 , step =  200 , loss_val =  0.0068272953\n",
      "epochs =  12 , step =  300 , loss_val =  0.0057228627\n",
      "epochs =  12 , step =  400 , loss_val =  0.0037125377\n",
      "epochs =  12 , step =  500 , loss_val =  0.010676706\n",
      "epochs =  13 , step =  0 , loss_val =  0.0046943263\n",
      "epochs =  13 , step =  100 , loss_val =  0.0017179879\n",
      "epochs =  13 , step =  200 , loss_val =  0.0010893736\n",
      "epochs =  13 , step =  300 , loss_val =  0.004410414\n",
      "epochs =  13 , step =  400 , loss_val =  0.0033573445\n",
      "epochs =  13 , step =  500 , loss_val =  0.00028499865\n",
      "epochs =  14 , step =  0 , loss_val =  0.0005421007\n",
      "epochs =  14 , step =  100 , loss_val =  0.0005549652\n",
      "epochs =  14 , step =  200 , loss_val =  0.00034504256\n",
      "epochs =  14 , step =  300 , loss_val =  0.0025081157\n",
      "epochs =  14 , step =  400 , loss_val =  0.0062365155\n",
      "epochs =  14 , step =  500 , loss_val =  0.011857704\n",
      "epochs =  15 , step =  0 , loss_val =  0.0026030615\n",
      "epochs =  15 , step =  100 , loss_val =  0.0007230173\n",
      "epochs =  15 , step =  200 , loss_val =  0.00028491401\n",
      "epochs =  15 , step =  300 , loss_val =  0.03664305\n",
      "epochs =  15 , step =  400 , loss_val =  0.0023342366\n",
      "epochs =  15 , step =  500 , loss_val =  0.0015348623\n",
      "epochs =  16 , step =  0 , loss_val =  0.00073404575\n",
      "epochs =  16 , step =  100 , loss_val =  0.00030135832\n",
      "epochs =  16 , step =  200 , loss_val =  0.0017309244\n",
      "epochs =  16 , step =  300 , loss_val =  0.00013871885\n",
      "epochs =  16 , step =  400 , loss_val =  0.004697041\n",
      "epochs =  16 , step =  500 , loss_val =  0.0004427696\n",
      "epochs =  17 , step =  0 , loss_val =  0.0001468646\n",
      "epochs =  17 , step =  100 , loss_val =  0.00023640983\n",
      "epochs =  17 , step =  200 , loss_val =  5.9685848e-05\n",
      "epochs =  17 , step =  300 , loss_val =  0.00024003325\n",
      "epochs =  17 , step =  400 , loss_val =  0.00020433306\n",
      "epochs =  17 , step =  500 , loss_val =  0.00021717692\n",
      "epochs =  18 , step =  0 , loss_val =  4.901734e-05\n",
      "epochs =  18 , step =  100 , loss_val =  0.0071416562\n",
      "epochs =  18 , step =  200 , loss_val =  0.0086264135\n",
      "epochs =  18 , step =  300 , loss_val =  0.0013367934\n",
      "epochs =  18 , step =  400 , loss_val =  0.00068165123\n",
      "epochs =  18 , step =  500 , loss_val =  0.001033234\n",
      "epochs =  19 , step =  0 , loss_val =  0.00016776833\n",
      "epochs =  19 , step =  100 , loss_val =  0.018835695\n",
      "epochs =  19 , step =  200 , loss_val =  0.0014352537\n",
      "epochs =  19 , step =  300 , loss_val =  0.018368088\n",
      "epochs =  19 , step =  400 , loss_val =  0.0004148298\n",
      "epochs =  19 , step =  500 , loss_val =  4.4509798e-05\n",
      "epochs =  20 , step =  0 , loss_val =  0.00075314386\n",
      "epochs =  20 , step =  100 , loss_val =  0.00040253744\n",
      "epochs =  20 , step =  200 , loss_val =  5.9774393e-05\n",
      "epochs =  20 , step =  300 , loss_val =  0.00016976161\n",
      "epochs =  20 , step =  400 , loss_val =  0.0004266519\n",
      "epochs =  20 , step =  500 , loss_val =  0.0008492022\n",
      "epochs =  21 , step =  0 , loss_val =  9.844929e-05\n",
      "epochs =  21 , step =  100 , loss_val =  0.00039294892\n",
      "epochs =  21 , step =  200 , loss_val =  8.815368e-05\n",
      "epochs =  21 , step =  300 , loss_val =  0.0011624407\n",
      "epochs =  21 , step =  400 , loss_val =  0.001539464\n",
      "epochs =  21 , step =  500 , loss_val =  6.554376e-05\n",
      "epochs =  22 , step =  0 , loss_val =  0.0004022769\n",
      "epochs =  22 , step =  100 , loss_val =  0.00016069277\n",
      "epochs =  22 , step =  200 , loss_val =  0.00038462967\n",
      "epochs =  22 , step =  300 , loss_val =  4.2152347e-05\n",
      "epochs =  22 , step =  400 , loss_val =  5.8873334e-06\n",
      "epochs =  22 , step =  500 , loss_val =  3.333874e-05\n",
      "epochs =  23 , step =  0 , loss_val =  4.971072e-05\n",
      "epochs =  23 , step =  100 , loss_val =  8.503654e-06\n",
      "epochs =  23 , step =  200 , loss_val =  0.0005000928\n",
      "epochs =  23 , step =  300 , loss_val =  0.0006762357\n",
      "epochs =  23 , step =  400 , loss_val =  0.0013494152\n",
      "epochs =  23 , step =  500 , loss_val =  2.2071059e-05\n",
      "epochs =  24 , step =  0 , loss_val =  3.4877183e-05\n",
      "epochs =  24 , step =  100 , loss_val =  0.00025836023\n",
      "epochs =  24 , step =  200 , loss_val =  0.00014924601\n",
      "epochs =  24 , step =  300 , loss_val =  0.00028356822\n",
      "epochs =  24 , step =  400 , loss_val =  0.0024201968\n",
      "epochs =  24 , step =  500 , loss_val =  0.00022264099\n",
      "epochs =  25 , step =  0 , loss_val =  0.011876553\n",
      "epochs =  25 , step =  100 , loss_val =  0.00017092469\n",
      "epochs =  25 , step =  200 , loss_val =  0.024145478\n",
      "epochs =  25 , step =  300 , loss_val =  0.00028304168\n",
      "epochs =  25 , step =  400 , loss_val =  0.00031418487\n",
      "epochs =  25 , step =  500 , loss_val =  0.00065068045\n",
      "epochs =  26 , step =  0 , loss_val =  0.0017063346\n",
      "epochs =  26 , step =  100 , loss_val =  0.0019081454\n",
      "epochs =  26 , step =  200 , loss_val =  0.0009906233\n",
      "epochs =  26 , step =  300 , loss_val =  8.8231696e-05\n",
      "epochs =  26 , step =  400 , loss_val =  4.9071547e-05\n",
      "epochs =  26 , step =  500 , loss_val =  5.6800236e-05\n",
      "epochs =  27 , step =  0 , loss_val =  0.0013197986\n",
      "epochs =  27 , step =  100 , loss_val =  0.0011041209\n",
      "epochs =  27 , step =  200 , loss_val =  0.00036298222\n",
      "epochs =  27 , step =  300 , loss_val =  5.3040753e-06\n",
      "epochs =  27 , step =  400 , loss_val =  3.0444883e-06\n",
      "epochs =  27 , step =  500 , loss_val =  1.9665826e-05\n",
      "epochs =  28 , step =  0 , loss_val =  0.011977578\n",
      "epochs =  28 , step =  100 , loss_val =  3.4911198e-05\n",
      "epochs =  28 , step =  200 , loss_val =  0.003695633\n",
      "epochs =  28 , step =  300 , loss_val =  2.8388908e-05\n",
      "epochs =  28 , step =  400 , loss_val =  0.0005955286\n",
      "epochs =  28 , step =  500 , loss_val =  0.049567644\n",
      "epochs =  29 , step =  0 , loss_val =  0.0031713936\n",
      "epochs =  29 , step =  100 , loss_val =  0.0010484938\n",
      "epochs =  29 , step =  200 , loss_val =  0.00029016242\n",
      "epochs =  29 , step =  300 , loss_val =  1.50840115e-05\n",
      "epochs =  29 , step =  400 , loss_val =  0.00022572927\n",
      "epochs =  29 , step =  500 , loss_val =  0.022877214\n",
      "\n",
      "elapsed time =  0:00:58.638095\n",
      "\n",
      "Accuracy =  0.9882\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  118\n",
      "\n",
      "length of index_label_false_list 118\n"
     ]
    }
   ],
   "source": [
    "index_label_prediction_list = []\n",
    "\n",
    "with  tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):    # 50 번 반복수행\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
    "\n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "      \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now() \n",
    "    \n",
    "    print(\"\\nelapsed time = \", end_time - start_time) \n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images    # 10000 X 784\n",
    "    test_t_data = mnist.test.labels    # 10000 X 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "        \n",
    "    # numpy type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_prediction_list.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BEvO3lFynxnk",
    "outputId": "ba41ccc4-4a6b-458d-f3a8-90e09803a904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247, 4, 6], [340, 5, 3], [445, 6, 0], [582, 8, 2], [646, 2, 6], [659, 2, 1], [691, 8, 4], [717, 0, 6], [720, 5, 8], [939, 2, 0], [956, 1, 5], [965, 6, 0], [1014, 6, 5], [1039, 7, 8], [1112, 4, 6], [1128, 3, 7], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1319, 8, 0], [1337, 2, 6], [1393, 5, 3], [1414, 9, 4], [1522, 7, 9], [1527, 1, 5], [1554, 9, 8], [1621, 0, 6], [1678, 2, 0], [1681, 3, 7], [1709, 9, 5], [1717, 8, 0], [1790, 2, 7], [1901, 9, 8], [2018, 1, 8], [2098, 2, 0], [2109, 3, 9], [2118, 6, 0], [2129, 9, 8], [2130, 4, 9], [2135, 6, 1], [2266, 1, 5], [2280, 3, 5], [2293, 9, 0], [2369, 5, 3], [2414, 9, 8], [2462, 2, 0], [2488, 2, 4], [2597, 5, 3], [2607, 7, 2], [2654, 6, 1], [2743, 5, 8], [2896, 8, 0], [2921, 3, 8], [2939, 9, 5], [2953, 3, 5], [3073, 1, 2], [3225, 7, 9], [3272, 1, 8], [3384, 2, 0], [3412, 0, 9], [3422, 6, 0], [3503, 9, 1], [3520, 6, 4], [3558, 5, 0], [3559, 8, 5], [3727, 8, 9], [3762, 6, 8], [3778, 5, 8], [3808, 7, 8], [3831, 9, 8], [4078, 9, 3], [4163, 9, 0], [4201, 1, 7], [4248, 2, 1], [4256, 3, 0], [4400, 7, 4], [4740, 3, 5], [4761, 9, 4], [4807, 8, 0], [4814, 6, 4], [5331, 1, 6], [5634, 2, 8], [5642, 1, 5], [5654, 7, 2], [5887, 7, 0], [5937, 5, 3], [5981, 5, 9], [5997, 5, 9], [6028, 5, 3], [6101, 1, 8], [6166, 9, 3], [6576, 7, 1], [6597, 0, 7], [6625, 8, 1], [6783, 1, 6], [7847, 1, 0], [7856, 1, 0], [7899, 1, 8], [7915, 7, 8], [7928, 1, 0], [7990, 1, 8], [8094, 2, 8], [8246, 3, 9], [8325, 0, 5], [8527, 4, 9], [9009, 7, 2], [9015, 7, 2], [9019, 7, 2], [9530, 9, 8], [9540, 1, 8], [9599, 1, 8], [9638, 9, 7], [9664, 2, 7], [9698, 6, 5], [9729, 5, 6], [9768, 2, 0], [9770, 5, 0], [9792, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# index_label_prediction_list\n",
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "kDbIrmOdn-ej",
    "outputId": "0f176eea-e692-4b5b-cdb4-d39e16b6aed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive   # colab 사용시 mount 하기 위한 용도. local 에서는 불필요\n",
    "drive.mount('/content/gdrive/')  # colab 사용시 mount 하기 위한 용도. local 에서는 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "E6tz0qHcnxoJ",
    "outputId": "2552180b-0dd7-42c3-b406-e0b8f9894ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "100 image is saved now\n",
      "110 image is saved now\n",
      "Elapsed save time =>  0:00:45.691260\n",
      "Total  118  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "\n",
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'CNN_example7_'\n",
    "save_dir_name = algorithm_name + str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "colab_default_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
    "\n",
    "os.chdir(colab_default_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_prediction_list:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmQ9v2qlnxoW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "(191124)CNN_example7_1conv_5X5_2FC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
