{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "(191124)CNN_example9_3conv_5X5_5X5_5X5_NoPooling_FC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt2ciGRak9-I",
        "colab_type": "code",
        "outputId": "aa4fe146-3ac5-4991-c48d-12f01b928acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
        "\n",
        "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
        "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
        "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
        "\n",
        "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
        "\n",
        "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
        "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
        "\n",
        "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
        "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
        "print(\"test image shape = \", np.shape(mnist.test.images))\n",
        "print(\"test label shape = \", np.shape(mnist.test.labels))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            " 55000 10000 5000\n",
            "\n",
            "train image shape =  (55000, 784)\n",
            "train label shape =  (55000, 10)\n",
            "test image shape =  (10000, 784)\n",
            "test label shape =  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Doo13ik9-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper-Parameter\n",
        "learning_rate = 0.001  # 학습율\n",
        "epochs = 30            # 반복횟수\n",
        "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbHu2Xnek9-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력과 정답을 위한 플레이스홀더 정의\n",
        "X = tf.placeholder(tf.float32, [None, 784])  \n",
        "\n",
        "T = tf.placeholder(tf.float32, [None, 10])  \n",
        "\n",
        "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
        "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28 X 28 X 1 (black/white)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-YcxLO1k9-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1번째 컨볼루션 층\n",
        "# 5X5 크기를 가지는 32개의 필터를 적용\n",
        "\n",
        "F2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  \n",
        "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
        "\n",
        "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
        "C2 = tf.nn.conv2d(A1, F2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z2 = tf.nn.relu(C2+b2)\n",
        "\n",
        "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
        "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWx5urPxk9-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2번째 컨볼루션 층\n",
        "F3 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev=0.01))  \n",
        "b3 = tf.Variable(tf.constant(0.1, shape=[64]))   \n",
        "\n",
        "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 64 \n",
        "C3 = tf.nn.conv2d(A2, F3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z3 = tf.nn.relu(C3+b3)\n",
        "\n",
        "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 64\n",
        "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNxBw9Fbk9-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3번째 컨볼루션 층\n",
        "F4 = tf.Variable(tf.random_normal([5, 5, 64, 128], stddev=0.01))  \n",
        "b4 = tf.Variable(tf.constant(0.1, shape=[128]))   \n",
        "\n",
        "# 3번째 컨볼루션 연산을 통해 7 X 7 X 64 => 7 X 7 X 128\n",
        "C4 = tf.nn.conv2d(A3, F4, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "A4 = Z4 = tf.nn.relu(C4+b4)\n",
        "\n",
        "# pooling 없음 \n",
        "#A4 = P4 = tf.nn.max_pool(Z4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKyURwwk9-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4X4 크기를 가진 128개의 activation map을 flatten 시킴\n",
        "A4_flat = P4_flat = tf.reshape(A4, [-1, 128*7*7])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vRk70vhk9-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 출력층\n",
        "W5 = tf.Variable(tf.random_normal([128*7*7, 10], stddev=0.01))\n",
        "b5 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "# 출력층 선형회귀  값 Z5, 즉 softmax 에 들어가는 입력 값\n",
        "Z5 = logits = tf.matmul(A4_flat, W5) + b5    # 선형회귀 값 Z5\n",
        "\n",
        "y = A5 = tf.nn.softmax(Z5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prsLY0U6k9-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z5, labels=T) )\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stkXP6Evk9-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
        "predicted_val = tf.equal( tf.argmax(A5, 1), tf.argmax(T, 1) )\n",
        "\n",
        "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
        "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
        "\n",
        "# index list 출력\n",
        "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
        "\n",
        "# 예측값 처리\n",
        "predicted_list = tf.argmax(A5, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9t7mdaWk9-m",
        "colab_type": "code",
        "outputId": "9e06bf04-2434-40a0-e12a-dbd39acdc8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "index_label_prediction_list = []\n",
        "\n",
        "with  tf.Session()  as sess:\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    for i in range(epochs):    # 30 번 반복수행\n",
        "        \n",
        "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
        "\n",
        "        for step in range(total_batch):\n",
        "            \n",
        "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
        "      \n",
        "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
        "        \n",
        "            if step % 100 == 0:\n",
        "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
        "    \n",
        "    end_time = datetime.now() \n",
        "    \n",
        "    print(\"\\nelapsed time = \", end_time - start_time) \n",
        "    \n",
        "    # Accuracy 확인\n",
        "    test_x_data = mnist.test.images    # 10000 X 784\n",
        "    test_t_data = mnist.test.labels    # 10000 X 10\n",
        "    \n",
        "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
        "    \n",
        "    print(\"\\nAccuracy = \", accuracy_val)\n",
        "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
        "    print(\"index_label.shape = \", index_label.shape)\n",
        "    \n",
        "    index_label_list = list(index_label)\n",
        "    print(\"length of index_label_list = \", len(index_label_list))\n",
        "    print(\"false label count = \", index_label_list.count([0]))\n",
        "        \n",
        "    # numpy type 으로 디버그\n",
        "    temp_list = [] \n",
        "    \n",
        "    for index in range(len(index_label)):\n",
        "        \n",
        "        if index_label[index] == 0:\n",
        "            \n",
        "            temp_list.append(index)\n",
        "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
        "            temp_list.append(predicted_list_val[index])\n",
        "            \n",
        "            index_label_prediction_list.append(temp_list)\n",
        "            \n",
        "            temp_list = []\n",
        "            \n",
        "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs =  0 , step =  0 , loss_val =  2.6288614\n",
            "epochs =  0 , step =  100 , loss_val =  0.71275675\n",
            "epochs =  0 , step =  200 , loss_val =  0.2361058\n",
            "epochs =  0 , step =  300 , loss_val =  0.087724335\n",
            "epochs =  0 , step =  400 , loss_val =  0.05635737\n",
            "epochs =  0 , step =  500 , loss_val =  0.04764068\n",
            "epochs =  1 , step =  0 , loss_val =  0.044081964\n",
            "epochs =  1 , step =  100 , loss_val =  0.1303044\n",
            "epochs =  1 , step =  200 , loss_val =  0.068336815\n",
            "epochs =  1 , step =  300 , loss_val =  0.013663927\n",
            "epochs =  1 , step =  400 , loss_val =  0.05011179\n",
            "epochs =  1 , step =  500 , loss_val =  0.1736423\n",
            "epochs =  2 , step =  0 , loss_val =  0.029633299\n",
            "epochs =  2 , step =  100 , loss_val =  0.09348682\n",
            "epochs =  2 , step =  200 , loss_val =  0.041522518\n",
            "epochs =  2 , step =  300 , loss_val =  0.05909346\n",
            "epochs =  2 , step =  400 , loss_val =  0.044099484\n",
            "epochs =  2 , step =  500 , loss_val =  0.0286053\n",
            "epochs =  3 , step =  0 , loss_val =  0.00931208\n",
            "epochs =  3 , step =  100 , loss_val =  0.0268363\n",
            "epochs =  3 , step =  200 , loss_val =  0.002730736\n",
            "epochs =  3 , step =  300 , loss_val =  0.041094314\n",
            "epochs =  3 , step =  400 , loss_val =  0.007019956\n",
            "epochs =  3 , step =  500 , loss_val =  0.01876464\n",
            "epochs =  4 , step =  0 , loss_val =  0.019638326\n",
            "epochs =  4 , step =  100 , loss_val =  0.0052007027\n",
            "epochs =  4 , step =  200 , loss_val =  0.0039088624\n",
            "epochs =  4 , step =  300 , loss_val =  0.027785115\n",
            "epochs =  4 , step =  400 , loss_val =  0.018972233\n",
            "epochs =  4 , step =  500 , loss_val =  0.01860375\n",
            "epochs =  5 , step =  0 , loss_val =  0.03470382\n",
            "epochs =  5 , step =  100 , loss_val =  0.0007264928\n",
            "epochs =  5 , step =  200 , loss_val =  0.004319632\n",
            "epochs =  5 , step =  300 , loss_val =  0.0046794396\n",
            "epochs =  5 , step =  400 , loss_val =  0.0037866107\n",
            "epochs =  5 , step =  500 , loss_val =  0.03323006\n",
            "epochs =  6 , step =  0 , loss_val =  0.04546586\n",
            "epochs =  6 , step =  100 , loss_val =  0.0037733878\n",
            "epochs =  6 , step =  200 , loss_val =  0.016930448\n",
            "epochs =  6 , step =  300 , loss_val =  0.013484603\n",
            "epochs =  6 , step =  400 , loss_val =  0.0012079233\n",
            "epochs =  6 , step =  500 , loss_val =  0.0051473896\n",
            "epochs =  7 , step =  0 , loss_val =  0.0064022117\n",
            "epochs =  7 , step =  100 , loss_val =  0.0042863274\n",
            "epochs =  7 , step =  200 , loss_val =  0.017579675\n",
            "epochs =  7 , step =  300 , loss_val =  0.022350691\n",
            "epochs =  7 , step =  400 , loss_val =  0.03448915\n",
            "epochs =  7 , step =  500 , loss_val =  0.0067092776\n",
            "epochs =  8 , step =  0 , loss_val =  0.00034934416\n",
            "epochs =  8 , step =  100 , loss_val =  0.0021498292\n",
            "epochs =  8 , step =  200 , loss_val =  0.0009409442\n",
            "epochs =  8 , step =  300 , loss_val =  1.8325996e-05\n",
            "epochs =  8 , step =  400 , loss_val =  0.0008555731\n",
            "epochs =  8 , step =  500 , loss_val =  0.0003152321\n",
            "epochs =  9 , step =  0 , loss_val =  0.0003338835\n",
            "epochs =  9 , step =  100 , loss_val =  0.0020317794\n",
            "epochs =  9 , step =  200 , loss_val =  0.0002813812\n",
            "epochs =  9 , step =  300 , loss_val =  0.017107744\n",
            "epochs =  9 , step =  400 , loss_val =  0.059905075\n",
            "epochs =  9 , step =  500 , loss_val =  0.01778729\n",
            "epochs =  10 , step =  0 , loss_val =  0.015061593\n",
            "epochs =  10 , step =  100 , loss_val =  0.008719655\n",
            "epochs =  10 , step =  200 , loss_val =  0.030189224\n",
            "epochs =  10 , step =  300 , loss_val =  0.011379076\n",
            "epochs =  10 , step =  400 , loss_val =  0.00019341953\n",
            "epochs =  10 , step =  500 , loss_val =  0.004764953\n",
            "epochs =  11 , step =  0 , loss_val =  0.0033324938\n",
            "epochs =  11 , step =  100 , loss_val =  0.004051274\n",
            "epochs =  11 , step =  200 , loss_val =  3.5830337e-05\n",
            "epochs =  11 , step =  300 , loss_val =  5.299229e-05\n",
            "epochs =  11 , step =  400 , loss_val =  0.0010870689\n",
            "epochs =  11 , step =  500 , loss_val =  0.0050689722\n",
            "epochs =  12 , step =  0 , loss_val =  0.0010624725\n",
            "epochs =  12 , step =  100 , loss_val =  0.001329506\n",
            "epochs =  12 , step =  200 , loss_val =  0.00595507\n",
            "epochs =  12 , step =  300 , loss_val =  0.0003944058\n",
            "epochs =  12 , step =  400 , loss_val =  0.0011092854\n",
            "epochs =  12 , step =  500 , loss_val =  0.0018907633\n",
            "epochs =  13 , step =  0 , loss_val =  0.0003123129\n",
            "epochs =  13 , step =  100 , loss_val =  0.0023429617\n",
            "epochs =  13 , step =  200 , loss_val =  0.00017457189\n",
            "epochs =  13 , step =  300 , loss_val =  0.000108934604\n",
            "epochs =  13 , step =  400 , loss_val =  0.0018874398\n",
            "epochs =  13 , step =  500 , loss_val =  0.00039506805\n",
            "epochs =  14 , step =  0 , loss_val =  1.9137415e-05\n",
            "epochs =  14 , step =  100 , loss_val =  0.0008537843\n",
            "epochs =  14 , step =  200 , loss_val =  0.00026221105\n",
            "epochs =  14 , step =  300 , loss_val =  7.5212505e-05\n",
            "epochs =  14 , step =  400 , loss_val =  0.00023597322\n",
            "epochs =  14 , step =  500 , loss_val =  0.0002734631\n",
            "epochs =  15 , step =  0 , loss_val =  0.00011010012\n",
            "epochs =  15 , step =  100 , loss_val =  0.0027864438\n",
            "epochs =  15 , step =  200 , loss_val =  0.002020665\n",
            "epochs =  15 , step =  300 , loss_val =  0.0004548256\n",
            "epochs =  15 , step =  400 , loss_val =  0.009477869\n",
            "epochs =  15 , step =  500 , loss_val =  2.8051209e-05\n",
            "epochs =  16 , step =  0 , loss_val =  0.00054450764\n",
            "epochs =  16 , step =  100 , loss_val =  5.57299e-05\n",
            "epochs =  16 , step =  200 , loss_val =  0.0027676066\n",
            "epochs =  16 , step =  300 , loss_val =  0.0018950622\n",
            "epochs =  16 , step =  400 , loss_val =  0.030414606\n",
            "epochs =  16 , step =  500 , loss_val =  0.0011415661\n",
            "epochs =  17 , step =  0 , loss_val =  7.8799436e-05\n",
            "epochs =  17 , step =  100 , loss_val =  8.282739e-06\n",
            "epochs =  17 , step =  200 , loss_val =  1.0531731e-05\n",
            "epochs =  17 , step =  300 , loss_val =  4.79385e-05\n",
            "epochs =  17 , step =  400 , loss_val =  1.6611673e-05\n",
            "epochs =  17 , step =  500 , loss_val =  0.00012099008\n",
            "epochs =  18 , step =  0 , loss_val =  0.00021391701\n",
            "epochs =  18 , step =  100 , loss_val =  7.247752e-05\n",
            "epochs =  18 , step =  200 , loss_val =  5.9987364e-05\n",
            "epochs =  18 , step =  300 , loss_val =  0.00030173297\n",
            "epochs =  18 , step =  400 , loss_val =  0.00020704795\n",
            "epochs =  18 , step =  500 , loss_val =  8.826734e-06\n",
            "epochs =  19 , step =  0 , loss_val =  7.622622e-05\n",
            "epochs =  19 , step =  100 , loss_val =  0.00011234056\n",
            "epochs =  19 , step =  200 , loss_val =  5.897507e-05\n",
            "epochs =  19 , step =  300 , loss_val =  3.803507e-05\n",
            "epochs =  19 , step =  400 , loss_val =  6.884543e-05\n",
            "epochs =  19 , step =  500 , loss_val =  0.06046306\n",
            "epochs =  20 , step =  0 , loss_val =  6.4687796e-05\n",
            "epochs =  20 , step =  100 , loss_val =  0.00063742866\n",
            "epochs =  20 , step =  200 , loss_val =  0.031158378\n",
            "epochs =  20 , step =  300 , loss_val =  0.00032529756\n",
            "epochs =  20 , step =  400 , loss_val =  0.07840648\n",
            "epochs =  20 , step =  500 , loss_val =  8.380423e-05\n",
            "epochs =  21 , step =  0 , loss_val =  0.004880429\n",
            "epochs =  21 , step =  100 , loss_val =  1.82195e-05\n",
            "epochs =  21 , step =  200 , loss_val =  0.00047740038\n",
            "epochs =  21 , step =  300 , loss_val =  0.00015236788\n",
            "epochs =  21 , step =  400 , loss_val =  6.3179436e-07\n",
            "epochs =  21 , step =  500 , loss_val =  2.5711247e-06\n",
            "epochs =  22 , step =  0 , loss_val =  0.001032945\n",
            "epochs =  22 , step =  100 , loss_val =  0.00058177754\n",
            "epochs =  22 , step =  200 , loss_val =  4.0196974e-05\n",
            "epochs =  22 , step =  300 , loss_val =  0.011572789\n",
            "epochs =  22 , step =  400 , loss_val =  4.478423e-06\n",
            "epochs =  22 , step =  500 , loss_val =  0.05451449\n",
            "epochs =  23 , step =  0 , loss_val =  5.0952975e-05\n",
            "epochs =  23 , step =  100 , loss_val =  8.713926e-05\n",
            "epochs =  23 , step =  200 , loss_val =  0.023546852\n",
            "epochs =  23 , step =  300 , loss_val =  0.015748221\n",
            "epochs =  23 , step =  400 , loss_val =  0.0002593431\n",
            "epochs =  23 , step =  500 , loss_val =  1.410827e-05\n",
            "epochs =  24 , step =  0 , loss_val =  2.2433753e-06\n",
            "epochs =  24 , step =  100 , loss_val =  0.00013427208\n",
            "epochs =  24 , step =  200 , loss_val =  6.13782e-05\n",
            "epochs =  24 , step =  300 , loss_val =  3.390435e-05\n",
            "epochs =  24 , step =  400 , loss_val =  0.00039048248\n",
            "epochs =  24 , step =  500 , loss_val =  1.2385664e-06\n",
            "epochs =  25 , step =  0 , loss_val =  5.60283e-08\n",
            "epochs =  25 , step =  100 , loss_val =  0.0022641828\n",
            "epochs =  25 , step =  200 , loss_val =  1.3100937e-06\n",
            "epochs =  25 , step =  300 , loss_val =  3.02168e-06\n",
            "epochs =  25 , step =  400 , loss_val =  1.2124505e-05\n",
            "epochs =  25 , step =  500 , loss_val =  0.001438845\n",
            "epochs =  26 , step =  0 , loss_val =  0.010195455\n",
            "epochs =  26 , step =  100 , loss_val =  0.010838167\n",
            "epochs =  26 , step =  200 , loss_val =  9.726697e-06\n",
            "epochs =  26 , step =  300 , loss_val =  0.0002710119\n",
            "epochs =  26 , step =  400 , loss_val =  2.5574327e-05\n",
            "epochs =  26 , step =  500 , loss_val =  0.0035232357\n",
            "epochs =  27 , step =  0 , loss_val =  0.0003526789\n",
            "epochs =  27 , step =  100 , loss_val =  9.6558e-07\n",
            "epochs =  27 , step =  200 , loss_val =  0.0010459354\n",
            "epochs =  27 , step =  300 , loss_val =  0.003894995\n",
            "epochs =  27 , step =  400 , loss_val =  6.6843972e-06\n",
            "epochs =  27 , step =  500 , loss_val =  8.4952546e-05\n",
            "epochs =  28 , step =  0 , loss_val =  0.00035607535\n",
            "epochs =  28 , step =  100 , loss_val =  0.09017464\n",
            "epochs =  28 , step =  200 , loss_val =  0.0010434386\n",
            "epochs =  28 , step =  300 , loss_val =  0.0005887421\n",
            "epochs =  28 , step =  400 , loss_val =  1.386363e-06\n",
            "epochs =  28 , step =  500 , loss_val =  0.00046160945\n",
            "epochs =  29 , step =  0 , loss_val =  8.571047e-07\n",
            "epochs =  29 , step =  100 , loss_val =  8.528799e-06\n",
            "epochs =  29 , step =  200 , loss_val =  0.00015327787\n",
            "epochs =  29 , step =  300 , loss_val =  1.0919174e-06\n",
            "epochs =  29 , step =  400 , loss_val =  0.00060663075\n",
            "epochs =  29 , step =  500 , loss_val =  9.179102e-08\n",
            "\n",
            "elapsed time =  0:03:38.699889\n",
            "\n",
            "Accuracy =  0.9943\n",
            "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
            "index_label.shape =  (10000,)\n",
            "length of index_label_list =  10000\n",
            "false label count =  57\n",
            "\n",
            "length of index_label_false_list 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48THz29lk9-o",
        "colab_type": "code",
        "outputId": "e98c86dd-879a-4781-948b-dc9e25189d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# index_label_prediction_list\n",
        "print(index_label_prediction_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[247, 4, 2], [340, 5, 3], [582, 8, 3], [659, 2, 1], [674, 5, 3], [740, 4, 9], [791, 5, 9], [947, 8, 9], [1014, 6, 0], [1033, 8, 1], [1039, 7, 1], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1260, 7, 1], [1459, 2, 3], [1878, 8, 3], [1901, 9, 4], [2035, 5, 3], [2070, 7, 1], [2130, 4, 9], [2135, 6, 1], [2414, 9, 4], [2582, 9, 7], [2597, 5, 3], [2654, 6, 1], [2720, 9, 4], [2771, 4, 9], [2896, 8, 0], [2921, 3, 8], [2953, 3, 5], [3422, 6, 0], [3558, 5, 0], [3727, 8, 3], [3762, 6, 8], [3780, 4, 6], [3941, 4, 6], [4176, 2, 7], [4360, 5, 3], [4571, 6, 8], [4699, 6, 1], [4723, 2, 3], [4740, 3, 5], [4761, 9, 4], [4823, 9, 4], [5654, 7, 2], [5936, 4, 9], [5937, 5, 3], [6576, 7, 1], [6597, 0, 9], [6625, 8, 2], [6651, 0, 6], [7216, 0, 6], [8094, 2, 8], [8316, 7, 2], [8520, 4, 9], [9729, 5, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9d89jv1XTkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "fd445556-3a84-40a1-f0d5-932bba7c7eea"
      },
      "source": [
        "from google.colab import drive   # colab 사용시 mount 하기 위한 용도. local 에서는 불필요\n",
        "drive.mount('/content/gdrive/')  # colab 사용시 mount 하기 위한 용도. local 에서는 불필요"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjMMkZkdk9-p",
        "colab_type": "code",
        "outputId": "aa92e866-2668-4e91-86ff-3f08b7f68027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "# check false data\n",
        "import os\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "save_count = 0\n",
        "\n",
        "# 현재 디렉토리 저장\n",
        "curr_dir = os.getcwd()\n",
        "\n",
        "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
        "now = datetime.now()\n",
        "algorithm_name = 'CNN_example9_'\n",
        "save_dir_name = algorithm_name + str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
        "\n",
        "colab_default_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "\n",
        "os.chdir(colab_default_dir)\n",
        "os.mkdir(save_dir_name)\n",
        "\n",
        "# change dir\n",
        "os.chdir(save_dir_name)\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for list_data in index_label_prediction_list:\n",
        "    \n",
        "    index_int = list_data[0]\n",
        "    label_int = list_data[1]\n",
        "    prediction_int = list_data[2]\n",
        "        \n",
        "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
        "    img = test_x_data[index_int].reshape(28,28)  \n",
        "    plt.imshow(img, cmap='gray')\n",
        "    \n",
        "    # 정답 문자열\n",
        "    label_str = str(label_int)\n",
        "    \n",
        "    # 예측값 문자열\n",
        "    prediction_str = str(prediction_int)\n",
        "    \n",
        "    # 정답과 오답을 나타내는 문자열\n",
        "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
        "    \n",
        "    # 저장 파일 이름 생성, str(index_int).png\n",
        "    save_image_name = str(index_int) + '.png'\n",
        "    \n",
        "    plt.title(label_prediction_str)\n",
        "    plt.savefig(save_image_name)\n",
        "    \n",
        "    save_count += 1\n",
        "    \n",
        "    if save_count % 10 == 0:\n",
        "        \n",
        "        print(save_count, 'image is saved now')\n",
        "\n",
        "    \n",
        "end_time = datetime.now()\n",
        "\n",
        "print('Elapsed save time => ', end_time - start_time)\n",
        "print('Total ', save_count, \" data is saved\")\n",
        "\n",
        "# 원래의 dir 로 복귀\n",
        "os.chdir(curr_dir)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 image is saved now\n",
            "20 image is saved now\n",
            "30 image is saved now\n",
            "40 image is saved now\n",
            "50 image is saved now\n",
            "Elapsed save time =>  0:00:16.005185\n",
            "Total  57  data is saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWSYcdrNMOOxmmfg/Zrp2Gv21GMgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GVrLMouk9-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}