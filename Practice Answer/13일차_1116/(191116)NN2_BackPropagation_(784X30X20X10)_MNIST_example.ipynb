{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralNetwork Class\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # 생성자\n",
    "    def __init__(self, input_nodes, hidden_nodes_1, hidden_nodes_2, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes_1 = hidden_nodes_1\n",
    "        self.hidden_nodes_2 = hidden_nodes_2\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # 2층 hidden layer unit \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        #self.W2 = np.random.rand(self.input_nodes,self.hidden_nodes)\n",
    "        # Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes_1) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes_1)\n",
    "        \n",
    "        # Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes_1, self.hidden_nodes_2) / np.sqrt(self.hidden_nodes_1/2)\n",
    "        self.b3= np.random.rand(self.hidden_nodes_2)\n",
    "        \n",
    "        # 3층 output layer unit\n",
    "        #self.W3 = np.random.rand(self.hidden_nodes, self.output_nodes)\n",
    "        # Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W4 = np.random.randn(self.hidden_nodes_2, self.output_nodes) / np.sqrt(self.hidden_nodes_2/2)\n",
    "        self.b4 = np.random.rand(self.output_nodes)\n",
    "                                \n",
    "        # 4층 output layer 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z4 = np.zeros([1,output_nodes])\n",
    "        self.A4 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 3층 hidden layer 2 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,hidden_nodes_2])\n",
    "        self.A3 = np.zeros([1,hidden_nodes_2])\n",
    "        \n",
    "        # 2층 hidden layer 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes_1])\n",
    "        self.A2 = np.zeros([1,hidden_nodes_1])\n",
    "        \n",
    "        # 1층 input layer 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])       \n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 1층 출력 계산, 가중합과 출력은 입력 값과 동일함\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 2층 가중합, 출력 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 3층 가중합, 출력 계산    \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 4층 가중합 , 출력 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        y = self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        #MSE\n",
    "        #return ( np.sum( (self.A4-self.target_data)**2 ) ) / ( len(self.input_data) )\n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 1층 출력 계산, 가중합과 출력은 입력 값과 동일함\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 2층 가중합, 출력 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 3층 가중합, 출력 계산    \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 4층 가중합 , 출력 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        y = self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        #MSE\n",
    "        #return ( np.sum( (self.A4-self.target_data)**2 ) ) / ( len(self.input_data) )\n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        # input_data 는 행렬로 입력됨 즉, (1, 784) shape 을 가짐\n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        Z4 = np.dot(A3, self.W4) + self.b4\n",
    "        y = A4 = sigmoid(Z4)\n",
    "        \n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "    \n",
    "\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, test_input_data, test_target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        # list which contains (index, label, prediction) value\n",
    "        index_label_prediction_list = []\n",
    "        \n",
    "        # temp list which contains label and prediction in sequence\n",
    "        temp_list = []\n",
    "        \n",
    "        for index in range(len(test_input_data)):\n",
    "                        \n",
    "            label = int(test_target_data[index])\n",
    "                        \n",
    "            # one-hot encoding을 위한 데이터 정규화 (data normalize)\n",
    "            data = (test_input_data[index] / 255.0 * 0.99) + 0.01\n",
    "                  \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌\n",
    "            predicted_num = self.predict(np.array(data, ndmin=2)) \n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                # label_prediction_list\n",
    "                temp_list.append(index)\n",
    "                temp_list.append(label)\n",
    "                temp_list.append(predicted_num)\n",
    "                \n",
    "                index_label_prediction_list.append(temp_list)\n",
    "                \n",
    "                temp_list = []\n",
    "                \n",
    "                \n",
    "        print(\"Current Accuracy = \", (len(matched_list)/(len(test_input_data))) )\n",
    "        \n",
    "        return matched_list, not_matched_list, index_label_prediction_list\n",
    "    \n",
    "            \n",
    "    # input_data : 784 개,  target_data : 10개\n",
    "    def train(self, input_data, target_data):  \n",
    "        \n",
    "        self.target_data = target_data    \n",
    "        self.input_data = input_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()\n",
    "        \n",
    "        \n",
    "        # 출력층 loss 인 loss_4, W4, b4 계산\n",
    "        loss_4 = (self.A4-self.target_data) * self.A4 * (1-self.A4)     \n",
    "        \n",
    "        W4_diff = np.dot(self.A3.T, loss_4)\n",
    "        b4_diff = loss_4\n",
    "        \n",
    "        self.W4 = self.W4 - self.learning_rate * W4_diff        \n",
    "        self.b4 = self.b4 - self.learning_rate * b4_diff\n",
    "                \n",
    "        # 은닉층 2 loss 인 loss_3, W3, b3 계산\n",
    "        loss_3 = np.dot(loss_4, self.W4.T) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        W3_diff = np.dot(self.A2.T, loss_3)\n",
    "        b3_diff = loss_3\n",
    "        \n",
    "        self.W3 = self.W3 - self.learning_rate * W3_diff        \n",
    "        self.b3 = self.b3 - self.learning_rate * b3_diff         \n",
    "        \n",
    "        # 은닉층 1 loss 인 loss_2, W2, b2 계산  \n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        W2_diff = np.dot(self.A1.T, loss_2)\n",
    "        b2_diff = loss_2\n",
    "        \n",
    "        self.W2 = self.W2 - self.learning_rate * W2_diff        \n",
    "        self.b2 = self.b2 - self.learning_rate * b2_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n",
      "training_data[0,0] =  5.0 , len(training_data[0]) =  785\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 training data 읽어옴\n",
    "training_data = np.loadtxt('./(191116)mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape)\n",
    "print(\"training_data[0,0] = \", training_data[0,0], \", len(training_data[0]) = \", len(training_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 784 X 30 X 20 X 10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 ,  loss_val =  9.812880521067589\n",
      "epochs =  0 , step =  1000 ,  loss_val =  3.1943361877322403\n",
      "epochs =  0 , step =  2000 ,  loss_val =  3.3742283606500902\n",
      "epochs =  0 , step =  3000 ,  loss_val =  3.6870999471627517\n",
      "epochs =  0 , step =  4000 ,  loss_val =  1.6429630332991636\n",
      "epochs =  0 , step =  5000 ,  loss_val =  1.2553811605087812\n",
      "epochs =  0 , step =  6000 ,  loss_val =  1.0269334571189748\n",
      "epochs =  0 , step =  7000 ,  loss_val =  1.8590467129916257\n",
      "epochs =  0 , step =  8000 ,  loss_val =  0.9869158040613637\n",
      "epochs =  0 , step =  9000 ,  loss_val =  1.3461808364565566\n",
      "epochs =  0 , step =  10000 ,  loss_val =  0.9261116383654657\n",
      "epochs =  0 , step =  11000 ,  loss_val =  0.8629257050130223\n",
      "epochs =  0 , step =  12000 ,  loss_val =  1.1839223982132256\n",
      "epochs =  0 , step =  13000 ,  loss_val =  1.0753877970896624\n",
      "epochs =  0 , step =  14000 ,  loss_val =  0.7166898971089484\n",
      "epochs =  0 , step =  15000 ,  loss_val =  1.1779687768217635\n",
      "epochs =  0 , step =  16000 ,  loss_val =  0.8297966328211135\n",
      "epochs =  0 , step =  17000 ,  loss_val =  0.9329516997769476\n",
      "epochs =  0 , step =  18000 ,  loss_val =  0.9101769407327738\n",
      "epochs =  0 , step =  19000 ,  loss_val =  0.843460704350903\n",
      "epochs =  0 , step =  20000 ,  loss_val =  0.7673704747612824\n",
      "epochs =  0 , step =  21000 ,  loss_val =  1.0477423090720137\n",
      "epochs =  0 , step =  22000 ,  loss_val =  0.7735153731884824\n",
      "epochs =  0 , step =  23000 ,  loss_val =  0.7010409643005937\n",
      "epochs =  0 , step =  24000 ,  loss_val =  0.7858375136573503\n",
      "epochs =  0 , step =  25000 ,  loss_val =  1.1517639297131566\n",
      "epochs =  0 , step =  26000 ,  loss_val =  0.6695905443351904\n",
      "epochs =  0 , step =  27000 ,  loss_val =  1.1943774097931832\n",
      "epochs =  0 , step =  28000 ,  loss_val =  0.7155786167739462\n",
      "epochs =  0 , step =  29000 ,  loss_val =  0.7268537074919237\n",
      "epochs =  0 , step =  30000 ,  loss_val =  0.6456379176759628\n",
      "epochs =  0 , step =  31000 ,  loss_val =  1.8430904421226828\n",
      "epochs =  0 , step =  32000 ,  loss_val =  0.7072732257752088\n",
      "epochs =  0 , step =  33000 ,  loss_val =  0.9618764440482115\n",
      "epochs =  0 , step =  34000 ,  loss_val =  0.8669062326946004\n",
      "epochs =  0 , step =  35000 ,  loss_val =  0.6950196271779346\n",
      "epochs =  0 , step =  36000 ,  loss_val =  0.8564802812294533\n",
      "epochs =  0 , step =  37000 ,  loss_val =  0.6809593798282576\n",
      "epochs =  0 , step =  38000 ,  loss_val =  0.6849908101655169\n",
      "epochs =  0 , step =  39000 ,  loss_val =  1.1108256189303038\n",
      "epochs =  0 , step =  40000 ,  loss_val =  0.6501354532300061\n",
      "epochs =  0 , step =  41000 ,  loss_val =  0.7206269476197904\n",
      "epochs =  0 , step =  42000 ,  loss_val =  0.6757156871857157\n",
      "epochs =  0 , step =  43000 ,  loss_val =  1.0828456441752308\n",
      "epochs =  0 , step =  44000 ,  loss_val =  0.7229489809242048\n",
      "epochs =  0 , step =  45000 ,  loss_val =  0.6792375496479053\n",
      "epochs =  0 , step =  46000 ,  loss_val =  0.7384014797179538\n",
      "epochs =  0 , step =  47000 ,  loss_val =  0.7261508911211538\n",
      "epochs =  0 , step =  48000 ,  loss_val =  0.6712271846701793\n",
      "epochs =  0 , step =  49000 ,  loss_val =  0.6555946110925825\n",
      "epochs =  0 , step =  50000 ,  loss_val =  0.7715260485746318\n",
      "epochs =  0 , step =  51000 ,  loss_val =  0.7150055696685923\n",
      "epochs =  0 , step =  52000 ,  loss_val =  0.8129198435610746\n",
      "epochs =  0 , step =  53000 ,  loss_val =  0.6858210923779009\n",
      "epochs =  0 , step =  54000 ,  loss_val =  0.7849253187025523\n",
      "epochs =  0 , step =  55000 ,  loss_val =  0.6862292640190947\n",
      "epochs =  0 , step =  56000 ,  loss_val =  0.7596920478382643\n",
      "epochs =  0 , step =  57000 ,  loss_val =  0.7160365996955534\n",
      "epochs =  0 , step =  58000 ,  loss_val =  0.8900342648094139\n",
      "epochs =  0 , step =  59000 ,  loss_val =  0.7676552087234526\n",
      "epochs =  1 , step =  0 ,  loss_val =  0.918567276091455\n",
      "epochs =  1 , step =  1000 ,  loss_val =  0.7524825851232763\n",
      "epochs =  1 , step =  2000 ,  loss_val =  4.262828653520137\n",
      "epochs =  1 , step =  3000 ,  loss_val =  0.7995549621803982\n",
      "epochs =  1 , step =  4000 ,  loss_val =  0.7310706306960851\n",
      "epochs =  1 , step =  5000 ,  loss_val =  0.8782039210339783\n",
      "epochs =  1 , step =  6000 ,  loss_val =  0.7074179253282938\n",
      "epochs =  1 , step =  7000 ,  loss_val =  0.7942757294654266\n",
      "epochs =  1 , step =  8000 ,  loss_val =  0.7179649733665456\n",
      "epochs =  1 , step =  9000 ,  loss_val =  1.0918737229059645\n",
      "epochs =  1 , step =  10000 ,  loss_val =  0.6638716722463875\n",
      "epochs =  1 , step =  11000 ,  loss_val =  0.7002850322413772\n",
      "epochs =  1 , step =  12000 ,  loss_val =  0.9756226199078568\n",
      "epochs =  1 , step =  13000 ,  loss_val =  0.7458478422488801\n",
      "epochs =  1 , step =  14000 ,  loss_val =  0.727463121563867\n",
      "epochs =  1 , step =  15000 ,  loss_val =  0.7016704200426269\n",
      "epochs =  1 , step =  16000 ,  loss_val =  0.6512495564874798\n",
      "epochs =  1 , step =  17000 ,  loss_val =  0.659584427458056\n",
      "epochs =  1 , step =  18000 ,  loss_val =  0.7871965417945208\n",
      "epochs =  1 , step =  19000 ,  loss_val =  0.8983719385711185\n",
      "epochs =  1 , step =  20000 ,  loss_val =  0.6659979875121733\n",
      "epochs =  1 , step =  21000 ,  loss_val =  0.8226538759160467\n",
      "epochs =  1 , step =  22000 ,  loss_val =  0.6686443916704958\n",
      "epochs =  1 , step =  23000 ,  loss_val =  0.7100091449738685\n",
      "epochs =  1 , step =  24000 ,  loss_val =  0.7583777782289698\n",
      "epochs =  1 , step =  25000 ,  loss_val =  0.9426183084337664\n",
      "epochs =  1 , step =  26000 ,  loss_val =  0.6651569907568413\n",
      "epochs =  1 , step =  27000 ,  loss_val =  1.2307947726501487\n",
      "epochs =  1 , step =  28000 ,  loss_val =  0.7371810371165347\n",
      "epochs =  1 , step =  29000 ,  loss_val =  0.7281296287492448\n",
      "epochs =  1 , step =  30000 ,  loss_val =  0.641345417398041\n",
      "epochs =  1 , step =  31000 ,  loss_val =  1.584129880623669\n",
      "epochs =  1 , step =  32000 ,  loss_val =  0.6784588417186462\n",
      "epochs =  1 , step =  33000 ,  loss_val =  0.7459366178713308\n",
      "epochs =  1 , step =  34000 ,  loss_val =  0.8684910337213172\n",
      "epochs =  1 , step =  35000 ,  loss_val =  0.7504511755002228\n",
      "epochs =  1 , step =  36000 ,  loss_val =  0.783471053812147\n",
      "epochs =  1 , step =  37000 ,  loss_val =  0.7266044386734378\n",
      "epochs =  1 , step =  38000 ,  loss_val =  0.6787734299209546\n",
      "epochs =  1 , step =  39000 ,  loss_val =  0.944211827774043\n",
      "epochs =  1 , step =  40000 ,  loss_val =  0.696562487266279\n",
      "epochs =  1 , step =  41000 ,  loss_val =  0.6924647843319249\n",
      "epochs =  1 , step =  42000 ,  loss_val =  0.7345294181463058\n",
      "epochs =  1 , step =  43000 ,  loss_val =  0.8547850084821098\n",
      "epochs =  1 , step =  44000 ,  loss_val =  0.7347556208918987\n",
      "epochs =  1 , step =  45000 ,  loss_val =  0.646330610858626\n",
      "epochs =  1 , step =  46000 ,  loss_val =  0.7279003960483643\n",
      "epochs =  1 , step =  47000 ,  loss_val =  0.7412574863110966\n",
      "epochs =  1 , step =  48000 ,  loss_val =  0.6751064350806689\n",
      "epochs =  1 , step =  49000 ,  loss_val =  0.7119907985527735\n",
      "epochs =  1 , step =  50000 ,  loss_val =  0.6830794997993836\n",
      "epochs =  1 , step =  51000 ,  loss_val =  0.7518161259872371\n",
      "epochs =  1 , step =  52000 ,  loss_val =  0.7861667289167826\n",
      "epochs =  1 , step =  53000 ,  loss_val =  0.7455144083601163\n",
      "epochs =  1 , step =  54000 ,  loss_val =  0.7600489185357887\n",
      "epochs =  1 , step =  55000 ,  loss_val =  0.7317396170511657\n",
      "epochs =  1 , step =  56000 ,  loss_val =  0.7906003839030952\n",
      "epochs =  1 , step =  57000 ,  loss_val =  0.72933474710457\n",
      "epochs =  1 , step =  58000 ,  loss_val =  0.7365323588790135\n",
      "epochs =  1 , step =  59000 ,  loss_val =  0.7876568321156422\n",
      "\n",
      "elapsed time =  0:00:35.586862\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "\n",
    "hidden_nodes_1 = 30\n",
    "hidden_nodes_2 = 20\n",
    "\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 2\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes_1, hidden_nodes_2, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        #target_data = training_data[step, 0]\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        #input_data = training_data[step, 1:]\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \",  loss_val = \", nn.loss_val())\n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Current Accuracy =  0.9413\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "test_data = np.loadtxt('./(191116)mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "test_input_data = test_data[ : , 1: ]\n",
    "test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "# measure accuracy\n",
    "(true_list, false_list, index_label_prediction_list) = nn.accuracy(test_input_data, test_target_data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 784 X 40 X 40 X 10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 ,  loss_val =  7.259214386289922\n",
      "epochs =  0 , step =  1000 ,  loss_val =  3.158337289158233\n",
      "epochs =  0 , step =  2000 ,  loss_val =  2.9110514516704136\n",
      "epochs =  0 , step =  3000 ,  loss_val =  3.5999858233314743\n",
      "epochs =  0 , step =  4000 ,  loss_val =  1.8196394872268715\n",
      "epochs =  0 , step =  5000 ,  loss_val =  1.3359786248073102\n",
      "epochs =  0 , step =  6000 ,  loss_val =  0.9357008723009992\n",
      "epochs =  0 , step =  7000 ,  loss_val =  1.8059464042390518\n",
      "epochs =  0 , step =  8000 ,  loss_val =  0.8362586880677303\n",
      "epochs =  0 , step =  9000 ,  loss_val =  1.3649445605584762\n",
      "epochs =  0 , step =  10000 ,  loss_val =  0.8102417412059502\n",
      "epochs =  0 , step =  11000 ,  loss_val =  0.7366961567105924\n",
      "epochs =  0 , step =  12000 ,  loss_val =  0.964751490976774\n",
      "epochs =  0 , step =  13000 ,  loss_val =  0.9095652648836524\n",
      "epochs =  0 , step =  14000 ,  loss_val =  0.6659918430199427\n",
      "epochs =  0 , step =  15000 ,  loss_val =  0.867676918913431\n",
      "epochs =  0 , step =  16000 ,  loss_val =  0.7152102417785958\n",
      "epochs =  0 , step =  17000 ,  loss_val =  1.036516818203212\n",
      "epochs =  0 , step =  18000 ,  loss_val =  0.9962676194464464\n",
      "epochs =  0 , step =  19000 ,  loss_val =  0.9151297442318493\n",
      "epochs =  0 , step =  20000 ,  loss_val =  0.6841841868510944\n",
      "epochs =  0 , step =  21000 ,  loss_val =  0.9693041188939269\n",
      "epochs =  0 , step =  22000 ,  loss_val =  0.8882912282177241\n",
      "epochs =  0 , step =  23000 ,  loss_val =  0.6822137002067379\n",
      "epochs =  0 , step =  24000 ,  loss_val =  0.7389734810059513\n",
      "epochs =  0 , step =  25000 ,  loss_val =  1.2024705132674662\n",
      "epochs =  0 , step =  26000 ,  loss_val =  0.6582930166020685\n",
      "epochs =  0 , step =  27000 ,  loss_val =  1.1910846561861879\n",
      "epochs =  0 , step =  28000 ,  loss_val =  0.6705059613590535\n",
      "epochs =  0 , step =  29000 ,  loss_val =  0.6880011572100028\n",
      "epochs =  0 , step =  30000 ,  loss_val =  0.6656684962106201\n",
      "epochs =  0 , step =  31000 ,  loss_val =  1.5447399921246647\n",
      "epochs =  0 , step =  32000 ,  loss_val =  0.6523109574450943\n",
      "epochs =  0 , step =  33000 ,  loss_val =  0.9768553931472729\n",
      "epochs =  0 , step =  34000 ,  loss_val =  0.8326572268808159\n",
      "epochs =  0 , step =  35000 ,  loss_val =  0.6977843908816099\n",
      "epochs =  0 , step =  36000 ,  loss_val =  0.9198534478575469\n",
      "epochs =  0 , step =  37000 ,  loss_val =  0.6363202895767768\n",
      "epochs =  0 , step =  38000 ,  loss_val =  0.6984160400098347\n",
      "epochs =  0 , step =  39000 ,  loss_val =  1.0220496343062524\n",
      "epochs =  0 , step =  40000 ,  loss_val =  0.6817036745936265\n",
      "epochs =  0 , step =  41000 ,  loss_val =  0.7070467960149108\n",
      "epochs =  0 , step =  42000 ,  loss_val =  0.6653466930312297\n",
      "epochs =  0 , step =  43000 ,  loss_val =  0.9479830032648366\n",
      "epochs =  0 , step =  44000 ,  loss_val =  0.7877414690910947\n",
      "epochs =  0 , step =  45000 ,  loss_val =  0.7657569434193097\n",
      "epochs =  0 , step =  46000 ,  loss_val =  0.7520584522838871\n",
      "epochs =  0 , step =  47000 ,  loss_val =  0.714142639255396\n",
      "epochs =  0 , step =  48000 ,  loss_val =  0.7466776498116596\n",
      "epochs =  0 , step =  49000 ,  loss_val =  0.6491915268963013\n",
      "epochs =  0 , step =  50000 ,  loss_val =  0.8503468344427707\n",
      "epochs =  0 , step =  51000 ,  loss_val =  0.7300044475033841\n",
      "epochs =  0 , step =  52000 ,  loss_val =  0.7276972772517551\n",
      "epochs =  0 , step =  53000 ,  loss_val =  0.6776044661730655\n",
      "epochs =  0 , step =  54000 ,  loss_val =  0.7303327420553317\n",
      "epochs =  0 , step =  55000 ,  loss_val =  0.7028731153383547\n",
      "epochs =  0 , step =  56000 ,  loss_val =  0.7397768799602608\n",
      "epochs =  0 , step =  57000 ,  loss_val =  0.7531255470697859\n",
      "epochs =  0 , step =  58000 ,  loss_val =  0.8166814632881152\n",
      "epochs =  0 , step =  59000 ,  loss_val =  0.7326853120345802\n",
      "epochs =  1 , step =  0 ,  loss_val =  0.755971050822411\n",
      "epochs =  1 , step =  1000 ,  loss_val =  0.7294557753446502\n",
      "epochs =  1 , step =  2000 ,  loss_val =  1.353841480758488\n",
      "epochs =  1 , step =  3000 ,  loss_val =  0.8362270447559141\n",
      "epochs =  1 , step =  4000 ,  loss_val =  0.8015321071975647\n",
      "epochs =  1 , step =  5000 ,  loss_val =  0.8421707778432214\n",
      "epochs =  1 , step =  6000 ,  loss_val =  0.7050213925621693\n",
      "epochs =  1 , step =  7000 ,  loss_val =  0.6875966528189805\n",
      "epochs =  1 , step =  8000 ,  loss_val =  0.7238449405038678\n",
      "epochs =  1 , step =  9000 ,  loss_val =  0.7558267998386502\n",
      "epochs =  1 , step =  10000 ,  loss_val =  0.7340034287725832\n",
      "epochs =  1 , step =  11000 ,  loss_val =  0.6746615441129625\n",
      "epochs =  1 , step =  12000 ,  loss_val =  1.0142569925472742\n",
      "epochs =  1 , step =  13000 ,  loss_val =  0.7776028795934469\n",
      "epochs =  1 , step =  14000 ,  loss_val =  0.7182973023004421\n",
      "epochs =  1 , step =  15000 ,  loss_val =  0.6816088987309563\n",
      "epochs =  1 , step =  16000 ,  loss_val =  0.6531566888435544\n",
      "epochs =  1 , step =  17000 ,  loss_val =  0.7325716770956328\n",
      "epochs =  1 , step =  18000 ,  loss_val =  0.7141467234467114\n",
      "epochs =  1 , step =  19000 ,  loss_val =  0.8053940348077832\n",
      "epochs =  1 , step =  20000 ,  loss_val =  0.6890239626013183\n",
      "epochs =  1 , step =  21000 ,  loss_val =  0.9282000053214298\n",
      "epochs =  1 , step =  22000 ,  loss_val =  0.7751424681577213\n",
      "epochs =  1 , step =  23000 ,  loss_val =  0.7645561398619708\n",
      "epochs =  1 , step =  24000 ,  loss_val =  0.696470274724292\n",
      "epochs =  1 , step =  25000 ,  loss_val =  0.9627930425956578\n",
      "epochs =  1 , step =  26000 ,  loss_val =  0.6587019124576238\n",
      "epochs =  1 , step =  27000 ,  loss_val =  0.9948880105142258\n",
      "epochs =  1 , step =  28000 ,  loss_val =  0.7138687087713724\n",
      "epochs =  1 , step =  29000 ,  loss_val =  0.7253911245465\n",
      "epochs =  1 , step =  30000 ,  loss_val =  0.7526693835886119\n",
      "epochs =  1 , step =  31000 ,  loss_val =  1.4157782385825448\n",
      "epochs =  1 , step =  32000 ,  loss_val =  0.6645864073456843\n",
      "epochs =  1 , step =  33000 ,  loss_val =  0.8998422772643182\n",
      "epochs =  1 , step =  34000 ,  loss_val =  0.7223753865386251\n",
      "epochs =  1 , step =  35000 ,  loss_val =  0.7370179136934232\n",
      "epochs =  1 , step =  36000 ,  loss_val =  0.7833176877201944\n",
      "epochs =  1 , step =  37000 ,  loss_val =  0.6638620187455475\n",
      "epochs =  1 , step =  38000 ,  loss_val =  0.6762878176693022\n",
      "epochs =  1 , step =  39000 ,  loss_val =  0.8658610089646235\n",
      "epochs =  1 , step =  40000 ,  loss_val =  0.7435117170041206\n",
      "epochs =  1 , step =  41000 ,  loss_val =  0.7874856354142761\n",
      "epochs =  1 , step =  42000 ,  loss_val =  0.7156771086518515\n",
      "epochs =  1 , step =  43000 ,  loss_val =  0.9007844063817327\n",
      "epochs =  1 , step =  44000 ,  loss_val =  0.8294928329580886\n",
      "epochs =  1 , step =  45000 ,  loss_val =  0.777432755631543\n",
      "epochs =  1 , step =  46000 ,  loss_val =  0.7273101366623878\n",
      "epochs =  1 , step =  47000 ,  loss_val =  0.72902250710649\n",
      "epochs =  1 , step =  48000 ,  loss_val =  0.7623689419343549\n",
      "epochs =  1 , step =  49000 ,  loss_val =  0.6830003347629611\n",
      "epochs =  1 , step =  50000 ,  loss_val =  0.821922138621032\n",
      "epochs =  1 , step =  51000 ,  loss_val =  0.7859300747783539\n",
      "epochs =  1 , step =  52000 ,  loss_val =  0.7240794495342078\n",
      "epochs =  1 , step =  53000 ,  loss_val =  0.8060129106315657\n",
      "epochs =  1 , step =  54000 ,  loss_val =  0.6874835720479079\n",
      "epochs =  1 , step =  55000 ,  loss_val =  0.7153417094191897\n",
      "epochs =  1 , step =  56000 ,  loss_val =  0.7488371487232852\n",
      "epochs =  1 , step =  57000 ,  loss_val =  0.7837679391854756\n",
      "epochs =  1 , step =  58000 ,  loss_val =  0.7553543706704416\n",
      "epochs =  1 , step =  59000 ,  loss_val =  0.7463195402896775\n",
      "\n",
      "elapsed time =  0:00:44.880016\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "\n",
    "hidden_nodes_1 = 40\n",
    "hidden_nodes_2 = 40\n",
    "\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 2\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes_1, hidden_nodes_2, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        #target_data = training_data[step, 0]\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        #input_data = training_data[step, 1:]\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \",  loss_val = \", nn.loss_val())\n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Current Accuracy =  0.9468\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "test_data = np.loadtxt('./(191116)mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "test_input_data = test_data[ : , 1: ]\n",
    "test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "# measure accuracy\n",
    "(true_list, false_list, index_label_prediction_list) = nn.accuracy(test_input_data, test_target_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
