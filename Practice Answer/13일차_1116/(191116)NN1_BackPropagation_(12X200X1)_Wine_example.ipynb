{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    \n",
    "    # target_position = 0 (첫번째열이 정답데이터), target_position=-1 (마지막열이 정답데이터)\n",
    "    def __init__(self, name, file_path, seperation_rate, target_position=-1):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.seperation_rate = seperation_rate\n",
    "        \n",
    "        if (target_position == -1  or  target_position == 0):      \n",
    "            self.target_position = target_position\n",
    "        \n",
    "        else:\n",
    "            err_str = 'target_position must be -1 or 0'            \n",
    "            raise Exception(err_str)    \n",
    "            \n",
    "    \n",
    "    # print data target distribution \n",
    "    # str_of_kind : 'original data' or  'training data'  or  'test data'\n",
    "    def print_target_distribution(self, data, str_of_kind='original data'):\n",
    "        \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        target_data = data[ :, self.target_position ]\n",
    "        \n",
    "        # numpy.unique() 사용하여 loaded data target 분포 확인\n",
    "        unique, counts = np.unique(target_data, return_counts=True)\n",
    "\n",
    "        print('[DataGeneration]  ', str_of_kind, ' target value = ', dict(zip(unique, counts)).items())\n",
    "\n",
    "        num_zeros = dict(zip(unique, counts))[0.0]  # key 0.0 에 대한 value 값 count 리턴\n",
    "        num_ones = dict(zip(unique, counts))[1.0]  # key 1.0 에 대한 value 값 count 리턴\n",
    "\n",
    "        print('[DataGeneration]  ', str_of_kind, ' zeros numbers = ', num_zeros, ', ratio = ', 100 * num_zeros / (data.shape[0]), ' %')\n",
    "        print('[DataGeneration]  ', str_of_kind, ' ones numbers = ', num_ones, ', ratio = ', 100 * num_ones / (data.shape[0]), '%') \n",
    "    \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        \n",
    "    # shuffle 기능을 이용하여 training_data / test_data 생성\n",
    "    def generate(self):\n",
    "    \n",
    "        # 데이터 불러오기, 파일이 없는 경우 exception 발생\n",
    "\n",
    "        try:\n",
    "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "\n",
    "        print(\"[DataGeneration]  loaded_data.shape = \", loaded_data.shape)\n",
    "            \n",
    "        # print the target distribution of original data \n",
    "        \n",
    "        self.print_target_distribution(loaded_data, 'original data')\n",
    "        \n",
    "        \n",
    "        # random.shuffle() 이용한 데이터 인덱스 분리 및 트레이닝/테스트 데이터 생성\n",
    "        \n",
    "        # 임시 저장 리스트\n",
    "        training_data_list = []\n",
    "        test_data_list = []\n",
    "\n",
    "        # 분리비율에 맞게 테스트데이터로 분리\n",
    "        total_data_num = len(loaded_data)\n",
    "        test_data_num = int(len(loaded_data) * self.seperation_rate)\n",
    "\n",
    "        #print(\"[DataGeneration]  total_data_num = \", total_data_num, \", test_data_num = \", test_data_num)\n",
    "\n",
    "        # 전체 데이터 인덱스를 가지고 있는 리스트 생성\n",
    "        total_data_index_list = [ index for index in range(total_data_num) ]\n",
    "\n",
    "        # random.shuffle 을 이용하여 인덱스 리스트 생성\n",
    "        random.shuffle(total_data_index_list)  # 전체 인덱스가 랜덤하게 섞여진 리스트로 변형된다\n",
    "\n",
    "        # test data 를 위한 인덱스는 total_data_index_list 로뷰터 앞에서 분리비율(seperation_rate)의 데이터 인덱스\n",
    "        test_data_index_list = total_data_index_list[ 0:test_data_num ]\n",
    "\n",
    "        #print(\"[DataGeneration]  length of test_data_index_list = \", len(test_data_index_list))\n",
    "\n",
    "        # training data 를 위한 인덱스는 total_data_index_list 에서 test data 인덱스를 제외한 나머지 부분\n",
    "        training_data_index_list = total_data_index_list[ test_data_num: ]\n",
    "\n",
    "        #print(\"[DataGeneration]  length of training_data_index_list = \", len(training_data_index_list))\n",
    "\n",
    "        # training data 구성\n",
    "        for training_data_index in training_data_index_list:\n",
    "    \n",
    "            training_data_list.append(loaded_data[training_data_index])\n",
    "\n",
    "        # test data 구성\n",
    "        for test_data_index in test_data_index_list:\n",
    "    \n",
    "            test_data_list.append(loaded_data[test_data_index])\n",
    "\n",
    "        # generate training data from training_data_list using np.arrya(...)\n",
    "        training_data = np.array(training_data_list)\n",
    "\n",
    "        # generate test data from test_data_list using np.arrya(...)\n",
    "        test_data = np.array(test_data_list)\n",
    "\n",
    "        # verification shape\n",
    "        #print(\"[DataGeneration]  training_data.shape = \", training_data.shape)\n",
    "        #print(\"[DataGeneration]  test_data.shape = \", test_data.shape)\n",
    "\n",
    "        # print target distribution of generated data \n",
    "        \n",
    "        self.print_target_distribution(training_data, 'training data')\n",
    "        \n",
    "        self.print_target_distribution(test_data, 'test data')\n",
    "        \n",
    "        \n",
    "        # save training & test data (.csv)\n",
    "        training_data_save_path = './' + self.name + '_training_data.csv'\n",
    "        test_data_save_path = './' + self.name + '_test_data.csv'\n",
    "        \n",
    "        # 저장공간이 없거나 파일 write 실패시 exception 발생\n",
    "        try:\n",
    "            np.savetxt(training_data_save_path, training_data, delimiter=',')\n",
    "            np.savetxt(test_data_save_path, test_data, delimiter=',')\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "        \n",
    "        return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "class Wine:\n",
    "    \n",
    "    def __init__(self, name, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # 은닉층 가중치  W2 = Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)      \n",
    "        \n",
    "        # 출력층 가중치는 W3 =  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)      \n",
    "                        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,output_nodes])\n",
    "        self.A3 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes])\n",
    "        self.A2 = np.zeros([1,hidden_nodes])\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])       \n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # name 초기화\n",
    "        self.name = name\n",
    "        \n",
    "        print(self.name, \" object is created !!!\")\n",
    "        \n",
    "    def feed_forward(self):  \n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        return  -np.sum( self.target_data*np.log(self.A3 + delta) + (1-self.target_data)*np.log((1 - self.A3)+delta ) )    \n",
    "    \n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        return  -np.sum( self.target_data*np.log(self.A3 + delta) + (1-self.target_data)*np.log((1 - self.A3)+delta ) )\n",
    "    \n",
    "    # accuracy method\n",
    "    def accuracy(self, input_data, target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        # list which contains (index, label, prediction) value\n",
    "        index_label_prediction_list = []\n",
    "        \n",
    "        temp_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "            \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌\n",
    "            (real_val, predicted_num) = self.predict(np.array(input_data[index], ndmin=2)) \n",
    "            \n",
    "            if predicted_num == target_data[index]:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                temp_list.append(index)\n",
    "                temp_list.append(target_data[index])\n",
    "                temp_list.append(predicted_num)\n",
    "                \n",
    "                index_label_prediction_list.append(temp_list)\n",
    "                \n",
    "                temp_list = []\n",
    "                \n",
    "        accuracy_result = len(matched_list) / len(input_data)\n",
    "            \n",
    "        print(\"Accuracy => \", accuracy_result)\n",
    "            \n",
    "        return matched_list, not_matched_list, index_label_prediction_list\n",
    "    \n",
    "    # train method\n",
    "    def train(self, input_data, target_data):   \n",
    "        \n",
    "        self.target_data = target_data    \n",
    "        self.input_data = input_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()\n",
    "        \n",
    "        # 출력층 loss 인 loss_3 구함\n",
    "        loss_3 = (self.A3-self.target_data) * self.A3 * (1-self.A3)\n",
    "                        \n",
    "        # 출력층 가중치 W3, 출력층 바이어스 b3 업데이트\n",
    "        self.W3 = self.W3 - self.learning_rate * np.dot(self.A2.T, loss_3)   \n",
    "        \n",
    "        self.b3 = self.b3 - self.learning_rate * loss_3\n",
    "        \n",
    "        # 은닉층 loss 인 loss_2 구함        \n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        # 은닉층 가중치 W2, 은닉층 바이어스 b2 업데이트\n",
    "        self.W2 = self.W2 - self.learning_rate * np.dot(self.A1.T, loss_2)   \n",
    "        \n",
    "        self.b2 = self.b2 - self.learning_rate * loss_2\n",
    "        \n",
    "    def predict(self, input_data):        # input_data 는 행렬로 입력됨     \n",
    "        \n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        y = A3 = sigmoid(Z3)\n",
    "        \n",
    "        if y >= 0.5:\n",
    "            predicted_num = 1\n",
    "        else:\n",
    "            predicted_num = 0\n",
    "    \n",
    "        return y, predicted_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataGeneration class 이용하여 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataGeneration]  loaded_data.shape =  (6497, 13)\n",
      "=======================================================================================================\n",
      "[DataGeneration]   original data  target value =  dict_items([(0.0, 4898), (1.0, 1599)])\n",
      "[DataGeneration]   original data  zeros numbers =  4898 , ratio =  75.38864091118978  %\n",
      "[DataGeneration]   original data  ones numbers =  1599 , ratio =  24.61135908881022 %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration]   training data  target value =  dict_items([(0.0, 2932), (1.0, 967)])\n",
      "[DataGeneration]   training data  zeros numbers =  2932 , ratio =  75.19876891510644  %\n",
      "[DataGeneration]   training data  ones numbers =  967 , ratio =  24.801231084893562 %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration]   test data  target value =  dict_items([(0.0, 1966), (1.0, 632)])\n",
      "[DataGeneration]   test data  zeros numbers =  1966 , ratio =  75.67359507313319  %\n",
      "[DataGeneration]   test data  ones numbers =  632 , ratio =  24.32640492686682 %\n",
      "=======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# DataGeneration 객체 생성\n",
    "seperation_rate = 0.4    # training data : test data = 6 : 4\n",
    "target_position = -1\n",
    "\n",
    "try:\n",
    "    data_obj = DataGeneration('Wine', './(191116)wine.csv', seperation_rate, target_position)  \n",
    "    (training_data, test_data) = data_obj.generate()\n",
    "    \n",
    "except Exception as err:\n",
    "    print('Exception Occur !!')\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper-parameter 설정 및 train 을 이용한 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine  object is created !!!\n",
      "Neural Network Learning using BackPropagation...\n",
      "epochs =  0 loss value =  1.1711017873591443\n",
      "epochs =  10 loss value =  0.2784971532480516\n",
      "epochs =  20 loss value =  0.2313730288638357\n",
      "epochs =  30 loss value =  0.22000933048078586\n",
      "epochs =  40 loss value =  0.21352063054335918\n",
      "epochs =  50 loss value =  0.2071264358091828\n",
      "epochs =  60 loss value =  0.1996751798439996\n",
      "epochs =  70 loss value =  0.19144440341892358\n",
      "epochs =  80 loss value =  0.18335915016794846\n",
      "epochs =  90 loss value =  0.17597423253974132\n",
      "epochs =  100 loss value =  0.16935629756230489\n",
      "epochs =  110 loss value =  0.1633950071839928\n",
      "epochs =  120 loss value =  0.1579655112038056\n",
      "epochs =  130 loss value =  0.15296550505257522\n",
      "epochs =  140 loss value =  0.14831847528319939\n",
      "epochs =  150 loss value =  0.14396918237060102\n",
      "epochs =  160 loss value =  0.13987711747634235\n",
      "epochs =  170 loss value =  0.13601132899929444\n",
      "epochs =  180 loss value =  0.13234652076794914\n",
      "epochs =  190 loss value =  0.1288593372623944\n",
      "\n",
      "Elapsed Time =>  0:01:43.868314\n"
     ]
    }
   ],
   "source": [
    "#hyper-parameter\n",
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 200  # hidden nodes 개수, \n",
    "o_nodes = 1    # output nodes 개수\n",
    "lr = 1e-5      # learning rate\n",
    "epochs = 200   # 반복횟수\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성\n",
    "loss_val_list = []\n",
    "\n",
    "# Wine 객체 생성\n",
    "wine_obj = Wine('Wine', i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "print(\"Neural Network Learning using BackPropagation...\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epochs):\n",
    "    \n",
    "    for index in range(len(training_data)):\n",
    "        \n",
    "        input_data = training_data[index, 0:-1]\n",
    "        target_data = training_data[index, [-1]]\n",
    "        \n",
    "        wine_obj.train( np.array(input_data, ndmin=2), np.array([target_data], ndmin=2) )  # 행렬로 입력\n",
    "        \n",
    "    if step % 10 == 0:\n",
    "        print(\"epochs = \", step, \"loss value = \", wine_obj.loss_val())\n",
    "        \n",
    "    # 손실함수 값 저장\n",
    "    loss_val_list.append(wine_obj.loss_val()) \n",
    "    \n",
    "\n",
    "end_time = datetime.now()\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =>  0.9207082371054658\n"
     ]
    }
   ],
   "source": [
    "test_input_data = test_data[ :, 0:-1 ]\n",
    "test_target_data = test_data[ :, -1 ]\n",
    "\n",
    "(true_list, false_list, index_label_prediction_list) = wine_obj.accuracy(test_input_data, test_target_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 1.0, 0], [16, 0.0, 1], [19, 0.0, 1], [24, 1.0, 0], [26, 1.0, 0], [42, 1.0, 0], [54, 1.0, 0], [85, 1.0, 0], [87, 1.0, 0], [89, 1.0, 0], [90, 1.0, 0], [108, 1.0, 0], [113, 1.0, 0], [143, 1.0, 0], [146, 1.0, 0], [150, 1.0, 0], [151, 1.0, 0], [189, 1.0, 0], [197, 1.0, 0], [198, 1.0, 0], [200, 1.0, 0], [212, 1.0, 0], [218, 1.0, 0], [223, 0.0, 1], [233, 1.0, 0], [256, 0.0, 1], [270, 1.0, 0], [282, 1.0, 0], [291, 1.0, 0], [293, 1.0, 0], [294, 1.0, 0], [320, 1.0, 0], [338, 1.0, 0], [348, 1.0, 0], [370, 1.0, 0], [391, 0.0, 1], [392, 1.0, 0], [422, 1.0, 0], [432, 1.0, 0], [456, 1.0, 0], [484, 1.0, 0], [495, 1.0, 0], [521, 1.0, 0], [522, 1.0, 0], [525, 1.0, 0], [527, 1.0, 0], [547, 1.0, 0], [558, 1.0, 0], [589, 1.0, 0], [606, 1.0, 0], [609, 1.0, 0], [634, 1.0, 0], [644, 1.0, 0], [649, 1.0, 0], [655, 1.0, 0], [657, 0.0, 1], [668, 1.0, 0], [671, 1.0, 0], [684, 1.0, 0], [688, 1.0, 0], [702, 1.0, 0], [716, 1.0, 0], [729, 1.0, 0], [753, 1.0, 0], [761, 1.0, 0], [773, 1.0, 0], [779, 0.0, 1], [788, 1.0, 0], [790, 1.0, 0], [803, 1.0, 0], [810, 1.0, 0], [821, 1.0, 0], [830, 1.0, 0], [845, 1.0, 0], [846, 1.0, 0], [866, 1.0, 0], [884, 1.0, 0], [928, 1.0, 0], [946, 1.0, 0], [947, 1.0, 0], [954, 1.0, 0], [1015, 0.0, 1], [1034, 1.0, 0], [1041, 1.0, 0], [1059, 1.0, 0], [1093, 1.0, 0], [1096, 1.0, 0], [1099, 1.0, 0], [1107, 1.0, 0], [1121, 1.0, 0], [1123, 1.0, 0], [1128, 1.0, 0], [1133, 1.0, 0], [1165, 1.0, 0], [1198, 1.0, 0], [1204, 1.0, 0], [1217, 1.0, 0], [1225, 1.0, 0], [1230, 1.0, 0], [1233, 1.0, 0], [1239, 1.0, 0], [1249, 1.0, 0], [1250, 1.0, 0], [1274, 1.0, 0], [1278, 0.0, 1], [1279, 0.0, 1], [1287, 0.0, 1], [1324, 0.0, 1], [1344, 1.0, 0], [1350, 1.0, 0], [1362, 1.0, 0], [1383, 1.0, 0], [1386, 0.0, 1], [1389, 1.0, 0], [1393, 1.0, 0], [1398, 1.0, 0], [1411, 1.0, 0], [1440, 1.0, 0], [1459, 1.0, 0], [1463, 1.0, 0], [1472, 1.0, 0], [1482, 1.0, 0], [1514, 1.0, 0], [1527, 1.0, 0], [1529, 1.0, 0], [1530, 1.0, 0], [1551, 1.0, 0], [1590, 0.0, 1], [1627, 1.0, 0], [1650, 1.0, 0], [1652, 1.0, 0], [1658, 1.0, 0], [1659, 1.0, 0], [1701, 1.0, 0], [1707, 1.0, 0], [1713, 1.0, 0], [1740, 1.0, 0], [1745, 1.0, 0], [1750, 1.0, 0], [1752, 1.0, 0], [1768, 1.0, 0], [1788, 1.0, 0], [1810, 1.0, 0], [1827, 1.0, 0], [1852, 1.0, 0], [1858, 1.0, 0], [1867, 1.0, 0], [1898, 1.0, 0], [1906, 1.0, 0], [1929, 1.0, 0], [1943, 0.0, 1], [1950, 0.0, 1], [1970, 1.0, 0], [1971, 1.0, 0], [1976, 1.0, 0], [1987, 1.0, 0], [1988, 1.0, 0], [2002, 1.0, 0], [2006, 1.0, 0], [2029, 1.0, 0], [2056, 0.0, 1], [2079, 1.0, 0], [2098, 1.0, 0], [2099, 0.0, 1], [2104, 1.0, 0], [2108, 1.0, 0], [2113, 1.0, 0], [2130, 1.0, 0], [2156, 1.0, 0], [2160, 1.0, 0], [2173, 1.0, 0], [2183, 1.0, 0], [2213, 1.0, 0], [2227, 1.0, 0], [2230, 1.0, 0], [2266, 1.0, 0], [2271, 1.0, 0], [2276, 1.0, 0], [2297, 1.0, 0], [2299, 1.0, 0], [2306, 0.0, 1], [2308, 1.0, 0], [2320, 1.0, 0], [2343, 1.0, 0], [2349, 1.0, 0], [2351, 1.0, 0], [2356, 1.0, 0], [2363, 1.0, 0], [2391, 1.0, 0], [2408, 1.0, 0], [2426, 1.0, 0], [2435, 1.0, 0], [2440, 1.0, 0], [2505, 1.0, 0], [2510, 1.0, 0], [2525, 1.0, 0], [2540, 1.0, 0], [2551, 1.0, 0], [2558, 0.0, 1], [2560, 0.0, 1], [2561, 1.0, 0], [2562, 1.0, 0], [2563, 1.0, 0], [2565, 1.0, 0], [2572, 1.0, 0], [2590, 1.0, 0]]\n",
      "\n",
      "number of false =>  206\n"
     ]
    }
   ],
   "source": [
    "print(index_label_prediction_list)\n",
    "\n",
    "print('\\nnumber of false => ', len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수 추세 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(len(loss_val_list))\n",
    "\n",
    "# 손실함수 추세 확인\n",
    "Y_DATA_LIST = []\n",
    "\n",
    "for index in range(0, len(loss_val_list)):\n",
    "    Y_DATA_LIST.append(loss_val_list[index])\n",
    "    \n",
    "plt.title('WINE Loss Value Trend')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss value')\n",
    "plt.grid()\n",
    "plt.plot(Y_DATA_LIST, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
