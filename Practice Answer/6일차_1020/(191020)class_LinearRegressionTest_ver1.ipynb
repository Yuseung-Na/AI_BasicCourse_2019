{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 를 이용하여 (191020)data-01.csv 선형회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class LinearRegressionTest:\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, xdata, tdata, learning_rate, iteration_count):\n",
    "        \n",
    "        self.xdata = xdata\n",
    "        self.tdata = tdata\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        \n",
    "        self.W = np.random.rand(self.xdata.shape[1], 1)   # 입력 xdata가 이미 행렬이라 가정한 구현\n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "        print(\"LinearRegressionTest Object is created\")\n",
    "        \n",
    "    \n",
    "    # obtain current W and current b\n",
    "    def getW_b(self):\n",
    "        \n",
    "        return self.W, self.b\n",
    "    \n",
    "    \n",
    "    # loss function\n",
    "    def loss_func(self):\n",
    "        \n",
    "        y = np.dot(self.xdata, self.W) + self.b\n",
    "    \n",
    "        return ( np.sum( (self.tdata - y)**2 ) ) / ( len(self.xdata) )\n",
    "        \n",
    "    \n",
    "    # display current error value\n",
    "    def error_val(self):\n",
    "        \n",
    "        y = np.dot(self.xdata, self.W) + self.b\n",
    "    \n",
    "        return ( np.sum( (self.tdata - y)**2 ) ) / ( len(self.xdata) )\n",
    "    \n",
    "    \n",
    "    # predict method\n",
    "    def predict(self, test_data):\n",
    "        \n",
    "        y = np.dot(test_data, self.W) + self.b\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    # train method\n",
    "    def train(self):\n",
    "    \n",
    "        f = lambda x : self.loss_func()\n",
    "\n",
    "        print(\"Initial error value = \", self.error_val(), \"Initial W = \", self.W, \"\\n\", \", b = \", self.b )\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        for step in  range(self.iteration_count):  \n",
    "    \n",
    "            self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
    "    \n",
    "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "    \n",
    "            if (step % 400 == 0):\n",
    "                print(\"step = \", step, \"error value = \", self.error_val(), \"W = \", self.W, \", b = \", self.b )\n",
    "                \n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (25, 3)\n",
      "t_data.ndim =  2 , t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "loaded_data = np.loadtxt('./(191020)data-01.csv', delimiter=',', dtype=np.float32) \n",
    "\n",
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]]\n",
    "\n",
    "# 데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionTest Object is created\n",
      "Initial error value =  80.0443340449435 Initial W =  [[0.71782409]\n",
      " [0.90918656]\n",
      " [0.49593372]] \n",
      " , b =  [0.31534424]\n",
      "step =  0 error value =  41.98309583076509 W =  [[0.70531973]\n",
      " [0.89651672]\n",
      " [0.48342552]] , b =  [0.31525087]\n",
      "step =  400 error value =  15.815999577389768 W =  [[0.65259865]\n",
      " [0.80972964]\n",
      " [0.56200496]] , b =  [0.31511431]\n",
      "step =  800 error value =  13.085743626887101 W =  [[0.62265853]\n",
      " [0.75432013]\n",
      " [0.64525037]] , b =  [0.31501563]\n",
      "step =  1200 error value =  11.143424417037037 W =  [[0.59584766]\n",
      " [0.70886581]\n",
      " [0.71572738]] , b =  [0.31482615]\n",
      "step =  1600 error value =  9.758497402529713 W =  [[0.57182253]\n",
      " [0.67165651]\n",
      " [0.77544087]] , b =  [0.31455972]\n",
      "step =  2000 error value =  8.76846366283993 W =  [[0.5502798 ]\n",
      " [0.64126909]\n",
      " [0.8260762 ]] , b =  [0.31422804]\n",
      "step =  2400 error value =  8.058676766818818 W =  [[0.53095122]\n",
      " [0.61651986]\n",
      " [0.86905068]] , b =  [0.31384099]\n",
      "step =  2800 error value =  7.548162219538931 W =  [[0.51359929]\n",
      " [0.59642485]\n",
      " [0.90555655]] , b =  [0.31340688]\n",
      "step =  3200 error value =  7.179655550494673 W =  [[0.49801348]\n",
      " [0.58016665]\n",
      " [0.93659713]] , b =  [0.31293278]\n",
      "step =  3600 error value =  6.912601019278331 W =  [[0.48400697]\n",
      " [0.56706662]\n",
      " [0.96301707]] , b =  [0.31242464]\n",
      "step =  4000 error value =  6.7182286118805425 W =  [[0.47141376]\n",
      " [0.5565618 ]\n",
      " [0.98552776]] , b =  [0.3118875]\n",
      "step =  4400 error value =  6.576090399978855 W =  [[0.46008622]\n",
      " [0.54818555]\n",
      " [1.00472865]] , b =  [0.31132563]\n",
      "step =  4800 error value =  6.471622021390118 W =  [[0.4498929 ]\n",
      " [0.54155143]\n",
      " [1.02112506]] , b =  [0.31074265]\n",
      "step =  5200 error value =  6.394424549559279 W =  [[0.44071668]\n",
      " [0.53633972]\n",
      " [1.03514321]] , b =  [0.31014163]\n",
      "step =  5600 error value =  6.337052849836344 W =  [[0.43245306]\n",
      " [0.53228623]\n",
      " [1.04714282]] , b =  [0.30952517]\n",
      "step =  6000 error value =  6.294160232518384 W =  [[0.42500877]\n",
      " [0.52917287]\n",
      " [1.05742761]] , b =  [0.3088955]\n",
      "step =  6400 error value =  6.261893911374515 W =  [[0.41830043]\n",
      " [0.5268199 ]\n",
      " [1.06625423]] , b =  [0.3082545]\n",
      "step =  6800 error value =  6.237467142410811 W =  [[0.41225351]\n",
      " [0.52507938]\n",
      " [1.07383968]] , b =  [0.30760377]\n",
      "step =  7200 error value =  6.2188559332427635 W =  [[0.40680129]\n",
      " [0.52382977]\n",
      " [1.08036754]] , b =  [0.30694467]\n",
      "step =  7600 error value =  6.204583670476586 W =  [[0.40188402]\n",
      " [0.52297139]\n",
      " [1.08599328]] , b =  [0.30627839]\n",
      "step =  8000 error value =  6.19356786841953 W =  [[0.39744815]\n",
      " [0.52242268]\n",
      " [1.09084861]] , b =  [0.30560591]\n",
      "step =  8400 error value =  6.185010869812 W =  [[0.39344567]\n",
      " [0.52211707]\n",
      " [1.09504527]] , b =  [0.30492809]\n",
      "step =  8800 error value =  6.178321690692202 W =  [[0.38983349]\n",
      " [0.52200037]\n",
      " [1.09867807]] , b =  [0.30424566]\n",
      "step =  9200 error value =  6.173059972107842 W =  [[0.38657291]\n",
      " [0.52202858]\n",
      " [1.10182758]] , b =  [0.30355924]\n",
      "step =  9600 error value =  6.168895654809733 W =  [[0.3836292 ]\n",
      " [0.52216616]\n",
      " [1.10456233]] , b =  [0.30286938]\n",
      "step =  10000 error value =  6.165579861621535 W =  [[0.3809711 ]\n",
      " [0.52238448]\n",
      " [1.10694062]] , b =  [0.30217654]\n",
      "\n",
      "Elapsed Time =>  0:00:02.645927\n"
     ]
    }
   ],
   "source": [
    "# LinearRegressionTest 객체를 만들기 위해 4개의 파라미터 필요\n",
    "# 1st : 입력데이터,  2nd : 정답데이터\n",
    "# 3rd : learning rate,  4th : iteration count\n",
    "obj = LinearRegressionTest(x_data, t_data, 1e-5, 10001)\n",
    "\n",
    "obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.255156])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "obj.predict(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.3809711 ]\n",
      " [0.52238448]\n",
      " [1.10694062]] , b =  [0.30217654]\n"
     ]
    }
   ],
   "source": [
    "(W, b) = obj.getW_b()\n",
    "\n",
    "print(\"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
