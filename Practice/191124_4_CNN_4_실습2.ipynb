{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 5x5x32 필터 \n",
    "## 3x3 에서 5x5 필터로 변경 -> 정확도 소폭 상승, 속도 느려짐\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "b2 = tf.Variable(tf.random_normal([32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 x 14 크기를 가진 32개의 activation map을 flatten 시킴\n",
    "A2_flat = P2_flat = tf.reshape(A2, [-1, 14*14*32])  # 행렬로 변환, -1 : 행은 상관 없고, 14*14*32 : 열은 이거를 만족하게 만들어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W3 = tf.Variable(tf.random_normal([14*14*32, 10], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀 값 Z3, 즉 softmax 에 들어가는 입력 값\n",
    "Z3 = logits = tf.matmul(A2_flat, W3) + b3\n",
    "\n",
    "y = A3 = tf.nn.softmax(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z3, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)  # GradientDecent 방식을 사용하면 정답률이 91 정도로 떨어짐\n",
    "## Adam(momentum)방식이 mnist 데이터에 잘 맞게 tf가 최적화 되어 있음.\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A3, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  3.087182\n",
      "epochs =  0 , step =  100 , loss_val =  0.7460567\n",
      "epochs =  0 , step =  200 , loss_val =  0.38480923\n",
      "epochs =  0 , step =  300 , loss_val =  0.17304802\n",
      "epochs =  0 , step =  400 , loss_val =  0.36199737\n",
      "epochs =  0 , step =  500 , loss_val =  0.17054419\n",
      "epochs =  1 , step =  0 , loss_val =  0.13562462\n",
      "epochs =  1 , step =  100 , loss_val =  0.14368881\n",
      "epochs =  1 , step =  200 , loss_val =  0.071264476\n",
      "epochs =  1 , step =  300 , loss_val =  0.25870663\n",
      "epochs =  1 , step =  400 , loss_val =  0.1732844\n",
      "epochs =  1 , step =  500 , loss_val =  0.18799913\n",
      "epochs =  2 , step =  0 , loss_val =  0.08410185\n",
      "epochs =  2 , step =  100 , loss_val =  0.13711613\n",
      "epochs =  2 , step =  200 , loss_val =  0.18638542\n",
      "epochs =  2 , step =  300 , loss_val =  0.15195832\n",
      "epochs =  2 , step =  400 , loss_val =  0.054620024\n",
      "epochs =  2 , step =  500 , loss_val =  0.041934785\n",
      "epochs =  3 , step =  0 , loss_val =  0.06696386\n",
      "epochs =  3 , step =  100 , loss_val =  0.12775813\n",
      "epochs =  3 , step =  200 , loss_val =  0.104113065\n",
      "epochs =  3 , step =  300 , loss_val =  0.037803266\n",
      "epochs =  3 , step =  400 , loss_val =  0.04854653\n",
      "epochs =  3 , step =  500 , loss_val =  0.062087417\n",
      "epochs =  4 , step =  0 , loss_val =  0.031123623\n",
      "epochs =  4 , step =  100 , loss_val =  0.02147218\n",
      "epochs =  4 , step =  200 , loss_val =  0.13016093\n",
      "epochs =  4 , step =  300 , loss_val =  0.10053489\n",
      "epochs =  4 , step =  400 , loss_val =  0.11199238\n",
      "epochs =  4 , step =  500 , loss_val =  0.051085245\n",
      "epochs =  5 , step =  0 , loss_val =  0.02590966\n",
      "epochs =  5 , step =  100 , loss_val =  0.04161854\n",
      "epochs =  5 , step =  200 , loss_val =  0.091025114\n",
      "epochs =  5 , step =  300 , loss_val =  0.033964213\n",
      "epochs =  5 , step =  400 , loss_val =  0.040779926\n",
      "epochs =  5 , step =  500 , loss_val =  0.057484087\n",
      "epochs =  6 , step =  0 , loss_val =  0.07142395\n",
      "epochs =  6 , step =  100 , loss_val =  0.03368346\n",
      "epochs =  6 , step =  200 , loss_val =  0.14069116\n",
      "epochs =  6 , step =  300 , loss_val =  0.09657076\n",
      "epochs =  6 , step =  400 , loss_val =  0.115092546\n",
      "epochs =  6 , step =  500 , loss_val =  0.04297366\n",
      "epochs =  7 , step =  0 , loss_val =  0.061994284\n",
      "epochs =  7 , step =  100 , loss_val =  0.06503609\n",
      "epochs =  7 , step =  200 , loss_val =  0.1031773\n",
      "epochs =  7 , step =  300 , loss_val =  0.12716286\n",
      "epochs =  7 , step =  400 , loss_val =  0.1318492\n",
      "epochs =  7 , step =  500 , loss_val =  0.031176686\n",
      "epochs =  8 , step =  0 , loss_val =  0.14438586\n",
      "epochs =  8 , step =  100 , loss_val =  0.023795255\n",
      "epochs =  8 , step =  200 , loss_val =  0.014056947\n",
      "epochs =  8 , step =  300 , loss_val =  0.06326508\n",
      "epochs =  8 , step =  400 , loss_val =  0.019246146\n",
      "epochs =  8 , step =  500 , loss_val =  0.010691344\n",
      "epochs =  9 , step =  0 , loss_val =  0.029844472\n",
      "epochs =  9 , step =  100 , loss_val =  0.05720223\n",
      "epochs =  9 , step =  200 , loss_val =  0.08583501\n",
      "epochs =  9 , step =  300 , loss_val =  0.03194188\n",
      "epochs =  9 , step =  400 , loss_val =  0.06579672\n",
      "epochs =  9 , step =  500 , loss_val =  0.004451221\n",
      "epochs =  10 , step =  0 , loss_val =  0.052003857\n",
      "epochs =  10 , step =  100 , loss_val =  0.054094624\n",
      "epochs =  10 , step =  200 , loss_val =  0.036584273\n",
      "epochs =  10 , step =  300 , loss_val =  0.0732565\n",
      "epochs =  10 , step =  400 , loss_val =  0.038505368\n",
      "epochs =  10 , step =  500 , loss_val =  0.06592049\n",
      "epochs =  11 , step =  0 , loss_val =  0.121371806\n",
      "epochs =  11 , step =  100 , loss_val =  0.048794832\n",
      "epochs =  11 , step =  200 , loss_val =  0.012061206\n",
      "epochs =  11 , step =  300 , loss_val =  0.017670948\n",
      "epochs =  11 , step =  400 , loss_val =  0.057311997\n",
      "epochs =  11 , step =  500 , loss_val =  0.14838552\n",
      "epochs =  12 , step =  0 , loss_val =  0.025557663\n",
      "epochs =  12 , step =  100 , loss_val =  0.024915548\n",
      "epochs =  12 , step =  200 , loss_val =  0.07899828\n",
      "epochs =  12 , step =  300 , loss_val =  0.05354951\n",
      "epochs =  12 , step =  400 , loss_val =  0.051835287\n",
      "epochs =  12 , step =  500 , loss_val =  0.007498499\n",
      "epochs =  13 , step =  0 , loss_val =  0.0066130296\n",
      "epochs =  13 , step =  100 , loss_val =  0.015531543\n",
      "epochs =  13 , step =  200 , loss_val =  0.01190784\n",
      "epochs =  13 , step =  300 , loss_val =  0.022142442\n",
      "epochs =  13 , step =  400 , loss_val =  0.008039001\n",
      "epochs =  13 , step =  500 , loss_val =  0.017600972\n",
      "epochs =  14 , step =  0 , loss_val =  0.13978307\n",
      "epochs =  14 , step =  100 , loss_val =  0.026348764\n",
      "epochs =  14 , step =  200 , loss_val =  0.014196027\n",
      "epochs =  14 , step =  300 , loss_val =  0.0046292753\n",
      "epochs =  14 , step =  400 , loss_val =  0.034879137\n",
      "epochs =  14 , step =  500 , loss_val =  0.03443994\n",
      "epochs =  15 , step =  0 , loss_val =  0.005549755\n",
      "epochs =  15 , step =  100 , loss_val =  0.042204853\n",
      "epochs =  15 , step =  200 , loss_val =  0.038132418\n",
      "epochs =  15 , step =  300 , loss_val =  0.028130895\n",
      "epochs =  15 , step =  400 , loss_val =  0.006068958\n",
      "epochs =  15 , step =  500 , loss_val =  0.046151865\n",
      "epochs =  16 , step =  0 , loss_val =  0.032441508\n",
      "epochs =  16 , step =  100 , loss_val =  0.021676525\n",
      "epochs =  16 , step =  200 , loss_val =  0.041911725\n",
      "epochs =  16 , step =  300 , loss_val =  0.10544424\n",
      "epochs =  16 , step =  400 , loss_val =  0.043222185\n",
      "epochs =  16 , step =  500 , loss_val =  0.006810652\n",
      "epochs =  17 , step =  0 , loss_val =  0.023682924\n",
      "epochs =  17 , step =  100 , loss_val =  0.006783171\n",
      "epochs =  17 , step =  200 , loss_val =  0.017404925\n",
      "epochs =  17 , step =  300 , loss_val =  0.046852008\n",
      "epochs =  17 , step =  400 , loss_val =  0.04963914\n",
      "epochs =  17 , step =  500 , loss_val =  0.02400256\n",
      "epochs =  18 , step =  0 , loss_val =  0.027933322\n",
      "epochs =  18 , step =  100 , loss_val =  0.0016427335\n",
      "epochs =  18 , step =  200 , loss_val =  0.006582913\n",
      "epochs =  18 , step =  300 , loss_val =  0.004151711\n",
      "epochs =  18 , step =  400 , loss_val =  0.0039867647\n",
      "epochs =  18 , step =  500 , loss_val =  0.10416689\n",
      "epochs =  19 , step =  0 , loss_val =  0.023089902\n",
      "epochs =  19 , step =  100 , loss_val =  0.009959029\n",
      "epochs =  19 , step =  200 , loss_val =  0.032488775\n",
      "epochs =  19 , step =  300 , loss_val =  0.0029145854\n",
      "epochs =  19 , step =  400 , loss_val =  0.0042581423\n",
      "epochs =  19 , step =  500 , loss_val =  0.014474351\n",
      "epochs =  20 , step =  0 , loss_val =  0.011056565\n",
      "epochs =  20 , step =  100 , loss_val =  0.0058566737\n",
      "epochs =  20 , step =  200 , loss_val =  0.022532763\n",
      "epochs =  20 , step =  300 , loss_val =  0.0030909753\n",
      "epochs =  20 , step =  400 , loss_val =  0.03313365\n",
      "epochs =  20 , step =  500 , loss_val =  0.0023134714\n",
      "epochs =  21 , step =  0 , loss_val =  0.0036168622\n",
      "epochs =  21 , step =  100 , loss_val =  0.0038767147\n",
      "epochs =  21 , step =  200 , loss_val =  0.020126225\n",
      "epochs =  21 , step =  300 , loss_val =  0.021900203\n",
      "epochs =  21 , step =  400 , loss_val =  0.0067550153\n",
      "epochs =  21 , step =  500 , loss_val =  0.062554285\n",
      "epochs =  22 , step =  0 , loss_val =  0.0043538767\n",
      "epochs =  22 , step =  100 , loss_val =  0.0065332055\n",
      "epochs =  22 , step =  200 , loss_val =  0.020803237\n",
      "epochs =  22 , step =  300 , loss_val =  0.028890405\n",
      "epochs =  22 , step =  400 , loss_val =  0.0030049533\n",
      "epochs =  22 , step =  500 , loss_val =  0.0036608034\n",
      "epochs =  23 , step =  0 , loss_val =  0.0029035928\n",
      "epochs =  23 , step =  100 , loss_val =  0.005387759\n",
      "epochs =  23 , step =  200 , loss_val =  0.022956353\n",
      "epochs =  23 , step =  300 , loss_val =  0.01173546\n",
      "epochs =  23 , step =  400 , loss_val =  0.0049352427\n",
      "epochs =  23 , step =  500 , loss_val =  0.014868429\n",
      "epochs =  24 , step =  0 , loss_val =  0.0028820068\n",
      "epochs =  24 , step =  100 , loss_val =  0.0039974637\n",
      "epochs =  24 , step =  200 , loss_val =  0.0827623\n",
      "epochs =  24 , step =  300 , loss_val =  0.012636856\n",
      "epochs =  24 , step =  400 , loss_val =  0.0018972155\n",
      "epochs =  24 , step =  500 , loss_val =  0.0052586184\n",
      "epochs =  25 , step =  0 , loss_val =  0.0007724506\n",
      "epochs =  25 , step =  100 , loss_val =  0.01920493\n",
      "epochs =  25 , step =  200 , loss_val =  0.0020128146\n",
      "epochs =  25 , step =  300 , loss_val =  0.0032340703\n",
      "epochs =  25 , step =  400 , loss_val =  0.019690827\n",
      "epochs =  25 , step =  500 , loss_val =  0.005324476\n",
      "epochs =  26 , step =  0 , loss_val =  0.0035470636\n",
      "epochs =  26 , step =  100 , loss_val =  0.0074900035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  26 , step =  200 , loss_val =  0.008039924\n",
      "epochs =  26 , step =  300 , loss_val =  0.0004340519\n",
      "epochs =  26 , step =  400 , loss_val =  0.0053851865\n",
      "epochs =  26 , step =  500 , loss_val =  0.013580528\n",
      "epochs =  27 , step =  0 , loss_val =  0.011003915\n",
      "epochs =  27 , step =  100 , loss_val =  0.019367574\n",
      "epochs =  27 , step =  200 , loss_val =  0.07825925\n",
      "epochs =  27 , step =  300 , loss_val =  0.009204943\n",
      "epochs =  27 , step =  400 , loss_val =  0.023687607\n",
      "epochs =  27 , step =  500 , loss_val =  0.0033341337\n",
      "epochs =  28 , step =  0 , loss_val =  0.02643131\n",
      "epochs =  28 , step =  100 , loss_val =  0.0052691014\n",
      "epochs =  28 , step =  200 , loss_val =  0.008321609\n",
      "epochs =  28 , step =  300 , loss_val =  0.02120716\n",
      "epochs =  28 , step =  400 , loss_val =  0.011981024\n",
      "epochs =  28 , step =  500 , loss_val =  0.0029494837\n",
      "epochs =  29 , step =  0 , loss_val =  0.006886222\n",
      "epochs =  29 , step =  100 , loss_val =  0.0015739957\n",
      "epochs =  29 , step =  200 , loss_val =  0.011465474\n",
      "epochs =  29 , step =  300 , loss_val =  0.0012705949\n",
      "epochs =  29 , step =  400 , loss_val =  0.018569557\n",
      "epochs =  29 , step =  500 , loss_val =  0.0038835937\n",
      "\n",
      "Elapsed Time =>  0:13:37.333224\n",
      "\n",
      "Accuracy = 0.9849\n",
      "length of index_label_list =  10000\n",
      "false label count =  151\n",
      "\n",
      "length of index_label_false_list_1 151\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115, 4, 9], [247, 4, 2], [259, 6, 0], [321, 2, 7], [340, 5, 3], [445, 6, 0], [449, 3, 5], [502, 5, 9], [571, 4, 9], [582, 8, 2], [583, 2, 7], [619, 1, 8], [659, 2, 1], [674, 5, 3], [684, 7, 3], [740, 4, 9], [829, 4, 8], [839, 8, 3], [846, 7, 9], [883, 3, 5], [947, 8, 9], [958, 3, 2], [965, 6, 0], [1014, 6, 5], [1039, 7, 2], [1112, 4, 6], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1290, 3, 5], [1319, 8, 0], [1326, 7, 2], [1393, 5, 3], [1520, 7, 2], [1530, 8, 7], [1549, 4, 6], [1641, 5, 9], [1709, 9, 5], [1717, 8, 0], [1737, 5, 4], [1790, 2, 7], [1878, 8, 3], [1898, 0, 6], [1901, 9, 4], [1982, 6, 8], [2035, 5, 3], [2053, 4, 9], [2093, 8, 2], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2266, 1, 2], [2272, 8, 0], [2293, 9, 4], [2314, 7, 9], [2329, 0, 2], [2369, 5, 3], [2387, 9, 1], [2406, 9, 4], [2447, 4, 9], [2597, 5, 3], [2654, 6, 1], [2713, 0, 8], [2771, 4, 9], [2778, 4, 2], [2836, 4, 9], [2851, 7, 9], [2896, 8, 0], [2907, 4, 9], [2921, 3, 2], [2939, 9, 5], [2953, 3, 5], [2995, 6, 5], [3030, 6, 0], [3225, 7, 9], [3289, 8, 9], [3384, 2, 6], [3451, 7, 9], [3503, 9, 1], [3520, 6, 4], [3558, 5, 0], [3726, 4, 9], [3727, 8, 9], [3808, 7, 8], [3853, 6, 0], [3941, 4, 2], [4007, 7, 4], [4063, 6, 5], [4075, 8, 0], [4201, 1, 7], [4207, 8, 2], [4238, 7, 3], [4248, 2, 1], [4256, 3, 2], [4265, 4, 9], [4382, 4, 9], [4571, 6, 8], [4575, 4, 9], [4578, 7, 9], [4639, 8, 9], [4740, 3, 5], [4783, 4, 9], [4807, 8, 0], [4837, 7, 2], [4838, 6, 5], [4860, 4, 9], [4956, 8, 4], [5159, 4, 9], [5199, 6, 0], [5201, 4, 9], [5228, 6, 4], [5246, 7, 2], [5634, 2, 8], [5745, 7, 1], [5749, 8, 5], [5955, 3, 8], [5973, 3, 8], [5981, 5, 9], [5997, 5, 9], [6091, 9, 5], [6166, 9, 3], [6532, 0, 5], [6560, 9, 5], [6561, 7, 9], [6569, 3, 2], [6571, 9, 7], [6576, 7, 1], [6597, 0, 9], [6651, 0, 8], [7434, 4, 8], [7800, 3, 2], [8246, 3, 9], [8325, 0, 6], [8527, 4, 9], [9009, 7, 2], [9015, 7, 2], [9024, 7, 2], [9342, 3, 2], [9540, 1, 8], [9634, 0, 2], [9679, 6, 2], [9692, 9, 7], [9698, 6, 1], [9729, 5, 6], [9754, 5, 6], [9768, 2, 9], [9770, 5, 0], [9781, 7, 9], [9792, 4, 9], [9800, 0, 9], [9940, 6, 4]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUSEUNG\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\16일차_1124\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "100 image is saved now\n",
      "110 image is saved now\n",
      "120 image is saved now\n",
      "130 image is saved now\n",
      "140 image is saved now\n",
      "150 image is saved now\n",
      "Elapsed save time =>  0:05:35.560733\n",
      "Total  151  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data_실습2'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_1:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
