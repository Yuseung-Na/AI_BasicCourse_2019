{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ver 2의 변화\n",
    "\n",
    "### 1. ver 1의 경우 training data 전체 행에 대한 오차의 평균을 줄이기 위해 w, b를 업데이트 하는 것이 1 번의 수행이다.\n",
    "### 그러나 ver 2의 경우 각각의 행에 대해서 오차를 줄이기 위해 한 행에서 w, b를 업데이트 하고 다음 행에 바로 적용하는 방법을 적용한다. 그렇기 때문에 더 빠르게 오차가 줄어들 수 있다.\n",
    "### 두 방법 모두 결국엔 오차를 줄이는 것이기 때문에 더 빠른 방법을 사용하여 학습 시간을 줄인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diabetes:\n",
    "    \n",
    "    def __init__(self, gate_name, i_node, h1_node, o_node, learning_rate):  \n",
    "        self.name = gate_name\n",
    "        \n",
    "        self.W2 = np.random.rand(i_node, h1_node)             \n",
    "        self.b2 = np.random.rand(h1_node)\n",
    "        \n",
    "        self.W3 = np.random.rand(h1_node, o_node) \n",
    "        self.b3 = np.random.rand(o_node)\n",
    "                        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        print(self.name + \" object is created\")\n",
    "\n",
    "    def feed_forward(self):\n",
    "        delta = 1e-7   \n",
    "        \n",
    "        Z2 = np.dot(self.xdata, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        y = sigmoid(Z3)\n",
    "        \n",
    "        return  -np.sum( self.tdata*np.log(y + delta) + (1-self.tdata)*np.log((1 - y)+delta ) )\n",
    "\n",
    "    def loss_val(self):\n",
    "        delta = 1e-7   \n",
    "    \n",
    "        Z2 = np.dot(self.xdata, self.W2) + self.b2    \n",
    "        A2 = sigmoid(Z2)    \n",
    "    \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3    \n",
    "        y = sigmoid(Z3)    \n",
    "        \n",
    "        return  -np.sum( self.tdata*np.log(y + delta) + (1-self.tdata)*np.log((1 - y)+delta ) )\n",
    "                       \n",
    "    def train(self, xdata, tdata):\n",
    "        self.xdata = xdata\n",
    "        self.tdata = tdata\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "                       \n",
    "        self.W2 -= self.learning_rate * numerical_derivative( f, self.W2 )\n",
    "        self.b2 -= self.learning_rate * numerical_derivative( f, self.b2 )\n",
    "\n",
    "        self.W3 -= self.learning_rate * numerical_derivative( f, self.W3 )\n",
    "        self.b3 -= self.learning_rate * numerical_derivative( f, self.b3 )\n",
    "                       \n",
    "    def predict(self, x):\n",
    "        z2 = np.dot(x, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "    \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "    \n",
    "        if y > 0.5:\n",
    "            result = 1  # True\n",
    "        else:\n",
    "            result = 0  # False\n",
    "    \n",
    "        return y, result\n",
    "    \n",
    "    # 정확도 예측 함수\n",
    "    def accuracy(self, test_xdata, test_tdata):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        index_label_prediction_list = []\n",
    "        temp_list = []\n",
    "        \n",
    "        for index in range(len(test_xdata)):            \n",
    "            (real_val, logical_val) = self.predict(test_xdata[index])\n",
    "            \n",
    "            if logical_val == test_tdata[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                temp_list.append(index)\n",
    "                temp_list.append(test_tdata[index])\n",
    "                temp_list.append(logical_val)\n",
    "                \n",
    "                index_label_prediction_list.append(temp_list)\n",
    "                \n",
    "                temp_list = []\n",
    "        \n",
    "        accuracy_result = len(matched_list) / len(test_xdata)\n",
    "        \n",
    "        print(\"\\nAccuracy =>\", accuracy_result)\n",
    "        \n",
    "        return matched_list, not_matched_list, index_label_prediction_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes ver 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes object is created\n",
      "count = 0 loss value = 1.1158664925728112 time = 0:00:05.700258\n",
      "count = 5 loss value = 0.9434087165285368 time = 0:00:34.472035\n",
      "count = 10 loss value = 0.7861309320139981 time = 0:01:01.937394\n",
      "count = 15 loss value = 0.6363027829080186 time = 0:01:29.418192\n",
      "count = 20 loss value = 0.5198366828927962 time = 0:01:56.966835\n",
      "count = 25 loss value = 0.4392122908360574 time = 0:02:24.509240\n",
      "count = 30 loss value = 0.3864925732129897 time = 0:02:52.041690\n",
      "count = 35 loss value = 0.3528944356530858 time = 0:03:19.590740\n",
      "count = 40 loss value = 0.3317736903505637 time = 0:03:47.038659\n",
      "count = 45 loss value = 0.3186677682022413 time = 0:04:14.586831\n",
      "count = 50 loss value = 0.31069033105208776 time = 0:04:42.138603\n",
      "count = 55 loss value = 0.3059875628652079 time = 0:05:09.614127\n",
      "count = 60 loss value = 0.30336395383690284 time = 0:05:37.055668\n",
      "count = 65 loss value = 0.3020432545621866 time = 0:06:04.647446\n",
      "count = 70 loss value = 0.3015184437503539 time = 0:06:32.078259\n",
      "count = 75 loss value = 0.3014572569608407 time = 0:06:59.415772\n",
      "count = 80 loss value = 0.3016420683653562 time = 0:07:26.749560\n",
      "count = 85 loss value = 0.3019311581645502 time = 0:07:54.243327\n",
      "count = 90 loss value = 0.3022334572380454 time = 0:08:21.815734\n",
      "count = 95 loss value = 0.3024918978123986 time = 0:08:49.203654\n",
      "count = 100 loss value = 0.3026723282958672 time = 0:09:16.600347\n",
      "count = 105 loss value = 0.3027560663754001 time = 0:09:43.922792\n",
      "count = 110 loss value = 0.30273485553811247 time = 0:10:11.318373\n",
      "count = 115 loss value = 0.3026074243652615 time = 0:10:38.849356\n",
      "count = 120 loss value = 0.3023771242517248 time = 0:11:06.290598\n",
      "count = 125 loss value = 0.30205029898397445 time = 0:11:33.729982\n",
      "count = 130 loss value = 0.3016351551173545 time = 0:12:01.125924\n",
      "count = 135 loss value = 0.30114097778187887 time = 0:12:28.673049\n",
      "count = 140 loss value = 0.30057758654118577 time = 0:12:56.156634\n",
      "count = 145 loss value = 0.2999549591912789 time = 0:13:23.668109\n",
      "count = 150 loss value = 0.2992829736645203 time = 0:13:51.055337\n",
      "count = 155 loss value = 0.2985712332225873 time = 0:14:18.526293\n",
      "count = 160 loss value = 0.2978289503059156 time = 0:14:46.112723\n",
      "count = 165 loss value = 0.2970648713456805 time = 0:15:13.549961\n",
      "count = 170 loss value = 0.2962872296223513 time = 0:15:40.994552\n",
      "count = 175 loss value = 0.2955037165596907 time = 0:16:08.376013\n",
      "count = 180 loss value = 0.29472146418924045 time = 0:16:35.900762\n",
      "count = 185 loss value = 0.29394703321899196 time = 0:17:03.287056\n",
      "count = 190 loss value = 0.2931864024474192 time = 0:17:30.749213\n",
      "count = 195 loss value = 0.2924449563373603 time = 0:17:58.144902\n",
      "count = 200 loss value = 0.2917274685132514 time = 0:18:25.622590\n",
      "count = 205 loss value = 0.29103807988043534 time = 0:18:53.073082\n",
      "count = 210 loss value = 0.29038027099580843 time = 0:19:20.439130\n",
      "count = 215 loss value = 0.289756829311735 time = 0:19:47.759915\n",
      "count = 220 loss value = 0.2891698129050902 time = 0:20:15.128778\n",
      "count = 225 loss value = 0.2886205132818164 time = 0:20:42.626253\n",
      "count = 230 loss value = 0.28810942070633266 time = 0:21:10.027294\n",
      "count = 235 loss value = 0.28763619613743663 time = 0:21:37.424560\n",
      "count = 240 loss value = 0.2871996541632283 time = 0:22:04.829929\n",
      "count = 245 loss value = 0.28679776120015427 time = 0:22:32.340761\n",
      "count = 250 loss value = 0.2864276526152254 time = 0:22:59.799877\n",
      "count = 255 loss value = 0.2860856713825039 time = 0:23:27.312314\n",
      "count = 260 loss value = 0.2857674294633554 time = 0:23:54.657999\n",
      "count = 265 loss value = 0.2854678915115287 time = 0:24:22.136451\n",
      "count = 270 loss value = 0.2851814789068301 time = 0:24:49.581489\n",
      "count = 275 loss value = 0.2849021907582523 time = 0:25:16.883805\n",
      "count = 280 loss value = 0.284623737511257 time = 0:25:44.251820\n",
      "count = 285 loss value = 0.2843396822270519 time = 0:26:11.672616\n",
      "count = 290 loss value = 0.2840435844783835 time = 0:26:39.134669\n",
      "count = 295 loss value = 0.2837291420213585 time = 0:27:06.547621\n",
      "count = 300 loss value = 0.2833903258984142 time = 0:27:33.968374\n",
      "count = 305 loss value = 0.28302150525129577 time = 0:28:01.322489\n",
      "count = 310 loss value = 0.28261755881571027 time = 0:28:28.814592\n",
      "count = 315 loss value = 0.2821739708135565 time = 0:28:56.187393\n",
      "count = 320 loss value = 0.2816869096904137 time = 0:29:23.589990\n",
      "count = 325 loss value = 0.28115328889603375 time = 0:29:50.892495\n",
      "count = 330 loss value = 0.2805708096705517 time = 0:30:18.341353\n",
      "count = 335 loss value = 0.27993798649647145 time = 0:30:45.702833\n",
      "count = 340 loss value = 0.27925415651685176 time = 0:31:13.024833\n",
      "count = 345 loss value = 0.27851947471035937 time = 0:31:40.442170\n",
      "count = 350 loss value = 0.2777348969157905 time = 0:32:07.898465\n",
      "count = 355 loss value = 0.276902152895278 time = 0:32:35.363391\n",
      "count = 360 loss value = 0.2760237114950314 time = 0:33:02.787241\n",
      "count = 365 loss value = 0.27510273967835985 time = 0:33:30.318284\n",
      "count = 370 loss value = 0.27414305678507855 time = 0:33:57.685373\n",
      "count = 375 loss value = 0.27314908490680107 time = 0:34:25.174034\n",
      "count = 380 loss value = 0.2721257958413094 time = 0:34:52.709913\n",
      "count = 385 loss value = 0.2710786547149703 time = 0:35:20.083245\n",
      "count = 390 loss value = 0.2700135601391496 time = 0:35:47.403348\n",
      "count = 395 loss value = 0.26893678067550814 time = 0:36:14.834411\n",
      "count = 400 loss value = 0.26785488741496144 time = 0:36:42.301120\n",
      "count = 405 loss value = 0.26677468265569126 time = 0:37:09.594344\n",
      "count = 410 loss value = 0.26570312488391323 time = 0:37:37.035403\n",
      "count = 415 loss value = 0.26464725055378513 time = 0:38:04.479194\n",
      "count = 420 loss value = 0.26361409343664305 time = 0:38:31.963877\n",
      "count = 425 loss value = 0.2626106025480696 time = 0:38:59.446620\n",
      "count = 430 loss value = 0.2616435598673619 time = 0:39:26.969802\n",
      "\n",
      "Elapsed Time =>  0:39:26.969802\n"
     ]
    }
   ],
   "source": [
    "training_data = np.loadtxt('./(191103)diabetes_training.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "xdata = training_data[:, 0:-1]\n",
    "tdata = training_data[:, [-1]]\n",
    "\n",
    "i_node = 8\n",
    "h1_node = 30  # 30\n",
    "o_node = 1\n",
    "learning_rate = 1e-2\n",
    "epochs = 431 # x 행의 개수(500) 번 반복\n",
    "\n",
    "obj = Diabetes(\"Diabetes\", i_node, h1_node, o_node, learning_rate)\n",
    "\n",
    "start_time = datetime.now()  \n",
    "        \n",
    "for count in  range(epochs):  # 전체 반복 횟수\n",
    "    for index in range(len(xdata)):  # 행의 길이 만큼 반복\n",
    "        obj.train(xdata[index], tdata[index])\n",
    "        \n",
    "    mid_time = datetime.now()\n",
    "    if (count % 5 == 0):\n",
    "        print(\"count =\", count, \"loss value =\", obj.loss_val(), \"time =\", (mid_time - start_time))\n",
    "                \n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes\n",
      "\n",
      "Accuracy => 0.803088803088803\n",
      "\n",
      "matched(208)\n",
      " [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 128, 129, 131, 132, 133, 135, 136, 137, 139, 141, 142, 143, 144, 145, 146, 148, 151, 152, 153, 154, 156, 159, 160, 162, 163, 164, 165, 166, 168, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 188, 189, 190, 191, 193, 194, 195, 196, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 214, 215, 216, 217, 218, 219, 220, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 236, 238, 239, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 258] \n",
      "\n",
      "not matched(51)\n",
      " [3, 8, 27, 32, 33, 34, 40, 41, 52, 61, 69, 76, 82, 84, 100, 110, 111, 114, 122, 127, 130, 134, 138, 140, 147, 149, 150, 155, 157, 158, 161, 167, 169, 174, 186, 187, 192, 197, 200, 210, 213, 221, 222, 230, 234, 235, 237, 240, 241, 248, 257] \n",
      "\n",
      "not matched list\n",
      " [[3, 0.0, 1], [8, 0.0, 1], [27, 0.0, 1], [32, 0.0, 1], [33, 0.0, 1], [34, 0.0, 1], [40, 1.0, 0], [41, 1.0, 0], [52, 0.0, 1], [61, 0.0, 1], [69, 0.0, 1], [76, 0.0, 1], [82, 0.0, 1], [84, 0.0, 1], [100, 1.0, 0], [110, 0.0, 1], [111, 0.0, 1], [114, 1.0, 0], [122, 0.0, 1], [127, 0.0, 1], [130, 0.0, 1], [134, 0.0, 1], [138, 0.0, 1], [140, 0.0, 1], [147, 0.0, 1], [149, 1.0, 0], [150, 0.0, 1], [155, 0.0, 1], [157, 0.0, 1], [158, 0.0, 1], [161, 1.0, 0], [167, 0.0, 1], [169, 0.0, 1], [174, 0.0, 1], [186, 0.0, 1], [187, 0.0, 1], [192, 0.0, 1], [197, 0.0, 1], [200, 0.0, 1], [210, 0.0, 1], [213, 0.0, 1], [221, 0.0, 1], [222, 0.0, 1], [230, 0.0, 1], [234, 0.0, 1], [235, 1.0, 0], [237, 0.0, 1], [240, 0.0, 1], [241, 0.0, 1], [248, 0.0, 1], [257, 0.0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(obj.name)\n",
    "\n",
    "test_data = np.loadtxt('./(191103)diabetes_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "test_xdata = test_data[:, 0:-1]\n",
    "test_tdata = test_data[:, -1]\n",
    "\n",
    "accuracy_ret = obj.accuracy(test_xdata, test_tdata)\n",
    "\n",
    "print(\"\\nmatched(%d)\\n\"%len(accuracy_ret[0]), accuracy_ret[0], \"\\n\\nnot matched(%d)\\n\"%len(accuracy_ret[1]), accuracy_ret[1], \"\\n\\nnot matched list\\n\", accuracy_ret[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
