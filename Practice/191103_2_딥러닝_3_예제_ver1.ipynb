{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ver 1의 경우 다음과 같은 문제들이 있다.\n",
    "\n",
    "### 1. training data만 있고, test data가 없다. diabetes.csv만 있기 때문에 학습을 마친 후 테스트 할 데이터가 없다. 이로 인해 데이터 파일을 열어 이를 임의로 잘라서 나눠줘야한다.\n",
    "\n",
    "### 2. training 시간을 확인해보면 너무 오래 걸린다. (6만번 수행 시 3시간 이상) -> 나누기 연산이 포함되기 때문,, 모두 곱하기로 바꿔줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diabetes:\n",
    "    \n",
    "    def __init__(self, gate_name, xdata, tdata, i_node, h1_node, o_node, learning_rate, it_count):  \n",
    "        self.name = gate_name\n",
    "        \n",
    "        self.xdata = xdata\n",
    "        self.tdata = tdata\n",
    "        \n",
    "        self.W2 = np.random.rand(i_node, h1_node)             \n",
    "        self.b2 = np.random.rand(h1_node)\n",
    "        \n",
    "        self.W3 = np.random.rand(h1_node, o_node) \n",
    "        self.b3 = np.random.rand(o_node)\n",
    "                        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.it_count = it_count\n",
    "        \n",
    "        print(self.name + \" object is created\")\n",
    "\n",
    "    def feed_forward(self):\n",
    "        delta = 1e-7   \n",
    "        \n",
    "        Z2 = np.dot(self.xdata, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        y = sigmoid(Z3)\n",
    "        \n",
    "        return  -np.sum( self.tdata*np.log(y + delta) + (1-self.tdata)*np.log((1 - y)+delta ) )\n",
    "\n",
    "    def loss_val(self):\n",
    "        delta = 1e-7   \n",
    "    \n",
    "        Z2 = np.dot(self.xdata, self.W2) + self.b2    \n",
    "        A2 = sigmoid(Z2)    \n",
    "    \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3    \n",
    "        y = sigmoid(Z3)    \n",
    "        \n",
    "        return  -np.sum( self.tdata*np.log(y + delta) + (1-self.tdata)*np.log((1 - y)+delta ) )\n",
    "                       \n",
    "    def train(self):\n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        print('\\n=================================================')\n",
    "        print(\"Initial loss value =\", self.loss_val())\n",
    "        print('=================================================\\n')\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "                       \n",
    "        for step in  range(self.it_count):\n",
    "            self.W2 -= self.learning_rate * numerical_derivative( f, self.W2 )\n",
    "            self.b2 -= self.learning_rate * numerical_derivative( f, self.b2 )\n",
    "\n",
    "            self.W3 -= self.learning_rate * numerical_derivative( f, self.W3 )\n",
    "            self.b3 -= self.learning_rate * numerical_derivative( f, self.b3 )\n",
    "            \n",
    "            mid_time = datetime.now()\n",
    "            if (step % 1000 == 0):\n",
    "                print(\"step =\", step, \"loss value =\", self.loss_val(), \"time =\", (mid_time - start_time))\n",
    "                \n",
    "        end_time = datetime.now()\n",
    "        print('\\n=================================================')\n",
    "        print(\"updated loss value =\", self.loss_val())\n",
    "        print(\"Elapsed Time =>\", end_time - start_time)\n",
    "        print('=================================================\\n')\n",
    "                       \n",
    "    def predict(self, x):\n",
    "        z2 = np.dot(x, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "    \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "    \n",
    "        if y > 0.5:\n",
    "            result = 1  # True\n",
    "        else:\n",
    "            result = 0  # False\n",
    "    \n",
    "        return y, result\n",
    "    \n",
    "    # 정확도 예측 함수\n",
    "    def accuracy(self, test_xdata, test_tdata):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_xdata)):            \n",
    "            (real_val, logical_val) = self.predict(test_xdata[index])\n",
    "            \n",
    "            if logical_val == test_tdata[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "        \n",
    "        accuracy_result = len(matched_list) / len(test_xdata)\n",
    "        print(\"\\nAccuracy =>\", accuracy_result)\n",
    "        \n",
    "        return matched_list, not_matched_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes ver 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes object is created\n",
      "\n",
      "=================================================\n",
      "Initial loss value = 1214.6855954663142\n",
      "=================================================\n",
      "\n",
      "step = 0 loss value = 289.44219078160666 time = 0:00:00.058870\n",
      "step = 1000 loss value = 215.41741507469075 time = 0:01:04.663868\n",
      "step = 2000 loss value = 202.94548299447598 time = 0:02:10.020683\n",
      "step = 3000 loss value = 181.39415070097886 time = 0:03:15.625479\n",
      "step = 4000 loss value = 153.40499110880023 time = 0:04:20.958732\n",
      "step = 5000 loss value = 140.52252488531514 time = 0:05:27.710505\n",
      "step = 6000 loss value = 126.55278512943586 time = 0:06:34.068145\n",
      "step = 7000 loss value = 114.93152010129393 time = 0:07:40.651283\n",
      "step = 8000 loss value = 104.94708525189876 time = 0:08:46.367531\n",
      "step = 9000 loss value = 95.05334033449752 time = 0:09:53.470593\n",
      "step = 10000 loss value = 86.28364514065572 time = 0:10:59.339785\n",
      "step = 11000 loss value = 70.2675061733357 time = 0:12:06.309037\n",
      "step = 12000 loss value = 56.89053419280073 time = 0:13:13.583786\n",
      "step = 13000 loss value = 47.31674717864989 time = 0:14:19.614126\n",
      "step = 14000 loss value = 41.2897132116842 time = 0:15:25.902545\n",
      "step = 15000 loss value = 36.69374649680545 time = 0:16:32.637761\n",
      "step = 16000 loss value = 32.44927891113616 time = 0:17:39.088134\n",
      "step = 17000 loss value = 28.447418212256785 time = 0:18:45.311361\n",
      "step = 18000 loss value = 24.42654954788959 time = 0:19:52.894862\n",
      "step = 19000 loss value = 20.06804462127466 time = 0:20:58.840542\n",
      "step = 20000 loss value = 16.08894927213053 time = 0:22:05.015586\n",
      "step = 21000 loss value = 13.02235405048241 time = 0:23:12.169663\n",
      "step = 22000 loss value = 10.748118579078211 time = 0:24:19.585170\n",
      "step = 23000 loss value = 9.013531460617246 time = 0:25:26.781601\n",
      "step = 24000 loss value = 7.687662211349411 time = 0:26:33.909501\n",
      "step = 25000 loss value = 6.652163761926175 time = 0:27:40.308537\n",
      "step = 26000 loss value = 5.839508647806685 time = 0:28:46.734539\n",
      "step = 27000 loss value = 5.191110284596805 time = 0:29:53.206262\n",
      "step = 28000 loss value = 4.656674114747954 time = 0:30:59.470318\n",
      "step = 29000 loss value = 4.203615421242703 time = 0:32:06.731746\n",
      "step = 30000 loss value = 3.8149398237959655 time = 0:33:13.923066\n",
      "step = 31000 loss value = 3.481185615136203 time = 0:34:20.312644\n",
      "step = 32000 loss value = 3.1938626849989586 time = 0:35:26.899005\n",
      "step = 33000 loss value = 2.9449051273304936 time = 0:36:34.286226\n",
      "step = 34000 loss value = 2.727433843013044 time = 0:37:40.868736\n",
      "step = 35000 loss value = 2.535839536497024 time = 0:38:48.135950\n",
      "step = 36000 loss value = 2.3656152264241816 time = 0:39:54.581932\n",
      "step = 37000 loss value = 2.2131941920718425 time = 0:41:01.076400\n",
      "step = 38000 loss value = 2.0758292314143505 time = 0:42:08.834484\n",
      "step = 39000 loss value = 1.951482237346388 time = 0:43:16.378146\n",
      "step = 40000 loss value = 1.8386771284622774 time = 0:44:23.591340\n",
      "step = 41000 loss value = 1.7363010104191916 time = 0:45:30.084101\n",
      "step = 42000 loss value = 1.643408262173829 time = 0:46:36.357279\n",
      "step = 43000 loss value = 1.5591036072353495 time = 0:47:42.727325\n",
      "step = 44000 loss value = 1.4825167032138786 time = 0:48:48.910633\n",
      "step = 45000 loss value = 1.4128217671642693 time = 0:49:55.337281\n",
      "step = 46000 loss value = 1.3492588339574811 time = 0:51:01.525289\n",
      "step = 47000 loss value = 1.2911423110190428 time = 0:52:07.980373\n",
      "step = 48000 loss value = 1.2378599073511538 time = 0:53:15.994119\n",
      "step = 49000 loss value = 1.1888678630243001 time = 0:54:22.193531\n",
      "step = 50000 loss value = 1.1436856942377158 time = 0:55:29.952479\n",
      "step = 51000 loss value = 1.1018911383396244 time = 0:56:36.087923\n",
      "step = 52000 loss value = 1.0631150274162424 time = 0:57:42.423541\n",
      "step = 53000 loss value = 1.0270358824813366 time = 0:58:49.398335\n",
      "step = 54000 loss value = 0.9933743285619334 time = 0:59:56.365672\n",
      "step = 55000 loss value = 0.9618876030586005 time = 1:01:03.219473\n",
      "step = 56000 loss value = 0.932364425270905 time = 1:02:09.277252\n",
      "step = 57000 loss value = 0.9046204003866742 time = 1:03:16.291530\n",
      "step = 58000 loss value = 0.8784940262932672 time = 1:04:22.323025\n",
      "step = 59000 loss value = 0.8538432939184359 time = 1:05:28.904385\n",
      "step = 60000 loss value = 0.8305428276746816 time = 1:06:35.411408\n",
      "\n",
      "=================================================\n",
      "updated loss value = 0.8305428276746816\n",
      "Elapsed Time => 1:06:35.411408\n",
      "=================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = np.loadtxt('./(191103)diabetes_training.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "xdata = training_data[:, 0:-1]\n",
    "tdata = training_data[:, [-1]]\n",
    "\n",
    "i_node = 8\n",
    "h1_node = 30\n",
    "o_node = 1\n",
    "learning_rate = 1e-2\n",
    "it_count = 60001\n",
    "\n",
    "obj = Diabetes(\"Diabetes\", xdata, tdata, i_node, h1_node, o_node, learning_rate, it_count)\n",
    "        \n",
    "obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes\n",
      "\n",
      "Accuracy => 0.6911196911196911\n",
      "\n",
      " [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 31, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 58, 59, 62, 64, 65, 66, 68, 69, 70, 71, 72, 74, 77, 78, 79, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 94, 95, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 116, 117, 118, 119, 121, 122, 124, 125, 126, 128, 129, 131, 133, 135, 139, 142, 143, 145, 146, 147, 148, 149, 152, 154, 155, 156, 159, 160, 162, 163, 165, 166, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 201, 205, 206, 207, 208, 209, 211, 213, 215, 217, 218, 220, 221, 223, 225, 227, 228, 229, 231, 232, 233, 236, 238, 239, 242, 243, 244, 245, 246, 250, 251, 252, 254, 256, 257, 258] \n",
      "\n",
      " [3, 8, 15, 21, 22, 23, 30, 32, 33, 34, 40, 48, 55, 57, 60, 61, 63, 67, 73, 75, 76, 80, 83, 86, 93, 96, 97, 103, 110, 114, 115, 120, 123, 127, 130, 132, 134, 136, 137, 138, 140, 141, 144, 150, 151, 153, 157, 158, 161, 164, 167, 174, 181, 184, 186, 192, 199, 200, 202, 203, 204, 210, 212, 214, 216, 219, 222, 224, 226, 230, 234, 235, 237, 240, 241, 247, 248, 249, 253, 255]\n"
     ]
    }
   ],
   "source": [
    "print(obj.name)\n",
    "\n",
    "test_data = np.loadtxt('./(191103)diabetes_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "test_xdata = test_data[:, 0:-1]\n",
    "test_tdata = test_data[:, [-1]]\n",
    "\n",
    "# for data in test_xdata:\n",
    "#     (real_val, logical_val) = obj.predict(data)\n",
    "#     print(\"real_val =\", real_val, \", logical_val =\", logical_val)\n",
    "\n",
    "accuracy_ret = obj.accuracy(test_xdata, test_tdata)\n",
    "\n",
    "print(\"\\n\", accuracy_ret[0], \"\\n\\n\", accuracy_ret[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
