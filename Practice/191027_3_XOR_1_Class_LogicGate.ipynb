{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, xdata, tdata, learning_rate, iteration_count):\n",
    "        self.xdata = xdata\n",
    "        self.tdata = tdata\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        \n",
    "        self.W = np.random.rand(self.xdata.shape[1], 1)\n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "        print(\"ClassificationCrossEntropy Object is created\")\n",
    "        \n",
    "        \n",
    "    def getW_b(self):\n",
    "        return self.W, self.b\n",
    "    \n",
    "    def loss_func(self):\n",
    "        delta = 1e-7\n",
    "        z = np.dot(self.xdata, self.W) + self.b\n",
    "        y = sigmoid(z)\n",
    "    \n",
    "        return (-1) * (np.sum(self.tdata*np.log(y+delta) + (1 - self.tdata)*np.log(1 - y + delta)))\n",
    "\n",
    "    def loss_val(self):\n",
    "        delta = 1e-7\n",
    "        z = np.dot(self.xdata, self.W) + self.b\n",
    "        y = sigmoid(z)\n",
    "    \n",
    "        return (-1) * (np.sum(self.tdata*np.log(y+delta) + (1 - self.tdata)*np.log(1 - y + delta)))\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        z = np.dot(test_data, self.W) + self.b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        if y >= 0.5:\n",
    "            result = 1\n",
    "        elif y < 0.5:\n",
    "            result = 0\n",
    "        print(\"y: \", y, \"\\t result: \", result)\n",
    "        return result\n",
    "    \n",
    "    def train(self):\n",
    "        f = lambda x : self.loss_func()\n",
    "\n",
    "        print(\"Initial loss value = \", self.loss_val(), \"Initial W = \", self.W, \"\\n\", \", b = \", self.b )\n",
    "\n",
    "        for step in range(self.iteration_count):\n",
    "            self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
    "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "    \n",
    "            if (step % 10000 == 0):\n",
    "                print(\"step = \", step, \"loss value = \", self.loss_val(), \"W = \", self.W, \", b = \", self.b )\n",
    "                \n",
    "    def accuracy(self, test_xdata, test_tdata):\n",
    "        den = len(test_xdata)\n",
    "        num = 0\n",
    "        for i in range(0, den):\n",
    "            if self.predict(test_xdata[i]) == test_tdata[i]:\n",
    "                num = num + 1\n",
    "                \n",
    "        \n",
    "        return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (4, 2) , t_data.shape =  (4, 1)\n",
      "ClassificationCrossEntropy Object is created\n",
      "Initial loss value =  3.489087286862102 Initial W =  [[0.3056994 ]\n",
      " [0.14977952]] \n",
      " , b =  [0.46701096]\n",
      "step =  0 loss value =  3.4587142455302655 W =  [[0.30170284]\n",
      " [0.14612915]] , b =  [0.4504053]\n",
      "step =  10000 loss value =  0.17213115059439088 W =  [[5.56906274]\n",
      " [5.5690555 ]] , b =  [-8.53338283]\n",
      "step =  20000 loss value =  0.08716929323106068 W =  [[6.9595313 ]\n",
      " [6.95953104]] , b =  [-10.61312428]\n",
      "step =  30000 loss value =  0.058070925882422575 W =  [[7.78226969]\n",
      " [7.78226966]] , b =  [-11.84531004]\n",
      "step =  40000 loss value =  0.04346597659182443 W =  [[8.36687941]\n",
      " [8.3668794 ]] , b =  [-12.72128151]\n",
      "step =  50000 loss value =  0.0347054669310115 W =  [[8.82019237]\n",
      " [8.82019237]] , b =  [-13.40069191]\n",
      "step =  60000 loss value =  0.028872610651053753 W =  [[9.19030062]\n",
      " [9.19030062]] , b =  [-13.95548481]\n",
      "step =  70000 loss value =  0.024712502809002623 W =  [[9.50296795]\n",
      " [9.50296795]] , b =  [-14.42422359]\n",
      "step =  80000 loss value =  0.02159699155863537 W =  [[9.7736012]\n",
      " [9.7736012]] , b =  [-14.8299778]\n",
      "step =  90000 loss value =  0.01917711976460661 W =  [[10.01214514]\n",
      " [10.01214514]] , b =  [-15.18764216]\n",
      "step =  100000 loss value =  0.017243632672653355 W =  [[10.22539097]\n",
      " [10.22539097]] , b =  [-15.50739008]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t_data = np.array([0, 0, 0, 1]).reshape(4, 1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)\n",
    "\n",
    "ANDobj = LogicGate(x_data, t_data, 1e-2, 100001)\n",
    "ANDobj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  [1.84173007e-07] \t result:  0\n",
      "y:  [0.00505656] \t result:  0\n",
      "y:  [0.00505656] \t result:  0\n",
      "y:  [0.99292011] \t result:  1\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "test_tdata = np.array([0, 0, 0, 1]).reshape(4, 1)\n",
    "\n",
    "print(\"Accuracy: \", ANDobj.accuracy(test_xdata, test_tdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (4, 2) , t_data.shape =  (4, 1)\n",
      "ClassificationCrossEntropy Object is created\n",
      "Initial loss value =  1.8677523048518474 Initial W =  [[0.25801881]\n",
      " [0.59727974]] \n",
      " , b =  [0.83381616]\n",
      "step =  0 loss value =  1.864785571957515 W =  [[0.26209046]\n",
      " [0.60076794]] , b =  [0.83282248]\n",
      "step =  10000 loss value =  0.09448933265314774 W =  [[6.77540062]\n",
      " [6.77713143]] , b =  [-2.91173965]\n",
      "step =  20000 loss value =  0.04670763439693657 W =  [[8.20233012]\n",
      " [8.20275508]] , b =  [-3.63432267]\n",
      "step =  30000 loss value =  0.03090815607922703 W =  [[9.0339389 ]\n",
      " [9.03412525]] , b =  [-4.0530908]\n",
      "step =  40000 loss value =  0.02306974008038302 W =  [[9.62181776]\n",
      " [9.62192164]] , b =  [-4.34849202]\n",
      "step =  50000 loss value =  0.018393667764320908 W =  [[10.07656186]\n",
      " [10.07662793]] , b =  [-4.57673352]\n",
      "step =  60000 loss value =  0.015289764605338008 W =  [[10.44734086]\n",
      " [10.44738652]] , b =  [-4.76269909]\n",
      "step =  70000 loss value =  0.013080159594244438 W =  [[10.76031874]\n",
      " [10.76035217]] , b =  [-4.91959762]\n",
      "step =  80000 loss value =  0.011427433260685191 W =  [[11.03107671]\n",
      " [11.03110223]] , b =  [-5.0552827]\n",
      "step =  90000 loss value =  0.01014483181427297 W =  [[11.26964414]\n",
      " [11.26966425]] , b =  [-5.1748038]\n",
      "step =  100000 loss value =  0.009120657250636958 W =  [[11.48285656]\n",
      " [11.48287282]] , b =  [-5.28159947]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t_data = np.array([0, 1, 1, 1]).reshape(4, 1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)\n",
    "\n",
    "ORobj = LogicGate(x_data, t_data, 1e-2, 100001)\n",
    "ORobj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  [0.00505857] \t result:  0\n",
      "y:  [0.99797725] \t result:  1\n",
      "y:  [0.99797722] \t result:  1\n",
      "y:  [0.99999998] \t result:  1\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "test_tdata = np.array([0, 1, 1, 1]).reshape(4, 1)\n",
    "\n",
    "print(\"Accuracy: \", ORobj.accuracy(test_xdata, test_tdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (4, 2) , t_data.shape =  (4, 1)\n",
      "ClassificationCrossEntropy Object is created\n",
      "Initial loss value =  3.0463227607369765 Initial W =  [[0.95591428]\n",
      " [0.37061578]] \n",
      " , b =  [0.18566361]\n",
      "step =  0 loss value =  3.0403377180904814 W =  [[0.95014073]\n",
      " [0.36606601]] , b =  [0.1881078]\n",
      "step =  10000 loss value =  0.17343931517082806 W =  [[-5.55345544]\n",
      " [-5.55348021]] , b =  [8.5100922]\n",
      "step =  20000 loss value =  0.08751202290227197 W =  [[-6.95156112]\n",
      " [-6.95156198]] , b =  [10.60119284]\n",
      "step =  30000 loss value =  0.058224234183196756 W =  [[-7.77694169]\n",
      " [-7.7769418 ]] , b =  [11.83732812]\n",
      "step =  40000 loss value =  0.04355221647546807 W =  [[-8.36288419]\n",
      " [-8.36288421]] , b =  [12.71529423]\n",
      "step =  50000 loss value =  0.03476058258842591 W =  [[-8.81699885]\n",
      " [-8.81699886]] , b =  [13.39590514]\n",
      "step =  60000 loss value =  0.02891081998977431 W =  [[-9.18764185]\n",
      " [-9.18764186]] , b =  [13.95149907]\n",
      "step =  70000 loss value =  0.024740527844194185 W =  [[-9.50069105]\n",
      " [-9.50069105]] , b =  [14.42081]\n",
      "step =  80000 loss value =  0.021618414887888217 W =  [[-9.77161054]\n",
      " [-9.77161054]] , b =  [14.82699316]\n",
      "step =  90000 loss value =  0.019194022990863563 W =  [[-10.01037698]\n",
      " [-10.01037698]] , b =  [15.18499097]\n",
      "step =  100000 loss value =  0.017257306902682897 W =  [[-10.22380068]\n",
      " [-10.22380068]] , b =  [15.5050055]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t_data = np.array([1, 1, 1, 0]).reshape(4, 1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)\n",
    "\n",
    "NANDobj = LogicGate(x_data, t_data, 1e-2, 100001)\n",
    "NANDobj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  [0.99999982] \t result:  1\n",
      "y:  [0.99493944] \t result:  1\n",
      "y:  [0.99493944] \t result:  1\n",
      "y:  [0.00708549] \t result:  0\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "test_tdata = np.array([1, 1, 1, 0]).reshape(4, 1)\n",
    "\n",
    "print(\"Accuracy: \", NANDobj.accuracy(test_xdata, test_tdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (4, 2) , t_data.shape =  (4, 1)\n",
      "ClassificationCrossEntropy Object is created\n",
      "Initial loss value =  3.2281263331844703 Initial W =  [[0.5548413 ]\n",
      " [0.41019433]] \n",
      " , b =  [0.4353041]\n",
      "step =  0 loss value =  3.215864724963032 W =  [[0.54952776]\n",
      " [0.40517574]] , b =  [0.42696045]\n",
      "step =  10000 loss value =  2.772587922239861 W =  [[1.90406449e-08]\n",
      " [1.90386221e-08]] , b =  [-2.25630017e-08]\n",
      "step =  20000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n",
      "step =  30000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n",
      "step =  40000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n",
      "step =  50000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n",
      "step =  60000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n",
      "step =  70000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n",
      "step =  80000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n",
      "step =  90000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n",
      "step =  100000 loss value =  2.7725879222398615 W =  [[9.60154178e-12]\n",
      " [7.33446637e-12]] , b =  [-9.99778038e-12]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t_data = np.array([0, 1, 1, 0]).reshape(4, 1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)\n",
    "\n",
    "XORobj = LogicGate(x_data, t_data, 1e-2, 100001)\n",
    "XORobj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  [0.5] \t result:  0\n",
      "y:  [0.5] \t result:  0\n",
      "y:  [0.5] \t result:  0\n",
      "y:  [0.5] \t result:  1\n",
      "Accuracy:  0.25\n"
     ]
    }
   ],
   "source": [
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "test_tdata = np.array([0, 1, 1, 0]).reshape(4, 1)\n",
    "\n",
    "print(\"Accuracy: \", XORobj.accuracy(test_xdata, test_tdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
