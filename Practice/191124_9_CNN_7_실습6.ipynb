{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1 5x5 32개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 4x4x32 필터 \n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 x 5 크기를 가진 32개의 activation map을 flatten 시킴\n",
    "A2_flat = P2_flat = tf.reshape(A4, [-1, 14*14*32])  # 행이 몇게가 오든 열 개수만 맞춰서 나중에 y는 최종적으로 (?, 10) 의 shape가 됨\n",
    "\n",
    "# ? 가 여러개 있는 것은 모두 평균을 내어 결과적으로 (1, 10) 의 모양이 되고, 이를 답과 비교하게 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W5 = tf.Variable(tf.random_normal([4*4*128, 10], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀 값 Z5, 즉 softmax 에 들어가는 입력 값\n",
    "Z5 = logits = tf.matmul(A4_flat, W5) + b5\n",
    "\n",
    "y = A5 = tf.nn.softmax(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z5, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A5, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.5596507\n",
      "epochs =  0 , step =  100 , loss_val =  0.9891903\n",
      "epochs =  0 , step =  200 , loss_val =  0.23193045\n",
      "epochs =  0 , step =  300 , loss_val =  0.050346542\n",
      "epochs =  0 , step =  400 , loss_val =  0.14194188\n",
      "epochs =  0 , step =  500 , loss_val =  0.08773869\n",
      "epochs =  1 , step =  0 , loss_val =  0.036828134\n",
      "epochs =  1 , step =  100 , loss_val =  0.039269824\n",
      "epochs =  1 , step =  200 , loss_val =  0.1382684\n",
      "epochs =  1 , step =  300 , loss_val =  0.008206204\n",
      "epochs =  1 , step =  400 , loss_val =  0.05820755\n",
      "epochs =  1 , step =  500 , loss_val =  0.03899339\n",
      "epochs =  2 , step =  0 , loss_val =  0.012510245\n",
      "epochs =  2 , step =  100 , loss_val =  0.0111548\n",
      "epochs =  2 , step =  200 , loss_val =  0.029188657\n",
      "epochs =  2 , step =  300 , loss_val =  0.08090368\n",
      "epochs =  2 , step =  400 , loss_val =  0.031828023\n",
      "epochs =  2 , step =  500 , loss_val =  0.09016566\n",
      "epochs =  3 , step =  0 , loss_val =  0.010679768\n",
      "epochs =  3 , step =  100 , loss_val =  0.026196755\n",
      "epochs =  3 , step =  200 , loss_val =  0.0063276123\n",
      "epochs =  3 , step =  300 , loss_val =  0.0128060505\n",
      "epochs =  3 , step =  400 , loss_val =  0.011993307\n",
      "epochs =  3 , step =  500 , loss_val =  0.03126261\n",
      "epochs =  4 , step =  0 , loss_val =  0.0062843226\n",
      "epochs =  4 , step =  100 , loss_val =  0.0009440139\n",
      "epochs =  4 , step =  200 , loss_val =  0.034068767\n",
      "epochs =  4 , step =  300 , loss_val =  0.038729683\n",
      "epochs =  4 , step =  400 , loss_val =  0.0052213706\n",
      "epochs =  4 , step =  500 , loss_val =  0.005655508\n",
      "epochs =  5 , step =  0 , loss_val =  0.0011140124\n",
      "epochs =  5 , step =  100 , loss_val =  0.004868162\n",
      "epochs =  5 , step =  200 , loss_val =  0.0056895213\n",
      "epochs =  5 , step =  300 , loss_val =  0.02514331\n",
      "epochs =  5 , step =  400 , loss_val =  0.0050239023\n",
      "epochs =  5 , step =  500 , loss_val =  0.02006843\n",
      "epochs =  6 , step =  0 , loss_val =  0.009375911\n",
      "epochs =  6 , step =  100 , loss_val =  0.018356327\n",
      "epochs =  6 , step =  200 , loss_val =  0.0007186085\n",
      "epochs =  6 , step =  300 , loss_val =  0.0104715265\n",
      "epochs =  6 , step =  400 , loss_val =  0.002898443\n",
      "epochs =  6 , step =  500 , loss_val =  0.024699077\n",
      "epochs =  7 , step =  0 , loss_val =  0.018989734\n",
      "epochs =  7 , step =  100 , loss_val =  0.0009807325\n",
      "epochs =  7 , step =  200 , loss_val =  0.0002620182\n",
      "epochs =  7 , step =  300 , loss_val =  0.0077881827\n",
      "epochs =  7 , step =  400 , loss_val =  0.0016645003\n",
      "epochs =  7 , step =  500 , loss_val =  0.0005186592\n",
      "epochs =  8 , step =  0 , loss_val =  0.016218662\n",
      "epochs =  8 , step =  100 , loss_val =  0.0053995466\n",
      "epochs =  8 , step =  200 , loss_val =  0.07387405\n",
      "epochs =  8 , step =  300 , loss_val =  0.0011059042\n",
      "epochs =  8 , step =  400 , loss_val =  0.00034312627\n",
      "epochs =  8 , step =  500 , loss_val =  0.018550457\n",
      "epochs =  9 , step =  0 , loss_val =  0.00074457144\n",
      "epochs =  9 , step =  100 , loss_val =  0.00092255493\n",
      "epochs =  9 , step =  200 , loss_val =  0.003322734\n",
      "epochs =  9 , step =  300 , loss_val =  0.014278936\n",
      "epochs =  9 , step =  400 , loss_val =  0.0024047259\n",
      "epochs =  9 , step =  500 , loss_val =  0.010197316\n",
      "epochs =  10 , step =  0 , loss_val =  0.0042247106\n",
      "epochs =  10 , step =  100 , loss_val =  0.0005181678\n",
      "epochs =  10 , step =  200 , loss_val =  0.004232815\n",
      "epochs =  10 , step =  300 , loss_val =  0.011126033\n",
      "epochs =  10 , step =  400 , loss_val =  6.4422515e-05\n",
      "epochs =  10 , step =  500 , loss_val =  0.019888949\n",
      "epochs =  11 , step =  0 , loss_val =  0.0077415244\n",
      "epochs =  11 , step =  100 , loss_val =  0.000639905\n",
      "epochs =  11 , step =  200 , loss_val =  0.0017820611\n",
      "epochs =  11 , step =  300 , loss_val =  0.0010871383\n",
      "epochs =  11 , step =  400 , loss_val =  0.000124919\n",
      "epochs =  11 , step =  500 , loss_val =  0.0013020966\n",
      "epochs =  12 , step =  0 , loss_val =  3.9247574e-05\n",
      "epochs =  12 , step =  100 , loss_val =  0.00037926994\n",
      "epochs =  12 , step =  200 , loss_val =  0.060009826\n",
      "epochs =  12 , step =  300 , loss_val =  0.00026752785\n",
      "epochs =  12 , step =  400 , loss_val =  0.0012637661\n",
      "epochs =  12 , step =  500 , loss_val =  0.00018710033\n",
      "epochs =  13 , step =  0 , loss_val =  0.00021464797\n",
      "epochs =  13 , step =  100 , loss_val =  4.9622926e-05\n",
      "epochs =  13 , step =  200 , loss_val =  0.023739796\n",
      "epochs =  13 , step =  300 , loss_val =  0.0014945291\n",
      "epochs =  13 , step =  400 , loss_val =  0.00030205108\n",
      "epochs =  13 , step =  500 , loss_val =  0.003637797\n",
      "epochs =  14 , step =  0 , loss_val =  0.0018507808\n",
      "epochs =  14 , step =  100 , loss_val =  0.00018062188\n",
      "epochs =  14 , step =  200 , loss_val =  0.0009869094\n",
      "epochs =  14 , step =  300 , loss_val =  0.00014068006\n",
      "epochs =  14 , step =  400 , loss_val =  4.7892445e-05\n",
      "epochs =  14 , step =  500 , loss_val =  1.9189003e-05\n",
      "epochs =  15 , step =  0 , loss_val =  0.024973726\n",
      "epochs =  15 , step =  100 , loss_val =  0.000230486\n",
      "epochs =  15 , step =  200 , loss_val =  0.00014703644\n",
      "epochs =  15 , step =  300 , loss_val =  0.00012807574\n",
      "epochs =  15 , step =  400 , loss_val =  0.0710988\n",
      "epochs =  15 , step =  500 , loss_val =  0.011870202\n",
      "epochs =  16 , step =  0 , loss_val =  0.0002025547\n",
      "epochs =  16 , step =  100 , loss_val =  1.1152439e-05\n",
      "epochs =  16 , step =  200 , loss_val =  0.0017786578\n",
      "epochs =  16 , step =  300 , loss_val =  0.00012529705\n",
      "epochs =  16 , step =  400 , loss_val =  0.00087653147\n",
      "epochs =  16 , step =  500 , loss_val =  2.9765046e-05\n",
      "epochs =  17 , step =  0 , loss_val =  7.4728123e-06\n",
      "epochs =  17 , step =  100 , loss_val =  0.0059489147\n",
      "epochs =  17 , step =  200 , loss_val =  0.00033322122\n",
      "epochs =  17 , step =  300 , loss_val =  0.0003259277\n",
      "epochs =  17 , step =  400 , loss_val =  0.16778576\n",
      "epochs =  17 , step =  500 , loss_val =  0.00021906864\n",
      "epochs =  18 , step =  0 , loss_val =  0.012663923\n",
      "epochs =  18 , step =  100 , loss_val =  0.00028280323\n",
      "epochs =  18 , step =  200 , loss_val =  1.48811005e-05\n",
      "epochs =  18 , step =  300 , loss_val =  0.060429886\n",
      "epochs =  18 , step =  400 , loss_val =  0.0024020504\n",
      "epochs =  18 , step =  500 , loss_val =  0.0010883637\n",
      "epochs =  19 , step =  0 , loss_val =  2.7016378e-05\n",
      "epochs =  19 , step =  100 , loss_val =  0.00014142178\n",
      "epochs =  19 , step =  200 , loss_val =  0.00020645048\n",
      "epochs =  19 , step =  300 , loss_val =  0.00090805336\n",
      "epochs =  19 , step =  400 , loss_val =  0.006978365\n",
      "epochs =  19 , step =  500 , loss_val =  0.00020174864\n",
      "epochs =  20 , step =  0 , loss_val =  0.00065615604\n",
      "epochs =  20 , step =  100 , loss_val =  3.2721177e-06\n",
      "epochs =  20 , step =  200 , loss_val =  0.00057963235\n",
      "epochs =  20 , step =  300 , loss_val =  0.00091368577\n",
      "epochs =  20 , step =  400 , loss_val =  0.00034840457\n",
      "epochs =  20 , step =  500 , loss_val =  0.0062411516\n",
      "epochs =  21 , step =  0 , loss_val =  4.7538142e-05\n",
      "epochs =  21 , step =  100 , loss_val =  0.002224953\n",
      "epochs =  21 , step =  200 , loss_val =  9.529339e-06\n",
      "epochs =  21 , step =  300 , loss_val =  1.4250842e-05\n",
      "epochs =  21 , step =  400 , loss_val =  0.0018958017\n",
      "epochs =  21 , step =  500 , loss_val =  0.0044559245\n",
      "epochs =  22 , step =  0 , loss_val =  3.298588e-05\n",
      "epochs =  22 , step =  100 , loss_val =  0.00038065453\n",
      "epochs =  22 , step =  200 , loss_val =  8.058141e-05\n",
      "epochs =  22 , step =  300 , loss_val =  0.022114074\n",
      "epochs =  22 , step =  400 , loss_val =  0.00017786486\n",
      "epochs =  22 , step =  500 , loss_val =  0.028483134\n",
      "epochs =  23 , step =  0 , loss_val =  8.79908e-05\n",
      "epochs =  23 , step =  100 , loss_val =  1.8826373e-05\n",
      "epochs =  23 , step =  200 , loss_val =  0.007695754\n",
      "epochs =  23 , step =  300 , loss_val =  2.7747907e-05\n",
      "epochs =  23 , step =  400 , loss_val =  1.7750195e-05\n",
      "epochs =  23 , step =  500 , loss_val =  5.926706e-05\n",
      "epochs =  24 , step =  0 , loss_val =  0.00014718118\n",
      "epochs =  24 , step =  100 , loss_val =  0.00046860383\n",
      "epochs =  24 , step =  200 , loss_val =  1.02108e-05\n",
      "epochs =  24 , step =  300 , loss_val =  1.2309181e-05\n",
      "epochs =  24 , step =  400 , loss_val =  5.111768e-05\n",
      "epochs =  24 , step =  500 , loss_val =  6.294547e-06\n",
      "epochs =  25 , step =  0 , loss_val =  0.001566729\n",
      "epochs =  25 , step =  100 , loss_val =  1.5520532e-06\n",
      "epochs =  25 , step =  200 , loss_val =  0.00011800425\n",
      "epochs =  25 , step =  300 , loss_val =  0.00020470525\n",
      "epochs =  25 , step =  400 , loss_val =  0.0030159226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  25 , step =  500 , loss_val =  0.00054021704\n",
      "epochs =  26 , step =  0 , loss_val =  5.0332535e-05\n",
      "epochs =  26 , step =  100 , loss_val =  5.69406e-06\n",
      "epochs =  26 , step =  200 , loss_val =  1.1551222e-05\n",
      "epochs =  26 , step =  300 , loss_val =  5.817016e-06\n",
      "epochs =  26 , step =  400 , loss_val =  4.7501042e-05\n",
      "epochs =  26 , step =  500 , loss_val =  3.7919104e-05\n",
      "epochs =  27 , step =  0 , loss_val =  9.359945e-05\n",
      "epochs =  27 , step =  100 , loss_val =  1.6760507e-05\n",
      "epochs =  27 , step =  200 , loss_val =  0.00053038815\n",
      "epochs =  27 , step =  300 , loss_val =  0.0003052072\n",
      "epochs =  27 , step =  400 , loss_val =  3.611619e-06\n",
      "epochs =  27 , step =  500 , loss_val =  1.9788608e-07\n",
      "epochs =  28 , step =  0 , loss_val =  0.009174057\n",
      "epochs =  28 , step =  100 , loss_val =  0.0026148395\n",
      "epochs =  28 , step =  200 , loss_val =  0.024141164\n",
      "epochs =  28 , step =  300 , loss_val =  3.2863659e-06\n",
      "epochs =  28 , step =  400 , loss_val =  8.611515e-05\n",
      "epochs =  28 , step =  500 , loss_val =  0.0046919547\n",
      "epochs =  29 , step =  0 , loss_val =  3.0328403e-05\n",
      "epochs =  29 , step =  100 , loss_val =  5.219813e-06\n",
      "epochs =  29 , step =  200 , loss_val =  5.158883e-06\n",
      "epochs =  29 , step =  300 , loss_val =  1.3389946e-05\n",
      "epochs =  29 , step =  400 , loss_val =  0.009215495\n",
      "epochs =  29 , step =  500 , loss_val =  1.642611e-06\n",
      "\n",
      "Elapsed Time =>  0:23:46.245935\n",
      "\n",
      "Accuracy = 0.9938\n",
      "length of index_label_list =  10000\n",
      "false label count =  62\n",
      "\n",
      "length of index_label_false_list_1 62\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})   \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[340, 5, 3], [449, 3, 5], [582, 8, 2], [625, 6, 4], [674, 5, 3], [726, 7, 3], [846, 7, 9], [938, 3, 5], [947, 8, 9], [1014, 6, 5], [1039, 7, 1], [1226, 7, 2], [1232, 9, 4], [1260, 7, 1], [1500, 7, 3], [1522, 7, 9], [1527, 1, 3], [1621, 0, 6], [1709, 9, 5], [1901, 9, 4], [2035, 5, 3], [2118, 6, 0], [2130, 4, 9], [2182, 1, 3], [2293, 9, 4], [2314, 7, 4], [2414, 9, 4], [2597, 5, 3], [2654, 6, 1], [2927, 3, 2], [2939, 9, 5], [3225, 7, 9], [3343, 8, 2], [3422, 6, 0], [3520, 6, 4], [3767, 7, 2], [4176, 2, 7], [4199, 7, 9], [4571, 6, 8], [4740, 3, 5], [4761, 9, 4], [4807, 8, 3], [4860, 4, 9], [5265, 6, 4], [5331, 1, 6], [5450, 0, 5], [5457, 1, 4], [5654, 7, 2], [5906, 7, 9], [5937, 5, 3], [5955, 3, 8], [6576, 7, 1], [6597, 0, 7], [6625, 8, 2], [6783, 1, 6], [7928, 1, 0], [8094, 2, 8], [8246, 3, 5], [9015, 7, 2], [9024, 7, 2], [9700, 2, 8], [9729, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUSEUNG\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\16일차_1124\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "Elapsed save time =>  0:00:16.261903\n",
      "Total  62  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data_실습5'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_1:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
