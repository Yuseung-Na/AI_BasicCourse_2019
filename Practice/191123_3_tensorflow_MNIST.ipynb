{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape 및 type(mnist) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(mnist) =  <class 'tensorflow.contrib.learn.python.learn.datasets.base.Datasets'> , type(mnist.train.images) =  <class 'numpy.ndarray'> , type(mnist.train.labels) =  <class 'numpy.ndarray'>\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "test image shape =  (10000, 784)\n",
      "validation image shape =  (5000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"type(mnist) = \", type(mnist), \n",
    "      \", type(mnist.train.images) = \", type(mnist.train.images), \n",
    "      \", type(mnist.train.labels) = \", type(mnist.train.labels))\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))\n",
    "\n",
    "print(\"\\ntrain image shape = \", mnist.train.images.shape)\n",
    "print(\"test image shape = \", mnist.test.images.shape)\n",
    "print(\"validation image shape = \", mnist.validation.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of mnist.train.images =  55000\n",
      "\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
      " 0.46274513 0.2392157  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3529412\n",
      " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
      " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
      " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.7411765  0.09019608 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
      " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
      " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
      " 0.08235294 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14901961 0.32156864\n",
      " 0.0509804  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32941177\n",
      " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.09803922\n",
      " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.5568628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
      " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
      " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
      " 0.34901962 0.12156864 0.         0.         0.         0.\n",
      " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6627451  0.9960785\n",
      " 0.6901961  0.24313727 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07058824 0.48627454 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54509807\n",
      " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
      " 0.3372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01568628 0.45882356\n",
      " 0.27058825 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 정규화 확인\n",
    "print(\"length of mnist.train.images = \", len(mnist.train.images))\n",
    "\n",
    "for index in range(len(mnist.train.images)):\n",
    "    \n",
    "    min_val = np.min(mnist.train.images[index])\n",
    "    max_val = np.max(mnist.train.images[index])\n",
    "    \n",
    "    if min_val < 0.0:\n",
    "        print(\"min value is \", min_val, \", index = \", index)\n",
    "        break\n",
    "    \n",
    "    if max_val > 1.0:\n",
    "        print(\"max value is \", max_val, \", index = \", index)\n",
    "        break\n",
    "    \n",
    "print(\"\")\n",
    "print(mnist.train.images[0])  # 정규화 확인을 위한 테스트 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of mnist.train.images =  55000\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding 확인\n",
    "print(\"length of mnist.train.images = \", len(mnist.train.labels))\n",
    "\n",
    "for index in range(len(mnist.train.labels)):\n",
    "    \n",
    "    min_val = np.min(mnist.train.labels[index])\n",
    "    max_val = np.max(mnist.train.labels[index])\n",
    "    \n",
    "    if min_val < 0.0:\n",
    "        print(\"min value is \", min_val, \", index = \", index)\n",
    "        break\n",
    "    \n",
    "    if max_val > 1.0:\n",
    "        print(\"max value is \", max_val, \", index = \", index)\n",
    "        break\n",
    "    \n",
    "print(\"\")\n",
    "print(mnist.train.labels[0])  # one-hot encoding 확인을 위한 테스트 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, input_nodes])  \n",
    "T = tf.placeholder(tf.float32, [None, output_nodes])  \n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes]))  # 은닉층 1가중치 노드\n",
    "b2 = tf.Variable(tf.random_normal([hidden_nodes]))               # 은닉층 1바이어스 노드\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([hidden_nodes, output_nodes])) # 출력층 가중치 노드\n",
    "b3 = tf.Variable(tf.random_normal([output_nodes]))               # 출력층 바이어스 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = tf.matmul(X, W2) + b2\n",
    "A2 = tf.nn.relu(Z2)\n",
    "\n",
    "Z3 = logits = tf.matmul(A2, W3) + b3\n",
    "\n",
    "y = A3 = tf.nn.softmax(Z3)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z3, labels = T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_val = tf.equal(tf.argmax(A3, 1), tf.argmax(T, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  110.51482\n",
      "epochs =  0 , step =  100 , loss_val =  6.6810265\n",
      "epochs =  0 , step =  200 , loss_val =  2.5267076\n",
      "epochs =  0 , step =  300 , loss_val =  1.5641181\n",
      "epochs =  0 , step =  400 , loss_val =  1.8561412\n",
      "epochs =  0 , step =  500 , loss_val =  2.5793672\n",
      "epochs =  1 , step =  0 , loss_val =  1.9439887\n",
      "epochs =  1 , step =  100 , loss_val =  1.7594018\n",
      "epochs =  1 , step =  200 , loss_val =  1.1566716\n",
      "epochs =  1 , step =  300 , loss_val =  1.4990185\n",
      "epochs =  1 , step =  400 , loss_val =  1.0752435\n",
      "epochs =  1 , step =  500 , loss_val =  0.94328904\n",
      "epochs =  2 , step =  0 , loss_val =  0.3657356\n",
      "epochs =  2 , step =  100 , loss_val =  0.79073244\n",
      "epochs =  2 , step =  200 , loss_val =  0.74805045\n",
      "epochs =  2 , step =  300 , loss_val =  1.0967582\n",
      "epochs =  2 , step =  400 , loss_val =  0.6143054\n",
      "epochs =  2 , step =  500 , loss_val =  0.264339\n",
      "epochs =  3 , step =  0 , loss_val =  0.70574\n",
      "epochs =  3 , step =  100 , loss_val =  0.4885299\n",
      "epochs =  3 , step =  200 , loss_val =  0.386831\n",
      "epochs =  3 , step =  300 , loss_val =  0.56778973\n",
      "epochs =  3 , step =  400 , loss_val =  0.35671565\n",
      "epochs =  3 , step =  500 , loss_val =  0.5507654\n",
      "epochs =  4 , step =  0 , loss_val =  0.37426475\n",
      "epochs =  4 , step =  100 , loss_val =  0.38735378\n",
      "epochs =  4 , step =  200 , loss_val =  0.30259922\n",
      "epochs =  4 , step =  300 , loss_val =  0.5289671\n",
      "epochs =  4 , step =  400 , loss_val =  0.4111568\n",
      "epochs =  4 , step =  500 , loss_val =  0.5460876\n",
      "epochs =  5 , step =  0 , loss_val =  0.32939625\n",
      "epochs =  5 , step =  100 , loss_val =  0.49121913\n",
      "epochs =  5 , step =  200 , loss_val =  0.4696884\n",
      "epochs =  5 , step =  300 , loss_val =  0.27654174\n",
      "epochs =  5 , step =  400 , loss_val =  0.51993245\n",
      "epochs =  5 , step =  500 , loss_val =  0.56626505\n",
      "epochs =  6 , step =  0 , loss_val =  0.189333\n",
      "epochs =  6 , step =  100 , loss_val =  0.33992267\n",
      "epochs =  6 , step =  200 , loss_val =  0.32709435\n",
      "epochs =  6 , step =  300 , loss_val =  0.41678315\n",
      "epochs =  6 , step =  400 , loss_val =  0.14688593\n",
      "epochs =  6 , step =  500 , loss_val =  0.24828407\n",
      "epochs =  7 , step =  0 , loss_val =  0.3765989\n",
      "epochs =  7 , step =  100 , loss_val =  0.33151513\n",
      "epochs =  7 , step =  200 , loss_val =  0.4221638\n",
      "epochs =  7 , step =  300 , loss_val =  0.32912993\n",
      "epochs =  7 , step =  400 , loss_val =  0.35226867\n",
      "epochs =  7 , step =  500 , loss_val =  0.42048508\n",
      "epochs =  8 , step =  0 , loss_val =  0.31497815\n",
      "epochs =  8 , step =  100 , loss_val =  0.3568989\n",
      "epochs =  8 , step =  200 , loss_val =  0.33056724\n",
      "epochs =  8 , step =  300 , loss_val =  0.18122566\n",
      "epochs =  8 , step =  400 , loss_val =  0.3687162\n",
      "epochs =  8 , step =  500 , loss_val =  0.23602948\n",
      "epochs =  9 , step =  0 , loss_val =  0.3170226\n",
      "epochs =  9 , step =  100 , loss_val =  0.2372955\n",
      "epochs =  9 , step =  200 , loss_val =  0.32798046\n",
      "epochs =  9 , step =  300 , loss_val =  0.32229972\n",
      "epochs =  9 , step =  400 , loss_val =  0.1635799\n",
      "epochs =  9 , step =  500 , loss_val =  0.22038363\n",
      "epochs =  10 , step =  0 , loss_val =  0.30283937\n",
      "epochs =  10 , step =  100 , loss_val =  0.45285198\n",
      "epochs =  10 , step =  200 , loss_val =  0.4890481\n",
      "epochs =  10 , step =  300 , loss_val =  0.17728658\n",
      "epochs =  10 , step =  400 , loss_val =  0.32159653\n",
      "epochs =  10 , step =  500 , loss_val =  0.38732666\n",
      "epochs =  11 , step =  0 , loss_val =  0.3251218\n",
      "epochs =  11 , step =  100 , loss_val =  0.47917834\n",
      "epochs =  11 , step =  200 , loss_val =  0.1919583\n",
      "epochs =  11 , step =  300 , loss_val =  0.2121932\n",
      "epochs =  11 , step =  400 , loss_val =  0.23342852\n",
      "epochs =  11 , step =  500 , loss_val =  0.10532115\n",
      "epochs =  12 , step =  0 , loss_val =  0.22169279\n",
      "epochs =  12 , step =  100 , loss_val =  0.10982668\n",
      "epochs =  12 , step =  200 , loss_val =  0.36158627\n",
      "epochs =  12 , step =  300 , loss_val =  0.122943595\n",
      "epochs =  12 , step =  400 , loss_val =  0.2891225\n",
      "epochs =  12 , step =  500 , loss_val =  0.24486774\n",
      "epochs =  13 , step =  0 , loss_val =  0.2648649\n",
      "epochs =  13 , step =  100 , loss_val =  0.36143315\n",
      "epochs =  13 , step =  200 , loss_val =  0.43970913\n",
      "epochs =  13 , step =  300 , loss_val =  0.38884535\n",
      "epochs =  13 , step =  400 , loss_val =  0.34715036\n",
      "epochs =  13 , step =  500 , loss_val =  0.23730539\n",
      "epochs =  14 , step =  0 , loss_val =  0.1648563\n",
      "epochs =  14 , step =  100 , loss_val =  0.20972021\n",
      "epochs =  14 , step =  200 , loss_val =  0.39161828\n",
      "epochs =  14 , step =  300 , loss_val =  0.15298395\n",
      "epochs =  14 , step =  400 , loss_val =  0.33682418\n",
      "epochs =  14 , step =  500 , loss_val =  0.4090064\n",
      "epochs =  15 , step =  0 , loss_val =  0.20269318\n",
      "epochs =  15 , step =  100 , loss_val =  0.20976743\n",
      "epochs =  15 , step =  200 , loss_val =  0.26769578\n",
      "epochs =  15 , step =  300 , loss_val =  0.10618327\n",
      "epochs =  15 , step =  400 , loss_val =  0.07307862\n",
      "epochs =  15 , step =  500 , loss_val =  0.255211\n",
      "epochs =  16 , step =  0 , loss_val =  0.13543797\n",
      "epochs =  16 , step =  100 , loss_val =  0.2383771\n",
      "epochs =  16 , step =  200 , loss_val =  0.23300102\n",
      "epochs =  16 , step =  300 , loss_val =  0.22235507\n",
      "epochs =  16 , step =  400 , loss_val =  0.25801414\n",
      "epochs =  16 , step =  500 , loss_val =  0.29927835\n",
      "epochs =  17 , step =  0 , loss_val =  0.1522173\n",
      "epochs =  17 , step =  100 , loss_val =  0.092261665\n",
      "epochs =  17 , step =  200 , loss_val =  0.21716246\n",
      "epochs =  17 , step =  300 , loss_val =  0.16944858\n",
      "epochs =  17 , step =  400 , loss_val =  0.14414158\n",
      "epochs =  17 , step =  500 , loss_val =  0.19767527\n",
      "epochs =  18 , step =  0 , loss_val =  0.20138437\n",
      "epochs =  18 , step =  100 , loss_val =  0.09420188\n",
      "epochs =  18 , step =  200 , loss_val =  0.40490714\n",
      "epochs =  18 , step =  300 , loss_val =  0.3973862\n",
      "epochs =  18 , step =  400 , loss_val =  0.2770544\n",
      "epochs =  18 , step =  500 , loss_val =  0.14833066\n",
      "epochs =  19 , step =  0 , loss_val =  0.2653419\n",
      "epochs =  19 , step =  100 , loss_val =  0.08451011\n",
      "epochs =  19 , step =  200 , loss_val =  0.08340179\n",
      "epochs =  19 , step =  300 , loss_val =  0.13803983\n",
      "epochs =  19 , step =  400 , loss_val =  0.15384775\n",
      "epochs =  19 , step =  500 , loss_val =  0.25235596\n",
      "epochs =  20 , step =  0 , loss_val =  0.07556539\n",
      "epochs =  20 , step =  100 , loss_val =  0.17783424\n",
      "epochs =  20 , step =  200 , loss_val =  0.42101407\n",
      "epochs =  20 , step =  300 , loss_val =  0.074866064\n",
      "epochs =  20 , step =  400 , loss_val =  0.09237893\n",
      "epochs =  20 , step =  500 , loss_val =  0.31606004\n",
      "epochs =  21 , step =  0 , loss_val =  0.07226721\n",
      "epochs =  21 , step =  100 , loss_val =  0.32842663\n",
      "epochs =  21 , step =  200 , loss_val =  0.12162346\n",
      "epochs =  21 , step =  300 , loss_val =  0.21456201\n",
      "epochs =  21 , step =  400 , loss_val =  0.150307\n",
      "epochs =  21 , step =  500 , loss_val =  0.26550305\n",
      "epochs =  22 , step =  0 , loss_val =  0.2758912\n",
      "epochs =  22 , step =  100 , loss_val =  0.25573868\n",
      "epochs =  22 , step =  200 , loss_val =  0.13578749\n",
      "epochs =  22 , step =  300 , loss_val =  0.2424325\n",
      "epochs =  22 , step =  400 , loss_val =  0.19915785\n",
      "epochs =  22 , step =  500 , loss_val =  0.13165091\n",
      "epochs =  23 , step =  0 , loss_val =  0.06789558\n",
      "epochs =  23 , step =  100 , loss_val =  0.08670578\n",
      "epochs =  23 , step =  200 , loss_val =  0.20565079\n",
      "epochs =  23 , step =  300 , loss_val =  0.26120782\n",
      "epochs =  23 , step =  400 , loss_val =  0.029483158\n",
      "epochs =  23 , step =  500 , loss_val =  0.34552762\n",
      "epochs =  24 , step =  0 , loss_val =  0.09308037\n",
      "epochs =  24 , step =  100 , loss_val =  0.16578946\n",
      "epochs =  24 , step =  200 , loss_val =  0.108084984\n",
      "epochs =  24 , step =  300 , loss_val =  0.11874887\n",
      "epochs =  24 , step =  400 , loss_val =  0.12765622\n",
      "epochs =  24 , step =  500 , loss_val =  0.39596826\n",
      "epochs =  25 , step =  0 , loss_val =  0.12295954\n",
      "epochs =  25 , step =  100 , loss_val =  0.13652414\n",
      "epochs =  25 , step =  200 , loss_val =  0.13115431\n",
      "epochs =  25 , step =  300 , loss_val =  0.08242031\n",
      "epochs =  25 , step =  400 , loss_val =  0.17407677\n",
      "epochs =  25 , step =  500 , loss_val =  0.1550311\n",
      "epochs =  26 , step =  0 , loss_val =  0.2676329\n",
      "epochs =  26 , step =  100 , loss_val =  0.14039335\n",
      "epochs =  26 , step =  200 , loss_val =  0.14770094\n",
      "epochs =  26 , step =  300 , loss_val =  0.15108134\n",
      "epochs =  26 , step =  400 , loss_val =  0.2273272\n",
      "epochs =  26 , step =  500 , loss_val =  0.16259505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  27 , step =  0 , loss_val =  0.06839944\n",
      "epochs =  27 , step =  100 , loss_val =  0.09359114\n",
      "epochs =  27 , step =  200 , loss_val =  0.18061602\n",
      "epochs =  27 , step =  300 , loss_val =  0.20323673\n",
      "epochs =  27 , step =  400 , loss_val =  0.13204506\n",
      "epochs =  27 , step =  500 , loss_val =  0.22526951\n",
      "epochs =  28 , step =  0 , loss_val =  0.16242339\n",
      "epochs =  28 , step =  100 , loss_val =  0.22575755\n",
      "epochs =  28 , step =  200 , loss_val =  0.19983794\n",
      "epochs =  28 , step =  300 , loss_val =  0.21777904\n",
      "epochs =  28 , step =  400 , loss_val =  0.28066787\n",
      "epochs =  28 , step =  500 , loss_val =  0.2328795\n",
      "epochs =  29 , step =  0 , loss_val =  0.09686224\n",
      "epochs =  29 , step =  100 , loss_val =  0.13821733\n",
      "epochs =  29 , step =  200 , loss_val =  0.11468318\n",
      "epochs =  29 , step =  300 , loss_val =  0.19488902\n",
      "epochs =  29 , step =  400 , loss_val =  0.20409243\n",
      "epochs =  29 , step =  500 , loss_val =  0.16167486\n",
      "epochs =  30 , step =  0 , loss_val =  0.04440069\n",
      "epochs =  30 , step =  100 , loss_val =  0.2225008\n",
      "epochs =  30 , step =  200 , loss_val =  0.15298456\n",
      "epochs =  30 , step =  300 , loss_val =  0.1865563\n",
      "epochs =  30 , step =  400 , loss_val =  0.17447478\n",
      "epochs =  30 , step =  500 , loss_val =  0.10293992\n",
      "epochs =  31 , step =  0 , loss_val =  0.1260835\n",
      "epochs =  31 , step =  100 , loss_val =  0.2300546\n",
      "epochs =  31 , step =  200 , loss_val =  0.1078437\n",
      "epochs =  31 , step =  300 , loss_val =  0.21668255\n",
      "epochs =  31 , step =  400 , loss_val =  0.17564076\n",
      "epochs =  31 , step =  500 , loss_val =  0.11945456\n",
      "epochs =  32 , step =  0 , loss_val =  0.17201854\n",
      "epochs =  32 , step =  100 , loss_val =  0.24591927\n",
      "epochs =  32 , step =  200 , loss_val =  0.17623587\n",
      "epochs =  32 , step =  300 , loss_val =  0.14429899\n",
      "epochs =  32 , step =  400 , loss_val =  0.23652309\n",
      "epochs =  32 , step =  500 , loss_val =  0.13960633\n",
      "epochs =  33 , step =  0 , loss_val =  0.07493318\n",
      "epochs =  33 , step =  100 , loss_val =  0.20430812\n",
      "epochs =  33 , step =  200 , loss_val =  0.1854471\n",
      "epochs =  33 , step =  300 , loss_val =  0.22754893\n",
      "epochs =  33 , step =  400 , loss_val =  0.043668367\n",
      "epochs =  33 , step =  500 , loss_val =  0.116478555\n",
      "epochs =  34 , step =  0 , loss_val =  0.23788965\n",
      "epochs =  34 , step =  100 , loss_val =  0.16981906\n",
      "epochs =  34 , step =  200 , loss_val =  0.12561677\n",
      "epochs =  34 , step =  300 , loss_val =  0.16134132\n",
      "epochs =  34 , step =  400 , loss_val =  0.21973248\n",
      "epochs =  34 , step =  500 , loss_val =  0.23347461\n",
      "epochs =  35 , step =  0 , loss_val =  0.11784714\n",
      "epochs =  35 , step =  100 , loss_val =  0.13445446\n",
      "epochs =  35 , step =  200 , loss_val =  0.10837442\n",
      "epochs =  35 , step =  300 , loss_val =  0.16442737\n",
      "epochs =  35 , step =  400 , loss_val =  0.16990083\n",
      "epochs =  35 , step =  500 , loss_val =  0.15821707\n",
      "epochs =  36 , step =  0 , loss_val =  0.19325686\n",
      "epochs =  36 , step =  100 , loss_val =  0.29021955\n",
      "epochs =  36 , step =  200 , loss_val =  0.06469794\n",
      "epochs =  36 , step =  300 , loss_val =  0.19380088\n",
      "epochs =  36 , step =  400 , loss_val =  0.16441153\n",
      "epochs =  36 , step =  500 , loss_val =  0.23327564\n",
      "epochs =  37 , step =  0 , loss_val =  0.14698793\n",
      "epochs =  37 , step =  100 , loss_val =  0.13906296\n",
      "epochs =  37 , step =  200 , loss_val =  0.17883739\n",
      "epochs =  37 , step =  300 , loss_val =  0.32644594\n",
      "epochs =  37 , step =  400 , loss_val =  0.22723885\n",
      "epochs =  37 , step =  500 , loss_val =  0.12596224\n",
      "epochs =  38 , step =  0 , loss_val =  0.14726572\n",
      "epochs =  38 , step =  100 , loss_val =  0.08112904\n",
      "epochs =  38 , step =  200 , loss_val =  0.31541002\n",
      "epochs =  38 , step =  300 , loss_val =  0.1654184\n",
      "epochs =  38 , step =  400 , loss_val =  0.15667945\n",
      "epochs =  38 , step =  500 , loss_val =  0.18022104\n",
      "epochs =  39 , step =  0 , loss_val =  0.29238972\n",
      "epochs =  39 , step =  100 , loss_val =  0.19847506\n",
      "epochs =  39 , step =  200 , loss_val =  0.0624143\n",
      "epochs =  39 , step =  300 , loss_val =  0.17495075\n",
      "epochs =  39 , step =  400 , loss_val =  0.16264173\n",
      "epochs =  39 , step =  500 , loss_val =  0.13593157\n",
      "epochs =  40 , step =  0 , loss_val =  0.15587053\n",
      "epochs =  40 , step =  100 , loss_val =  0.100704454\n",
      "epochs =  40 , step =  200 , loss_val =  0.12976192\n",
      "epochs =  40 , step =  300 , loss_val =  0.083479665\n",
      "epochs =  40 , step =  400 , loss_val =  0.06800644\n",
      "epochs =  40 , step =  500 , loss_val =  0.18456632\n",
      "epochs =  41 , step =  0 , loss_val =  0.07279935\n",
      "epochs =  41 , step =  100 , loss_val =  0.19762407\n",
      "epochs =  41 , step =  200 , loss_val =  0.14197625\n",
      "epochs =  41 , step =  300 , loss_val =  0.37106472\n",
      "epochs =  41 , step =  400 , loss_val =  0.13180195\n",
      "epochs =  41 , step =  500 , loss_val =  0.11946511\n",
      "epochs =  42 , step =  0 , loss_val =  0.24432276\n",
      "epochs =  42 , step =  100 , loss_val =  0.106000215\n",
      "epochs =  42 , step =  200 , loss_val =  0.12567908\n",
      "epochs =  42 , step =  300 , loss_val =  0.113842525\n",
      "epochs =  42 , step =  400 , loss_val =  0.13035789\n",
      "epochs =  42 , step =  500 , loss_val =  0.34201857\n",
      "epochs =  43 , step =  0 , loss_val =  0.16118322\n",
      "epochs =  43 , step =  100 , loss_val =  0.1636462\n",
      "epochs =  43 , step =  200 , loss_val =  0.09784003\n",
      "epochs =  43 , step =  300 , loss_val =  0.20442556\n",
      "epochs =  43 , step =  400 , loss_val =  0.17904921\n",
      "epochs =  43 , step =  500 , loss_val =  0.10014486\n",
      "epochs =  44 , step =  0 , loss_val =  0.046359725\n",
      "epochs =  44 , step =  100 , loss_val =  0.078565024\n",
      "epochs =  44 , step =  200 , loss_val =  0.12959506\n",
      "epochs =  44 , step =  300 , loss_val =  0.15392071\n",
      "epochs =  44 , step =  400 , loss_val =  0.13856158\n",
      "epochs =  44 , step =  500 , loss_val =  0.109197386\n",
      "epochs =  45 , step =  0 , loss_val =  0.023127213\n",
      "epochs =  45 , step =  100 , loss_val =  0.06466469\n",
      "epochs =  45 , step =  200 , loss_val =  0.23435836\n",
      "epochs =  45 , step =  300 , loss_val =  0.19822879\n",
      "epochs =  45 , step =  400 , loss_val =  0.09589147\n",
      "epochs =  45 , step =  500 , loss_val =  0.08722047\n",
      "epochs =  46 , step =  0 , loss_val =  0.23247805\n",
      "epochs =  46 , step =  100 , loss_val =  0.05916471\n",
      "epochs =  46 , step =  200 , loss_val =  0.1415381\n",
      "epochs =  46 , step =  300 , loss_val =  0.108788945\n",
      "epochs =  46 , step =  400 , loss_val =  0.07391533\n",
      "epochs =  46 , step =  500 , loss_val =  0.051104575\n",
      "epochs =  47 , step =  0 , loss_val =  0.100915775\n",
      "epochs =  47 , step =  100 , loss_val =  0.24689245\n",
      "epochs =  47 , step =  200 , loss_val =  0.025469081\n",
      "epochs =  47 , step =  300 , loss_val =  0.097971156\n",
      "epochs =  47 , step =  400 , loss_val =  0.3145943\n",
      "epochs =  47 , step =  500 , loss_val =  0.08432687\n",
      "epochs =  48 , step =  0 , loss_val =  0.06500046\n",
      "epochs =  48 , step =  100 , loss_val =  0.11159067\n",
      "epochs =  48 , step =  200 , loss_val =  0.10083046\n",
      "epochs =  48 , step =  300 , loss_val =  0.09056047\n",
      "epochs =  48 , step =  400 , loss_val =  0.27876088\n",
      "epochs =  48 , step =  500 , loss_val =  0.21797031\n",
      "epochs =  49 , step =  0 , loss_val =  0.09033732\n",
      "epochs =  49 , step =  100 , loss_val =  0.078310765\n",
      "epochs =  49 , step =  200 , loss_val =  0.14400561\n",
      "epochs =  49 , step =  300 , loss_val =  0.08029649\n",
      "epochs =  49 , step =  400 , loss_val =  0.15751071\n",
      "epochs =  49 , step =  500 , loss_val =  0.08532408\n",
      "\n",
      "Elapsed Time =>  0:00:29.461214\n",
      "\n",
      "Accuracy = 0.9426\n",
      "length of index_label_list =  10000\n",
      "false label count =  574\n",
      "\n",
      "length of index_label_false_list_1 574\n",
      "\n",
      "length of index_label_false_list_2 574\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "index_label_false_list_2 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images\n",
    "    test_t_data = mnist.test.labels\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))\n",
    "    \n",
    "    # numpy type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_2.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_2\", len(index_label_false_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 9, 3], [8, 5, 9], [66, 6, 7], [77, 2, 1], [149, 2, 8], [241, 9, 8], [247, 4, 2], [268, 8, 9], [289, 5, 8], [300, 4, 1], [303, 2, 7], [320, 9, 7], [321, 2, 7], [340, 5, 3], [341, 6, 4], [362, 2, 7], [386, 6, 5], [389, 9, 4], [445, 6, 0], [447, 4, 9], [449, 3, 5], [478, 5, 4], [479, 9, 5], [495, 8, 2], [507, 3, 5], [528, 3, 2], [551, 7, 3], [582, 8, 2], [613, 2, 8], [619, 1, 8], [654, 5, 8], [659, 2, 8], [685, 8, 5], [691, 8, 4], [717, 0, 7], [723, 0, 5], [774, 4, 9], [813, 9, 8], [830, 2, 4], [839, 8, 3], [866, 5, 4], [877, 8, 2], [882, 9, 7], [896, 0, 2], [900, 1, 3], [924, 2, 7], [938, 3, 5], [939, 2, 8], [947, 8, 9], [951, 5, 7], [965, 6, 5], [975, 2, 3], [982, 3, 2], [992, 9, 7], [1003, 5, 3], [1012, 7, 9], [1014, 6, 5], [1017, 6, 2], [1032, 5, 8], [1039, 7, 8], [1050, 2, 6], [1062, 3, 7], [1082, 5, 1], [1112, 4, 6], [1114, 3, 8], [1124, 8, 5], [1128, 3, 7], [1178, 4, 0], [1181, 6, 1], [1182, 6, 5], [1191, 0, 7], [1194, 7, 2], [1200, 8, 3], [1204, 3, 2], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1243, 5, 4], [1247, 9, 5], [1248, 8, 5], [1260, 7, 1], [1272, 5, 8], [1287, 8, 9], [1289, 5, 3], [1299, 5, 7], [1319, 8, 6], [1320, 8, 3], [1325, 8, 6], [1328, 7, 9], [1348, 2, 6], [1364, 8, 2], [1378, 5, 8], [1403, 1, 8], [1410, 2, 4], [1411, 0, 8], [1414, 9, 4], [1433, 8, 3], [1444, 6, 4], [1453, 4, 9], [1463, 3, 7], [1465, 4, 6], [1466, 5, 3], [1468, 0, 6], [1469, 3, 5], [1500, 7, 3], [1522, 7, 9], [1527, 1, 5], [1530, 8, 7], [1531, 3, 1], [1549, 4, 2], [1553, 9, 3], [1569, 6, 7], [1570, 0, 2], [1571, 4, 9], [1581, 7, 9], [1584, 8, 9], [1601, 3, 7], [1609, 2, 6], [1611, 3, 5], [1617, 3, 8], [1670, 5, 2], [1681, 3, 7], [1709, 9, 5], [1718, 7, 3], [1732, 9, 5], [1737, 5, 3], [1740, 8, 5], [1759, 8, 4], [1772, 7, 4], [1782, 8, 3], [1790, 2, 7], [1794, 0, 5], [1800, 6, 4], [1809, 7, 9], [1813, 8, 2], [1819, 6, 5], [1822, 6, 5], [1850, 8, 7], [1857, 6, 4], [1901, 9, 4], [1903, 7, 2], [1913, 3, 8], [1917, 5, 8], [1938, 4, 6], [1941, 7, 2], [1952, 9, 8], [1963, 4, 9], [1970, 5, 3], [1976, 3, 5], [1984, 2, 0], [1987, 0, 6], [1990, 6, 4], [2011, 3, 2], [2016, 7, 2], [2018, 1, 8], [2023, 0, 5], [2040, 5, 8], [2043, 4, 8], [2053, 4, 9], [2063, 7, 5], [2070, 7, 4], [2091, 7, 3], [2098, 2, 0], [2109, 3, 4], [2118, 6, 0], [2121, 8, 6], [2125, 5, 6], [2129, 9, 8], [2130, 4, 9], [2135, 6, 1], [2145, 4, 2], [2174, 3, 5], [2182, 1, 2], [2185, 0, 5], [2189, 9, 1], [2198, 2, 1], [2225, 8, 9], [2237, 5, 6], [2266, 1, 6], [2272, 8, 6], [2291, 5, 7], [2293, 9, 6], [2299, 2, 7], [2325, 7, 2], [2333, 0, 2], [2369, 5, 6], [2371, 4, 9], [2378, 0, 2], [2387, 9, 1], [2394, 4, 9], [2406, 9, 1], [2414, 9, 4], [2425, 8, 3], [2433, 2, 1], [2455, 0, 6], [2488, 2, 4], [2526, 5, 3], [2534, 3, 5], [2542, 6, 5], [2545, 5, 3], [2551, 3, 8], [2556, 5, 8], [2560, 3, 6], [2574, 5, 9], [2589, 9, 0], [2598, 8, 2], [2607, 7, 2], [2610, 2, 8], [2618, 3, 5], [2631, 0, 6], [2645, 4, 9], [2648, 9, 0], [2654, 6, 1], [2684, 3, 9], [2695, 7, 4], [2699, 2, 6], [2720, 9, 4], [2721, 6, 2], [2730, 7, 2], [2743, 5, 8], [2751, 6, 5], [2761, 0, 6], [2877, 4, 7], [2906, 3, 5], [2909, 5, 9], [2921, 3, 2], [2927, 3, 2], [2930, 5, 7], [2939, 9, 5], [2945, 3, 7], [2952, 3, 5], [2979, 9, 7], [2986, 5, 6], [2995, 6, 5], [3005, 9, 1], [3030, 6, 2], [3033, 6, 4], [3060, 9, 1], [3073, 1, 2], [3100, 5, 3], [3110, 3, 5], [3117, 5, 9], [3129, 3, 2], [3130, 6, 0], [3136, 7, 8], [3176, 2, 7], [3183, 5, 8], [3185, 0, 6], [3189, 7, 6], [3205, 8, 1], [3206, 8, 3], [3344, 6, 8], [3373, 7, 9], [3376, 7, 9], [3412, 0, 9], [3503, 9, 1], [3520, 6, 4], [3549, 3, 2], [3550, 6, 5], [3558, 5, 0], [3559, 8, 3], [3565, 5, 8], [3567, 8, 5], [3574, 0, 7], [3575, 7, 8], [3597, 9, 3], [3604, 7, 4], [3634, 0, 2], [3662, 8, 6], [3681, 2, 3], [3702, 5, 9], [3718, 4, 9], [3727, 8, 4], [3742, 3, 8], [3751, 7, 1], [3757, 8, 3], [3763, 5, 4], [3767, 7, 3], [3773, 2, 3], [3778, 5, 2], [3780, 4, 2], [3796, 2, 8], [3806, 5, 6], [3808, 7, 3], [3810, 5, 8], [3817, 2, 4], [3818, 0, 6], [3821, 9, 4], [3833, 8, 1], [3838, 7, 1], [3846, 6, 2], [3853, 6, 5], [3855, 5, 8], [3893, 5, 6], [3902, 5, 3], [3906, 1, 2], [3926, 9, 3], [3941, 4, 2], [3943, 3, 5], [3946, 2, 8], [3962, 3, 2], [3968, 5, 3], [3976, 7, 1], [3984, 9, 1], [3985, 9, 4], [3995, 3, 5], [4000, 9, 4], [4007, 7, 4], [4027, 7, 4], [4044, 3, 5], [4065, 0, 6], [4075, 8, 3], [4078, 9, 3], [4091, 0, 5], [4093, 9, 4], [4102, 7, 9], [4159, 8, 3], [4163, 9, 0], [4176, 2, 7], [4199, 7, 9], [4208, 0, 6], [4211, 6, 5], [4224, 9, 7], [4248, 2, 4], [4256, 3, 2], [4265, 4, 7], [4268, 4, 2], [4272, 9, 4], [4286, 0, 5], [4289, 2, 7], [4300, 5, 8], [4306, 3, 8], [4314, 9, 7], [4315, 5, 9], [4317, 3, 9], [4327, 0, 5], [4344, 9, 7], [4355, 5, 9], [4374, 5, 6], [4380, 8, 5], [4411, 8, 3], [4433, 7, 2], [4435, 3, 7], [4437, 3, 2], [4439, 6, 4], [4443, 3, 2], [4497, 8, 7], [4500, 9, 1], [4523, 8, 3], [4536, 6, 5], [4547, 6, 4], [4548, 5, 6], [4551, 7, 4], [4575, 4, 9], [4578, 7, 9], [4601, 8, 4], [4639, 8, 9], [4640, 8, 2], [4690, 7, 2], [4731, 8, 7], [4739, 0, 7], [4742, 7, 4], [4761, 9, 5], [4807, 8, 3], [4823, 9, 8], [4833, 3, 2], [4879, 8, 6], [4880, 0, 8], [4910, 9, 4], [4918, 9, 7], [4990, 3, 2], [5054, 3, 8], [5062, 3, 9], [5067, 3, 2], [5068, 4, 1], [5140, 3, 5], [5143, 3, 5], [5165, 0, 5], [5183, 8, 4], [5201, 4, 9], [5210, 9, 4], [5246, 7, 1], [5283, 3, 8], [5331, 1, 6], [5401, 6, 3], [5420, 5, 3], [5457, 1, 8], [5586, 8, 2], [5600, 7, 9], [5611, 8, 5], [5613, 0, 6], [5634, 2, 8], [5642, 1, 8], [5653, 0, 6], [5654, 7, 9], [5676, 4, 2], [5677, 4, 2], [5678, 8, 5], [5709, 7, 9], [5714, 7, 9], [5718, 0, 5], [5735, 5, 6], [5749, 8, 6], [5757, 9, 7], [5841, 3, 5], [5845, 7, 9], [5854, 7, 4], [5887, 7, 9], [5888, 4, 0], [5912, 3, 5], [5913, 5, 3], [5936, 4, 9], [5945, 3, 8], [5955, 3, 8], [5972, 5, 3], [5973, 3, 8], [5982, 5, 3], [5985, 5, 8], [5996, 9, 4], [5997, 5, 8], [6011, 3, 2], [6030, 3, 8], [6035, 2, 6], [6045, 3, 7], [6065, 3, 8], [6091, 9, 5], [6101, 1, 8], [6112, 9, 8], [6124, 9, 8], [6139, 3, 2], [6157, 9, 8], [6160, 3, 8], [6166, 9, 7], [6172, 9, 8], [6351, 0, 6], [6386, 5, 6], [6390, 5, 8], [6391, 2, 6], [6392, 5, 2], [6416, 9, 8], [6421, 3, 2], [6426, 0, 6], [6505, 9, 0], [6555, 8, 9], [6560, 9, 3], [6572, 1, 2], [6575, 3, 5], [6576, 7, 1], [6580, 0, 2], [6590, 0, 5], [6597, 0, 9], [6599, 7, 1], [6603, 8, 5], [6608, 9, 4], [6614, 2, 7], [6625, 8, 2], [6642, 9, 5], [6645, 2, 8], [6651, 0, 2], [6765, 8, 6], [6783, 1, 6], [6793, 9, 4], [6847, 6, 4], [7089, 9, 4], [7121, 8, 7], [7130, 3, 8], [7208, 8, 7], [7216, 0, 5], [7233, 3, 5], [7248, 3, 5], [7259, 8, 3], [7338, 4, 8], [7432, 7, 1], [7434, 4, 8], [7444, 8, 5], [7446, 0, 2], [7451, 5, 6], [7541, 5, 4], [7643, 5, 3], [7797, 5, 6], [7800, 3, 2], [7842, 5, 6], [7876, 2, 4], [7899, 1, 8], [7915, 7, 9], [7921, 8, 6], [7945, 2, 6], [7991, 9, 8], [8020, 1, 8], [8094, 2, 1], [8119, 2, 4], [8123, 6, 4], [8156, 3, 9], [8171, 3, 5], [8183, 8, 5], [8198, 2, 4], [8207, 9, 4], [8246, 3, 9], [8253, 2, 9], [8263, 3, 9], [8272, 3, 8], [8273, 0, 7], [8277, 3, 9], [8278, 0, 5], [8279, 8, 5], [8293, 3, 9], [8294, 8, 5], [8308, 3, 9], [8318, 2, 3], [8322, 9, 2], [8325, 0, 5], [8339, 8, 4], [8358, 9, 7], [8362, 3, 5], [8382, 0, 6], [8406, 4, 9], [8408, 8, 6], [8426, 9, 4], [8502, 5, 8], [8519, 7, 3], [8863, 5, 6], [9009, 7, 2], [9015, 7, 2], [9022, 3, 2], [9024, 7, 2], [9025, 1, 8], [9158, 0, 7], [9163, 3, 2], [9253, 4, 9], [9280, 8, 5], [9422, 5, 2], [9425, 0, 6], [9482, 5, 2], [9544, 9, 7], [9587, 9, 4], [9612, 1, 2], [9634, 0, 3], [9662, 3, 2], [9664, 2, 7], [9679, 6, 5], [9700, 2, 8], [9716, 2, 5], [9729, 5, 6], [9732, 8, 5], [9733, 9, 8], [9735, 4, 1], [9738, 4, 6], [9745, 4, 6], [9749, 5, 6], [9758, 3, 5], [9764, 4, 9], [9768, 2, 0], [9770, 5, 0], [9777, 5, 0], [9779, 2, 0], [9792, 4, 9], [9808, 9, 4], [9831, 5, 8], [9839, 2, 7], [9858, 6, 8], [9862, 6, 8], [9867, 2, 8], [9879, 0, 6], [9883, 5, 1], [9888, 6, 0], [9891, 9, 4], [9910, 8, 3], [9924, 9, 4], [9941, 5, 1], [9944, 3, 5], [9970, 5, 3], [9976, 6, 4], [9980, 2, 3], [9982, 5, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 9, 3], [8, 5, 9], [66, 6, 7], [77, 2, 1], [149, 2, 8], [241, 9, 8], [247, 4, 2], [268, 8, 9], [289, 5, 8], [300, 4, 1], [303, 2, 7], [320, 9, 7], [321, 2, 7], [340, 5, 3], [341, 6, 4], [362, 2, 7], [386, 6, 5], [389, 9, 4], [445, 6, 0], [447, 4, 9], [449, 3, 5], [478, 5, 4], [479, 9, 5], [495, 8, 2], [507, 3, 5], [528, 3, 2], [551, 7, 3], [582, 8, 2], [613, 2, 8], [619, 1, 8], [654, 5, 8], [659, 2, 8], [685, 8, 5], [691, 8, 4], [717, 0, 7], [723, 0, 5], [774, 4, 9], [813, 9, 8], [830, 2, 4], [839, 8, 3], [866, 5, 4], [877, 8, 2], [882, 9, 7], [896, 0, 2], [900, 1, 3], [924, 2, 7], [938, 3, 5], [939, 2, 8], [947, 8, 9], [951, 5, 7], [965, 6, 5], [975, 2, 3], [982, 3, 2], [992, 9, 7], [1003, 5, 3], [1012, 7, 9], [1014, 6, 5], [1017, 6, 2], [1032, 5, 8], [1039, 7, 8], [1050, 2, 6], [1062, 3, 7], [1082, 5, 1], [1112, 4, 6], [1114, 3, 8], [1124, 8, 5], [1128, 3, 7], [1178, 4, 0], [1181, 6, 1], [1182, 6, 5], [1191, 0, 7], [1194, 7, 2], [1200, 8, 3], [1204, 3, 2], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1243, 5, 4], [1247, 9, 5], [1248, 8, 5], [1260, 7, 1], [1272, 5, 8], [1287, 8, 9], [1289, 5, 3], [1299, 5, 7], [1319, 8, 6], [1320, 8, 3], [1325, 8, 6], [1328, 7, 9], [1348, 2, 6], [1364, 8, 2], [1378, 5, 8], [1403, 1, 8], [1410, 2, 4], [1411, 0, 8], [1414, 9, 4], [1433, 8, 3], [1444, 6, 4], [1453, 4, 9], [1463, 3, 7], [1465, 4, 6], [1466, 5, 3], [1468, 0, 6], [1469, 3, 5], [1500, 7, 3], [1522, 7, 9], [1527, 1, 5], [1530, 8, 7], [1531, 3, 1], [1549, 4, 2], [1553, 9, 3], [1569, 6, 7], [1570, 0, 2], [1571, 4, 9], [1581, 7, 9], [1584, 8, 9], [1601, 3, 7], [1609, 2, 6], [1611, 3, 5], [1617, 3, 8], [1670, 5, 2], [1681, 3, 7], [1709, 9, 5], [1718, 7, 3], [1732, 9, 5], [1737, 5, 3], [1740, 8, 5], [1759, 8, 4], [1772, 7, 4], [1782, 8, 3], [1790, 2, 7], [1794, 0, 5], [1800, 6, 4], [1809, 7, 9], [1813, 8, 2], [1819, 6, 5], [1822, 6, 5], [1850, 8, 7], [1857, 6, 4], [1901, 9, 4], [1903, 7, 2], [1913, 3, 8], [1917, 5, 8], [1938, 4, 6], [1941, 7, 2], [1952, 9, 8], [1963, 4, 9], [1970, 5, 3], [1976, 3, 5], [1984, 2, 0], [1987, 0, 6], [1990, 6, 4], [2011, 3, 2], [2016, 7, 2], [2018, 1, 8], [2023, 0, 5], [2040, 5, 8], [2043, 4, 8], [2053, 4, 9], [2063, 7, 5], [2070, 7, 4], [2091, 7, 3], [2098, 2, 0], [2109, 3, 4], [2118, 6, 0], [2121, 8, 6], [2125, 5, 6], [2129, 9, 8], [2130, 4, 9], [2135, 6, 1], [2145, 4, 2], [2174, 3, 5], [2182, 1, 2], [2185, 0, 5], [2189, 9, 1], [2198, 2, 1], [2225, 8, 9], [2237, 5, 6], [2266, 1, 6], [2272, 8, 6], [2291, 5, 7], [2293, 9, 6], [2299, 2, 7], [2325, 7, 2], [2333, 0, 2], [2369, 5, 6], [2371, 4, 9], [2378, 0, 2], [2387, 9, 1], [2394, 4, 9], [2406, 9, 1], [2414, 9, 4], [2425, 8, 3], [2433, 2, 1], [2455, 0, 6], [2488, 2, 4], [2526, 5, 3], [2534, 3, 5], [2542, 6, 5], [2545, 5, 3], [2551, 3, 8], [2556, 5, 8], [2560, 3, 6], [2574, 5, 9], [2589, 9, 0], [2598, 8, 2], [2607, 7, 2], [2610, 2, 8], [2618, 3, 5], [2631, 0, 6], [2645, 4, 9], [2648, 9, 0], [2654, 6, 1], [2684, 3, 9], [2695, 7, 4], [2699, 2, 6], [2720, 9, 4], [2721, 6, 2], [2730, 7, 2], [2743, 5, 8], [2751, 6, 5], [2761, 0, 6], [2877, 4, 7], [2906, 3, 5], [2909, 5, 9], [2921, 3, 2], [2927, 3, 2], [2930, 5, 7], [2939, 9, 5], [2945, 3, 7], [2952, 3, 5], [2979, 9, 7], [2986, 5, 6], [2995, 6, 5], [3005, 9, 1], [3030, 6, 2], [3033, 6, 4], [3060, 9, 1], [3073, 1, 2], [3100, 5, 3], [3110, 3, 5], [3117, 5, 9], [3129, 3, 2], [3130, 6, 0], [3136, 7, 8], [3176, 2, 7], [3183, 5, 8], [3185, 0, 6], [3189, 7, 6], [3205, 8, 1], [3206, 8, 3], [3344, 6, 8], [3373, 7, 9], [3376, 7, 9], [3412, 0, 9], [3503, 9, 1], [3520, 6, 4], [3549, 3, 2], [3550, 6, 5], [3558, 5, 0], [3559, 8, 3], [3565, 5, 8], [3567, 8, 5], [3574, 0, 7], [3575, 7, 8], [3597, 9, 3], [3604, 7, 4], [3634, 0, 2], [3662, 8, 6], [3681, 2, 3], [3702, 5, 9], [3718, 4, 9], [3727, 8, 4], [3742, 3, 8], [3751, 7, 1], [3757, 8, 3], [3763, 5, 4], [3767, 7, 3], [3773, 2, 3], [3778, 5, 2], [3780, 4, 2], [3796, 2, 8], [3806, 5, 6], [3808, 7, 3], [3810, 5, 8], [3817, 2, 4], [3818, 0, 6], [3821, 9, 4], [3833, 8, 1], [3838, 7, 1], [3846, 6, 2], [3853, 6, 5], [3855, 5, 8], [3893, 5, 6], [3902, 5, 3], [3906, 1, 2], [3926, 9, 3], [3941, 4, 2], [3943, 3, 5], [3946, 2, 8], [3962, 3, 2], [3968, 5, 3], [3976, 7, 1], [3984, 9, 1], [3985, 9, 4], [3995, 3, 5], [4000, 9, 4], [4007, 7, 4], [4027, 7, 4], [4044, 3, 5], [4065, 0, 6], [4075, 8, 3], [4078, 9, 3], [4091, 0, 5], [4093, 9, 4], [4102, 7, 9], [4159, 8, 3], [4163, 9, 0], [4176, 2, 7], [4199, 7, 9], [4208, 0, 6], [4211, 6, 5], [4224, 9, 7], [4248, 2, 4], [4256, 3, 2], [4265, 4, 7], [4268, 4, 2], [4272, 9, 4], [4286, 0, 5], [4289, 2, 7], [4300, 5, 8], [4306, 3, 8], [4314, 9, 7], [4315, 5, 9], [4317, 3, 9], [4327, 0, 5], [4344, 9, 7], [4355, 5, 9], [4374, 5, 6], [4380, 8, 5], [4411, 8, 3], [4433, 7, 2], [4435, 3, 7], [4437, 3, 2], [4439, 6, 4], [4443, 3, 2], [4497, 8, 7], [4500, 9, 1], [4523, 8, 3], [4536, 6, 5], [4547, 6, 4], [4548, 5, 6], [4551, 7, 4], [4575, 4, 9], [4578, 7, 9], [4601, 8, 4], [4639, 8, 9], [4640, 8, 2], [4690, 7, 2], [4731, 8, 7], [4739, 0, 7], [4742, 7, 4], [4761, 9, 5], [4807, 8, 3], [4823, 9, 8], [4833, 3, 2], [4879, 8, 6], [4880, 0, 8], [4910, 9, 4], [4918, 9, 7], [4990, 3, 2], [5054, 3, 8], [5062, 3, 9], [5067, 3, 2], [5068, 4, 1], [5140, 3, 5], [5143, 3, 5], [5165, 0, 5], [5183, 8, 4], [5201, 4, 9], [5210, 9, 4], [5246, 7, 1], [5283, 3, 8], [5331, 1, 6], [5401, 6, 3], [5420, 5, 3], [5457, 1, 8], [5586, 8, 2], [5600, 7, 9], [5611, 8, 5], [5613, 0, 6], [5634, 2, 8], [5642, 1, 8], [5653, 0, 6], [5654, 7, 9], [5676, 4, 2], [5677, 4, 2], [5678, 8, 5], [5709, 7, 9], [5714, 7, 9], [5718, 0, 5], [5735, 5, 6], [5749, 8, 6], [5757, 9, 7], [5841, 3, 5], [5845, 7, 9], [5854, 7, 4], [5887, 7, 9], [5888, 4, 0], [5912, 3, 5], [5913, 5, 3], [5936, 4, 9], [5945, 3, 8], [5955, 3, 8], [5972, 5, 3], [5973, 3, 8], [5982, 5, 3], [5985, 5, 8], [5996, 9, 4], [5997, 5, 8], [6011, 3, 2], [6030, 3, 8], [6035, 2, 6], [6045, 3, 7], [6065, 3, 8], [6091, 9, 5], [6101, 1, 8], [6112, 9, 8], [6124, 9, 8], [6139, 3, 2], [6157, 9, 8], [6160, 3, 8], [6166, 9, 7], [6172, 9, 8], [6351, 0, 6], [6386, 5, 6], [6390, 5, 8], [6391, 2, 6], [6392, 5, 2], [6416, 9, 8], [6421, 3, 2], [6426, 0, 6], [6505, 9, 0], [6555, 8, 9], [6560, 9, 3], [6572, 1, 2], [6575, 3, 5], [6576, 7, 1], [6580, 0, 2], [6590, 0, 5], [6597, 0, 9], [6599, 7, 1], [6603, 8, 5], [6608, 9, 4], [6614, 2, 7], [6625, 8, 2], [6642, 9, 5], [6645, 2, 8], [6651, 0, 2], [6765, 8, 6], [6783, 1, 6], [6793, 9, 4], [6847, 6, 4], [7089, 9, 4], [7121, 8, 7], [7130, 3, 8], [7208, 8, 7], [7216, 0, 5], [7233, 3, 5], [7248, 3, 5], [7259, 8, 3], [7338, 4, 8], [7432, 7, 1], [7434, 4, 8], [7444, 8, 5], [7446, 0, 2], [7451, 5, 6], [7541, 5, 4], [7643, 5, 3], [7797, 5, 6], [7800, 3, 2], [7842, 5, 6], [7876, 2, 4], [7899, 1, 8], [7915, 7, 9], [7921, 8, 6], [7945, 2, 6], [7991, 9, 8], [8020, 1, 8], [8094, 2, 1], [8119, 2, 4], [8123, 6, 4], [8156, 3, 9], [8171, 3, 5], [8183, 8, 5], [8198, 2, 4], [8207, 9, 4], [8246, 3, 9], [8253, 2, 9], [8263, 3, 9], [8272, 3, 8], [8273, 0, 7], [8277, 3, 9], [8278, 0, 5], [8279, 8, 5], [8293, 3, 9], [8294, 8, 5], [8308, 3, 9], [8318, 2, 3], [8322, 9, 2], [8325, 0, 5], [8339, 8, 4], [8358, 9, 7], [8362, 3, 5], [8382, 0, 6], [8406, 4, 9], [8408, 8, 6], [8426, 9, 4], [8502, 5, 8], [8519, 7, 3], [8863, 5, 6], [9009, 7, 2], [9015, 7, 2], [9022, 3, 2], [9024, 7, 2], [9025, 1, 8], [9158, 0, 7], [9163, 3, 2], [9253, 4, 9], [9280, 8, 5], [9422, 5, 2], [9425, 0, 6], [9482, 5, 2], [9544, 9, 7], [9587, 9, 4], [9612, 1, 2], [9634, 0, 3], [9662, 3, 2], [9664, 2, 7], [9679, 6, 5], [9700, 2, 8], [9716, 2, 5], [9729, 5, 6], [9732, 8, 5], [9733, 9, 8], [9735, 4, 1], [9738, 4, 6], [9745, 4, 6], [9749, 5, 6], [9758, 3, 5], [9764, 4, 9], [9768, 2, 0], [9770, 5, 0], [9777, 5, 0], [9779, 2, 0], [9792, 4, 9], [9808, 9, 4], [9831, 5, 8], [9839, 2, 7], [9858, 6, 8], [9862, 6, 8], [9867, 2, 8], [9879, 0, 6], [9883, 5, 1], [9888, 6, 0], [9891, 9, 4], [9910, 8, 3], [9924, 9, 4], [9941, 5, 1], [9944, 3, 5], [9970, 5, 3], [9976, 6, 4], [9980, 2, 3], [9982, 5, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  5\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "img = test_x_data[9982].reshape(28,28)  \n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"label = \", np.argmax(test_t_data[9982]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUSEUNG\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\15일차_1123\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "100 image is saved now\n",
      "110 image is saved now\n",
      "120 image is saved now\n",
      "130 image is saved now\n",
      "140 image is saved now\n",
      "150 image is saved now\n",
      "160 image is saved now\n",
      "170 image is saved now\n",
      "180 image is saved now\n",
      "190 image is saved now\n",
      "200 image is saved now\n",
      "210 image is saved now\n",
      "220 image is saved now\n",
      "230 image is saved now\n",
      "240 image is saved now\n",
      "250 image is saved now\n",
      "260 image is saved now\n",
      "270 image is saved now\n",
      "280 image is saved now\n",
      "290 image is saved now\n",
      "300 image is saved now\n",
      "310 image is saved now\n",
      "320 image is saved now\n",
      "330 image is saved now\n",
      "340 image is saved now\n",
      "350 image is saved now\n",
      "360 image is saved now\n",
      "370 image is saved now\n",
      "380 image is saved now\n",
      "390 image is saved now\n",
      "400 image is saved now\n",
      "410 image is saved now\n",
      "420 image is saved now\n",
      "430 image is saved now\n",
      "440 image is saved now\n",
      "450 image is saved now\n",
      "460 image is saved now\n",
      "470 image is saved now\n",
      "480 image is saved now\n",
      "490 image is saved now\n",
      "500 image is saved now\n",
      "510 image is saved now\n",
      "520 image is saved now\n",
      "530 image is saved now\n",
      "540 image is saved now\n",
      "550 image is saved now\n",
      "560 image is saved now\n",
      "570 image is saved now\n",
      "Elapsed save time =>  0:17:29.215377\n",
      "Total  574  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_2:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
