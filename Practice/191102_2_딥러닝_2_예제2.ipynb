{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def predict(a1):\n",
    "    z2 = np.dot(a1,W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    z3 = np.dot(a2,W3) + b3\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    if a3 >= 0.5:\n",
    "        result = 1  # True\n",
    "    else:\n",
    "        result = 0  # False\n",
    "    \n",
    "    return a3, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(xdata, tdata):\n",
    "    delta = 1e-7   \n",
    "    \n",
    "    Z2 = np.dot(xdata, W2) + b2    \n",
    "    A2 = sigmoid(Z2)    \n",
    "    \n",
    "    Z3 = np.dot(A2, W3) + b3    \n",
    "    y = A3 = sigmoid(Z3)    \n",
    "        \n",
    "    return -np.sum( tdata*np.log(y + delta) + (1-tdata)*np.log((1 - y)+delta ) )    \n",
    "\n",
    "def loss_val(xdata, tdata):\n",
    "    delta = 1e-7   \n",
    "    \n",
    "    Z2 = np.dot(xdata, W2) + b2    \n",
    "    A2 = sigmoid(Z2)    \n",
    "    \n",
    "    Z3 = np.dot(A2, W3) + b3    \n",
    "    y = A3 = sigmoid(Z3)    \n",
    "    \n",
    "    return -np.sum( tdata*np.log(y + delta) + (1-tdata)*np.log((1 - y)+delta ) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "and_tdata = np.array([0, 0, 0, 1]).reshape(4, 1)\n",
    "or_tdata = np.array([0, 1, 1, 1]).reshape(4, 1)\n",
    "nand_tdata = np.array([1, 1, 1, 0]).reshape(4, 1)\n",
    "xor_tdata = np.array([0, 1, 1, 0]).reshape(4, 1)\n",
    "\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 2\n",
    "hidden_nodes = 10 ## 1개만 해도 돌아간다! 처음부터 너무 높히지 않고 할 것\n",
    "output_nodes = 1\n",
    "\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "initial W2 =  [[0.32515441 0.72843125 0.46404357 0.72137295 0.20715038 0.09932945\n",
      "  0.7807107  0.55779103 0.0099681  0.72727712]\n",
      " [0.13498071 0.18332076 0.08532649 0.44800331 0.06837904 0.89611391\n",
      "  0.6218476  0.6015282  0.82754099 0.72192399]]\n",
      "initial b2 =  [0.66702733 0.04252655 0.75554459 0.2042471  0.01284572 0.14328067\n",
      " 0.04778304 0.43951326 0.66359448 0.89478216]\n",
      "initial W3 =  [[0.71167068]\n",
      " [0.44234522]\n",
      " [0.75526878]\n",
      " [0.01735013]\n",
      " [0.10025782]\n",
      " [0.24667322]\n",
      " [0.25588348]\n",
      " [0.59628768]\n",
      " [0.83923151]\n",
      " [0.66765153]]\n",
      "initial b3 =  [0.28888271]\n",
      "=================================================\n",
      "\n",
      "Initial loss value =  10.600792781327598\n",
      "step =  0   , loss value =  6.350934900298324\n",
      "step =  1000   , loss value =  0.048606246358022936\n",
      "step =  2000   , loss value =  0.01685666991839603\n",
      "step =  3000   , loss value =  0.009705958755954718\n",
      "step =  4000   , loss value =  0.006687842785622596\n",
      "step =  5000   , loss value =  0.005051669375750723\n",
      "step =  6000   , loss value =  0.004034539268448234\n",
      "step =  7000   , loss value =  0.003344962132111492\n",
      "step =  8000   , loss value =  0.002848574296810037\n",
      "step =  9000   , loss value =  0.002475203801027008\n",
      "step =  10000   , loss value =  0.0021847695288900633\n",
      "\n",
      "=================================================\n",
      "updated W2 =  [[-0.82085056  2.40715732  0.25179473 -0.72341821 -3.9139379   0.38940119\n",
      "   2.30866791  1.76016457  0.84707986  0.7839434 ]\n",
      " [-0.8957359   1.79932076 -0.07939026 -0.82589961 -3.79092568  1.3544966\n",
      "   2.02214727  1.63844781  2.07498251  0.75125989]]\n",
      "updated b2 =  [ 0.9172199  -2.86148604  0.739256    0.8545233   5.61370543 -0.42713382\n",
      " -2.98175263 -2.2078573  -1.61473269  0.40435122]\n",
      "updated W3 =  [[-1.73700374]\n",
      " [ 4.18714375]\n",
      " [-0.40044588]\n",
      " [-1.61436466]\n",
      " [-9.70719963]\n",
      " [ 1.15143611]\n",
      " [ 4.30259694]\n",
      " [ 3.246933  ]\n",
      " [ 2.71215766]\n",
      " [ 0.4597659 ]]\n",
      "updated b3 =  [-3.36387047]\n",
      "Elapsed Time => 0:00:19.196700\n",
      "=================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W2 = np.random.rand(input_nodes, hidden_nodes)\n",
    "W3 = np.random.rand(hidden_nodes, output_nodes)\n",
    "    \n",
    "b2 = np.random.rand(hidden_nodes)\n",
    "b3= np.random.rand(output_nodes)\n",
    "\n",
    "f = lambda x : feed_forward(xdata, and_tdata)\n",
    "print('\\n=================================================')\n",
    "print('initial W2 = ', W2)\n",
    "print('initial b2 = ', b2)\n",
    "print('initial W3 = ', W3)\n",
    "print('initial b3 = ', b3)\n",
    "print('=================================================\\n')\n",
    "\n",
    "print(\"Initial loss value = \", loss_val(xdata, and_tdata))\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in  range(10001):\n",
    "    W2 -= learning_rate * numerical_derivative( f, W2 )\n",
    "    b2 -= learning_rate * numerical_derivative( f, b2 )\n",
    "\n",
    "    W3 -= learning_rate * numerical_derivative( f, W3 )\n",
    "    b3 -= learning_rate * numerical_derivative( f, b3 )\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "        print(\"step = \", step, \"  , loss value = \", loss_val(xdata, and_tdata))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\n=================================================')\n",
    "print('updated W2 = ', W2)\n",
    "print('updated b2 = ', b2)\n",
    "print('updated W3 = ', W3)\n",
    "print('updated b3 = ', b3)\n",
    "print(\"Elapsed Time =>\", end_time - start_time)\n",
    "print('=================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_val = [1.0738198e-06] , logical_val = 0\n",
      "real_val = [0.00060891] , logical_val = 0\n",
      "real_val = [0.00054656] , logical_val = 0\n",
      "real_val = [0.99897224] , logical_val = 1\n"
     ]
    }
   ],
   "source": [
    "for data in test_data:\n",
    "    (real_val, logical_val) = predict(data)\n",
    "    print(\"real_val =\", real_val, \", logical_val =\", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 2\n",
    "hidden_nodes = 1\n",
    "output_nodes = 1\n",
    "\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "initial W2 =  [[0.12892789]\n",
      " [0.06185661]]\n",
      "initial b2 =  [0.18558689]\n",
      "initial W3 =  [[0.87071937]]\n",
      "initial b3 =  [0.57008824]\n",
      "=================================================\n",
      "\n",
      "Initial loss value =  2.229420846210183\n",
      "step =  0   , loss value =  2.226915543498592\n",
      "step =  1000   , loss value =  0.07371443534849616\n",
      "step =  2000   , loss value =  0.031132268626958993\n",
      "step =  3000   , loss value =  0.0195459324209734\n",
      "step =  4000   , loss value =  0.014204203634038796\n",
      "step =  5000   , loss value =  0.011141419473205412\n",
      "step =  6000   , loss value =  0.009158913612122815\n",
      "step =  7000   , loss value =  0.0077721265483528\n",
      "step =  8000   , loss value =  0.006748216018061079\n",
      "step =  9000   , loss value =  0.005961537038329693\n",
      "step =  10000   , loss value =  0.00533837333564003\n",
      "\n",
      "=================================================\n",
      "updated W2 =  [[6.46380926]\n",
      " [6.46375818]]\n",
      "updated b2 =  [-3.43851261]\n",
      "updated W3 =  [[13.88713109]]\n",
      "updated b3 =  [-6.18511995]\n",
      "Elapsed Time => 0:00:02.450452\n",
      "=================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W2 = np.random.rand(input_nodes, hidden_nodes)\n",
    "W3 = np.random.rand(hidden_nodes, output_nodes)\n",
    "    \n",
    "b2 = np.random.rand(hidden_nodes)\n",
    "b3= np.random.rand(output_nodes)\n",
    "\n",
    "f = lambda x : feed_forward(xdata, or_tdata)\n",
    "print('\\n=================================================')\n",
    "print('initial W2 = ', W2)\n",
    "print('initial b2 = ', b2)\n",
    "print('initial W3 = ', W3)\n",
    "print('initial b3 = ', b3)\n",
    "print('=================================================\\n')\n",
    "\n",
    "print(\"Initial loss value = \", loss_val(xdata, or_tdata))\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in  range(10001):\n",
    "    W2 -= learning_rate * numerical_derivative( f, W2 )\n",
    "    b2 -= learning_rate * numerical_derivative( f, b2 )\n",
    "\n",
    "    W3 -= learning_rate * numerical_derivative( f, W3 )\n",
    "    b3 -= learning_rate * numerical_derivative( f, b3 )\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "        print(\"step = \", step, \"  , loss value = \", loss_val(xdata, or_tdata))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\n=================================================')\n",
    "print('updated W2 = ', W2)\n",
    "print('updated b2 = ', b2)\n",
    "print('updated W3 = ', W3)\n",
    "print('updated b3 = ', b3)\n",
    "print(\"Elapsed Time =>\", end_time - start_time)\n",
    "print('=================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_val = [0.00316307] , logical_val = 0\n",
      "real_val = [0.99914115] , logical_val = 1\n",
      "real_val = [0.99914118] , logical_val = 1\n",
      "real_val = [0.99954781] , logical_val = 1\n"
     ]
    }
   ],
   "source": [
    "for data in test_data:\n",
    "    (real_val, logical_val) = predict(data)\n",
    "    print(\"real_val =\", real_val, \", logical_val =\", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 2\n",
    "hidden_nodes = 1\n",
    "output_nodes = 1\n",
    "\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "initial W2 =  [[0.76802097]\n",
      " [0.48707409]]\n",
      "initial b2 =  [0.95854334]\n",
      "initial W3 =  [[0.61355864]]\n",
      "initial b3 =  [0.61279517]\n",
      "=================================================\n",
      "\n",
      "Initial loss value =  2.2996413678320007\n",
      "step =  0   , loss value =  2.2986004685005286\n",
      "step =  1000   , loss value =  0.1591288506036078\n",
      "step =  2000   , loss value =  0.04315612215311235\n",
      "step =  3000   , loss value =  0.024271344979611968\n",
      "step =  4000   , loss value =  0.016770723683756435\n",
      "step =  5000   , loss value =  0.012775995191696607\n",
      "step =  6000   , loss value =  0.010303209151067683\n",
      "step =  7000   , loss value =  0.00862488018150235\n",
      "step =  8000   , loss value =  0.007412507197022055\n",
      "step =  9000   , loss value =  0.0064963868469077365\n",
      "step =  10000   , loss value =  0.005780133658227427\n",
      "\n",
      "=================================================\n",
      "updated W2 =  [[5.46269573]\n",
      " [5.46269568]]\n",
      "updated b2 =  [-8.0938086]\n",
      "updated W3 =  [[-14.35346033]]\n",
      "updated b3 =  [7.51608078]\n",
      "Elapsed Time => 0:00:02.416570\n",
      "=================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W2 = np.random.rand(input_nodes, hidden_nodes)\n",
    "W3 = np.random.rand(hidden_nodes, output_nodes)\n",
    "    \n",
    "b2 = np.random.rand(hidden_nodes)\n",
    "b3= np.random.rand(output_nodes)\n",
    "\n",
    "f = lambda x : feed_forward(xdata, nand_tdata)\n",
    "print('\\n=================================================')\n",
    "print('initial W2 = ', W2)\n",
    "print('initial b2 = ', b2)\n",
    "print('initial W3 = ', W3)\n",
    "print('initial b3 = ', b3)\n",
    "print('=================================================\\n')\n",
    "\n",
    "print(\"Initial loss value = \", loss_val(xdata, nand_tdata))\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in  range(10001):\n",
    "    W2 -= learning_rate * numerical_derivative( f, W2 )\n",
    "    b2 -= learning_rate * numerical_derivative( f, b2 )\n",
    "\n",
    "    W3 -= learning_rate * numerical_derivative( f, W3 )\n",
    "    b3 -= learning_rate * numerical_derivative( f, b3 )\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "        print(\"step = \", step, \"  , loss value = \", loss_val(xdata, nand_tdata))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\n=================================================')\n",
    "print('updated W2 = ', W2)\n",
    "print('updated b2 = ', b2)\n",
    "print('updated W3 = ', W3)\n",
    "print('updated b3 = ', b3)\n",
    "print(\"Elapsed Time =>\", end_time - start_time)\n",
    "print('=================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_val = [0.99945365] , logical_val = 1\n",
      "real_val = [0.99857487] , logical_val = 1\n",
      "real_val = [0.99857487] , logical_val = 1\n",
      "real_val = [0.0023789] , logical_val = 0\n"
     ]
    }
   ],
   "source": [
    "for data in test_data:\n",
    "    (real_val, logical_val) = predict(data)\n",
    "    print(\"real_val =\", real_val, \", logical_val =\", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 2\n",
    "hidden_nodes = 2 ## XOR는 1개로는 안 됨!\n",
    "output_nodes = 1\n",
    "\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "initial W2 =  [[0.91897146 0.45605571]\n",
      " [0.47252958 0.5544793 ]]\n",
      "initial b2 =  [0.26203599 0.15811028]\n",
      "initial W3 =  [[0.07727417]\n",
      " [0.50154148]]\n",
      "initial b3 =  [0.01297816]\n",
      "=================================================\n",
      "\n",
      "Initial loss value =  2.8460485881594924\n",
      "step =  0   , loss value =  2.8210940679995287\n",
      "step =  1000   , loss value =  1.9211284153596133\n",
      "step =  2000   , loss value =  0.13147563597444828\n",
      "step =  3000   , loss value =  0.057040945288361636\n",
      "step =  4000   , loss value =  0.03599097299900228\n",
      "step =  5000   , loss value =  0.026186122370007676\n",
      "step =  6000   , loss value =  0.02054170602308346\n",
      "step =  7000   , loss value =  0.016881634694312066\n",
      "step =  8000   , loss value =  0.014319353973096003\n",
      "step =  9000   , loss value =  0.012426985668125725\n",
      "step =  10000   , loss value =  0.010973025968701346\n",
      "\n",
      "=================================================\n",
      "updated W2 =  [[5.66686066 7.46496636]\n",
      " [5.66546679 7.45754923]]\n",
      "updated b2 =  [-8.66449307 -3.41660736]\n",
      "updated W3 =  [[-13.73188689]\n",
      " [ 12.95009274]]\n",
      "updated b3 =  [-6.0719766]\n",
      "Elapsed Time =>  0:00:04.430188\n",
      "=================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W2 = np.random.rand(input_nodes, hidden_nodes)\n",
    "W3 = np.random.rand(hidden_nodes, output_nodes)\n",
    "    \n",
    "b2 = np.random.rand(hidden_nodes)\n",
    "b3= np.random.rand(output_nodes)\n",
    "\n",
    "f = lambda x : feed_forward(xdata, xor_tdata)\n",
    "print('\\n=================================================')\n",
    "print('initial W2 = ', W2)\n",
    "print('initial b2 = ', b2)\n",
    "print('initial W3 = ', W3)\n",
    "print('initial b3 = ', b3)\n",
    "print('=================================================\\n')\n",
    "\n",
    "print(\"Initial loss value = \", loss_val(xdata, xor_tdata))\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in  range(10001):\n",
    "    W2 -= learning_rate * numerical_derivative( f, W2 )\n",
    "    b2 -= learning_rate * numerical_derivative( f, b2 )\n",
    "\n",
    "    W3 -= learning_rate * numerical_derivative( f, W3 )\n",
    "    b3 -= learning_rate * numerical_derivative( f, b3 )\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "        print(\"step = \", step, \"  , loss value = \", loss_val(xdata, xor_tdata))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\n=================================================')\n",
    "print('updated W2 = ', W2)\n",
    "print('updated b2 = ', b2)\n",
    "print('updated W3 = ', W3)\n",
    "print('updated b3 = ', b3)\n",
    "print(\"Elapsed Time => \", end_time - start_time)\n",
    "print('=================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_val = [0.00346081] , logical_val = 0\n",
      "real_val = [0.9975336] , logical_val = 1\n",
      "real_val = [0.99753546] , logical_val = 1\n",
      "real_val = [0.00256629] , logical_val = 0\n"
     ]
    }
   ],
   "source": [
    "for data in test_data:\n",
    "    (real_val, logical_val) = predict(data)\n",
    "    print(\"real_val =\", real_val, \", logical_val =\", logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉층 노드(hidden_node) 개수를 늘리면 정확도는 높아지나(loss_value 감소) 최종 결과 값이 동일한 경우 개수가 적은 것을 선택하는 것이 좋다.\n",
    "\n",
    "ex) 2개 3만번 돌리면 14초 정도, 8개 3만번 돌리면 47초 정도."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
