{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1 3x3 32개 -> 5x5 32개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 3x3x32 필터 \n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "## b2 = tf.Variable(tf.random_normal([32]))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 2 3x3 32개 -> 5x5 64개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층, 3x3x32 필터 \n",
    "W3 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev=0.01))\n",
    "## b3 = tf.Variable(tf.random_normal([64]))\n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 x 14 x 32 => 14 x 14 x 64 \n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 1번째 max pooling을 통해 14 x 14 x 64 => 7 x 7 x 64\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 x 7 크기를 가진 32개의 activation map을 flatten 시킴\n",
    "A3_flat = P3_flat = tf.reshape(A3, [-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W4 = tf.Variable(tf.random_normal([7*7*64, 10], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀 값 Z4, 즉 softmax 에 들어가는 입력 값\n",
    "Z4 = logits = tf.matmul(A3_flat, W4) + b4\n",
    "\n",
    "y = A4 = tf.nn.softmax(Z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z4, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A4, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.6090806\n",
      "epochs =  0 , step =  100 , loss_val =  0.43829736\n",
      "epochs =  0 , step =  200 , loss_val =  0.16887482\n",
      "epochs =  0 , step =  300 , loss_val =  0.16058563\n",
      "epochs =  0 , step =  400 , loss_val =  0.10003356\n",
      "epochs =  0 , step =  500 , loss_val =  0.019380612\n",
      "epochs =  1 , step =  0 , loss_val =  0.08273588\n",
      "epochs =  1 , step =  100 , loss_val =  0.18048847\n",
      "epochs =  1 , step =  200 , loss_val =  0.07597459\n",
      "epochs =  1 , step =  300 , loss_val =  0.028787091\n",
      "epochs =  1 , step =  400 , loss_val =  0.09679048\n",
      "epochs =  1 , step =  500 , loss_val =  0.030284356\n",
      "epochs =  2 , step =  0 , loss_val =  0.021066377\n",
      "epochs =  2 , step =  100 , loss_val =  0.18569365\n",
      "epochs =  2 , step =  200 , loss_val =  0.035453063\n",
      "epochs =  2 , step =  300 , loss_val =  0.011025008\n",
      "epochs =  2 , step =  400 , loss_val =  0.055938613\n",
      "epochs =  2 , step =  500 , loss_val =  0.06490217\n",
      "epochs =  3 , step =  0 , loss_val =  0.017711695\n",
      "epochs =  3 , step =  100 , loss_val =  0.08268817\n",
      "epochs =  3 , step =  200 , loss_val =  0.015805868\n",
      "epochs =  3 , step =  300 , loss_val =  0.06400232\n",
      "epochs =  3 , step =  400 , loss_val =  0.016611455\n",
      "epochs =  3 , step =  500 , loss_val =  0.14381202\n",
      "epochs =  4 , step =  0 , loss_val =  0.009803033\n",
      "epochs =  4 , step =  100 , loss_val =  0.017145239\n",
      "epochs =  4 , step =  200 , loss_val =  0.049103543\n",
      "epochs =  4 , step =  300 , loss_val =  0.03581016\n",
      "epochs =  4 , step =  400 , loss_val =  0.007777679\n",
      "epochs =  4 , step =  500 , loss_val =  0.018153308\n",
      "epochs =  5 , step =  0 , loss_val =  0.03491863\n",
      "epochs =  5 , step =  100 , loss_val =  0.063810065\n",
      "epochs =  5 , step =  200 , loss_val =  0.018580627\n",
      "epochs =  5 , step =  300 , loss_val =  0.08387064\n",
      "epochs =  5 , step =  400 , loss_val =  0.008468517\n",
      "epochs =  5 , step =  500 , loss_val =  0.032196764\n",
      "epochs =  6 , step =  0 , loss_val =  0.020117575\n",
      "epochs =  6 , step =  100 , loss_val =  0.02597753\n",
      "epochs =  6 , step =  200 , loss_val =  0.02103549\n",
      "epochs =  6 , step =  300 , loss_val =  0.015789792\n",
      "epochs =  6 , step =  400 , loss_val =  0.012867618\n",
      "epochs =  6 , step =  500 , loss_val =  0.052727103\n",
      "epochs =  7 , step =  0 , loss_val =  0.004249285\n",
      "epochs =  7 , step =  100 , loss_val =  0.0031613512\n",
      "epochs =  7 , step =  200 , loss_val =  0.039006844\n",
      "epochs =  7 , step =  300 , loss_val =  0.06726933\n",
      "epochs =  7 , step =  400 , loss_val =  0.057700023\n",
      "epochs =  7 , step =  500 , loss_val =  0.0009512266\n",
      "epochs =  8 , step =  0 , loss_val =  0.009327328\n",
      "epochs =  8 , step =  100 , loss_val =  0.00836318\n",
      "epochs =  8 , step =  200 , loss_val =  0.01991338\n",
      "epochs =  8 , step =  300 , loss_val =  0.023077136\n",
      "epochs =  8 , step =  400 , loss_val =  0.012735758\n",
      "epochs =  8 , step =  500 , loss_val =  0.0006263593\n",
      "epochs =  9 , step =  0 , loss_val =  0.008809086\n",
      "epochs =  9 , step =  100 , loss_val =  0.042784605\n",
      "epochs =  9 , step =  200 , loss_val =  0.0023902454\n",
      "epochs =  9 , step =  300 , loss_val =  0.00041637121\n",
      "epochs =  9 , step =  400 , loss_val =  0.011047801\n",
      "epochs =  9 , step =  500 , loss_val =  0.008062367\n",
      "epochs =  10 , step =  0 , loss_val =  0.0048716925\n",
      "epochs =  10 , step =  100 , loss_val =  0.007394948\n",
      "epochs =  10 , step =  200 , loss_val =  0.023883456\n",
      "epochs =  10 , step =  300 , loss_val =  0.0026178597\n",
      "epochs =  10 , step =  400 , loss_val =  0.001412887\n",
      "epochs =  10 , step =  500 , loss_val =  0.033984583\n",
      "epochs =  11 , step =  0 , loss_val =  0.003807732\n",
      "epochs =  11 , step =  100 , loss_val =  0.0009538805\n",
      "epochs =  11 , step =  200 , loss_val =  0.008653855\n",
      "epochs =  11 , step =  300 , loss_val =  0.0009779988\n",
      "epochs =  11 , step =  400 , loss_val =  0.00078486593\n",
      "epochs =  11 , step =  500 , loss_val =  0.029229982\n",
      "epochs =  12 , step =  0 , loss_val =  0.0055961967\n",
      "epochs =  12 , step =  100 , loss_val =  0.00013982215\n",
      "epochs =  12 , step =  200 , loss_val =  0.0004416201\n",
      "epochs =  12 , step =  300 , loss_val =  0.016240215\n",
      "epochs =  12 , step =  400 , loss_val =  0.0026393705\n",
      "epochs =  12 , step =  500 , loss_val =  0.0035362886\n",
      "epochs =  13 , step =  0 , loss_val =  0.07519907\n",
      "epochs =  13 , step =  100 , loss_val =  0.00097120856\n",
      "epochs =  13 , step =  200 , loss_val =  0.00061745313\n",
      "epochs =  13 , step =  300 , loss_val =  0.0021119744\n",
      "epochs =  13 , step =  400 , loss_val =  0.017713891\n",
      "epochs =  13 , step =  500 , loss_val =  0.0038563495\n",
      "epochs =  14 , step =  0 , loss_val =  0.0072887675\n",
      "epochs =  14 , step =  100 , loss_val =  0.0037740264\n",
      "epochs =  14 , step =  200 , loss_val =  0.002556229\n",
      "epochs =  14 , step =  300 , loss_val =  0.00022761639\n",
      "epochs =  14 , step =  400 , loss_val =  0.00029634414\n",
      "epochs =  14 , step =  500 , loss_val =  0.001092845\n",
      "epochs =  15 , step =  0 , loss_val =  0.012279991\n",
      "epochs =  15 , step =  100 , loss_val =  0.01814705\n",
      "epochs =  15 , step =  200 , loss_val =  0.00075775874\n",
      "epochs =  15 , step =  300 , loss_val =  0.0003276791\n",
      "epochs =  15 , step =  400 , loss_val =  0.0021036372\n",
      "epochs =  15 , step =  500 , loss_val =  0.01679585\n",
      "epochs =  16 , step =  0 , loss_val =  0.0020722838\n",
      "epochs =  16 , step =  100 , loss_val =  0.020282442\n",
      "epochs =  16 , step =  200 , loss_val =  0.0062657213\n",
      "epochs =  16 , step =  300 , loss_val =  0.019132173\n",
      "epochs =  16 , step =  400 , loss_val =  0.00066950923\n",
      "epochs =  16 , step =  500 , loss_val =  0.0008778672\n",
      "epochs =  17 , step =  0 , loss_val =  0.0011122584\n",
      "epochs =  17 , step =  100 , loss_val =  0.00017756398\n",
      "epochs =  17 , step =  200 , loss_val =  0.0029808208\n",
      "epochs =  17 , step =  300 , loss_val =  0.00021646313\n",
      "epochs =  17 , step =  400 , loss_val =  0.0014344023\n",
      "epochs =  17 , step =  500 , loss_val =  0.0042298627\n",
      "epochs =  18 , step =  0 , loss_val =  0.010935128\n",
      "epochs =  18 , step =  100 , loss_val =  0.00224875\n",
      "epochs =  18 , step =  200 , loss_val =  0.0003980784\n",
      "epochs =  18 , step =  300 , loss_val =  0.00034500868\n",
      "epochs =  18 , step =  400 , loss_val =  0.00010936461\n",
      "epochs =  18 , step =  500 , loss_val =  0.0013358238\n",
      "epochs =  19 , step =  0 , loss_val =  0.0024819914\n",
      "epochs =  19 , step =  100 , loss_val =  0.00021700563\n",
      "epochs =  19 , step =  200 , loss_val =  0.0003508927\n",
      "epochs =  19 , step =  300 , loss_val =  8.350816e-05\n",
      "epochs =  19 , step =  400 , loss_val =  0.012207096\n",
      "epochs =  19 , step =  500 , loss_val =  0.00011880103\n",
      "epochs =  20 , step =  0 , loss_val =  0.00015862944\n",
      "epochs =  20 , step =  100 , loss_val =  0.00094021484\n",
      "epochs =  20 , step =  200 , loss_val =  0.0016437727\n",
      "epochs =  20 , step =  300 , loss_val =  0.00033850048\n",
      "epochs =  20 , step =  400 , loss_val =  2.4067565e-05\n",
      "epochs =  20 , step =  500 , loss_val =  0.007455664\n",
      "epochs =  21 , step =  0 , loss_val =  0.01087462\n",
      "epochs =  21 , step =  100 , loss_val =  0.013053116\n",
      "epochs =  21 , step =  200 , loss_val =  0.00018257955\n",
      "epochs =  21 , step =  300 , loss_val =  8.881349e-06\n",
      "epochs =  21 , step =  400 , loss_val =  0.021730315\n",
      "epochs =  21 , step =  500 , loss_val =  0.00036525473\n",
      "epochs =  22 , step =  0 , loss_val =  0.0004398199\n",
      "epochs =  22 , step =  100 , loss_val =  0.0027817497\n",
      "epochs =  22 , step =  200 , loss_val =  0.0050632954\n",
      "epochs =  22 , step =  300 , loss_val =  0.0038156512\n",
      "epochs =  22 , step =  400 , loss_val =  0.00053046556\n",
      "epochs =  22 , step =  500 , loss_val =  0.04457464\n",
      "epochs =  23 , step =  0 , loss_val =  0.006871407\n",
      "epochs =  23 , step =  100 , loss_val =  0.0009736046\n",
      "epochs =  23 , step =  200 , loss_val =  0.00025840045\n",
      "epochs =  23 , step =  300 , loss_val =  0.00033008968\n",
      "epochs =  23 , step =  400 , loss_val =  9.372628e-06\n",
      "epochs =  23 , step =  500 , loss_val =  0.0019472634\n",
      "epochs =  24 , step =  0 , loss_val =  0.00055432116\n",
      "epochs =  24 , step =  100 , loss_val =  0.007532432\n",
      "epochs =  24 , step =  200 , loss_val =  7.2813764e-06\n",
      "epochs =  24 , step =  300 , loss_val =  0.00015069047\n",
      "epochs =  24 , step =  400 , loss_val =  0.03294463\n",
      "epochs =  24 , step =  500 , loss_val =  0.0019494636\n",
      "epochs =  25 , step =  0 , loss_val =  1.3413178e-05\n",
      "epochs =  25 , step =  100 , loss_val =  0.0008116239\n",
      "epochs =  25 , step =  200 , loss_val =  0.00012448407\n",
      "epochs =  25 , step =  300 , loss_val =  0.0026166055\n",
      "epochs =  25 , step =  400 , loss_val =  0.0040044426\n",
      "epochs =  25 , step =  500 , loss_val =  0.0006759566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  26 , step =  0 , loss_val =  0.0002083274\n",
      "epochs =  26 , step =  100 , loss_val =  0.00023733538\n",
      "epochs =  26 , step =  200 , loss_val =  5.8087066e-06\n",
      "epochs =  26 , step =  300 , loss_val =  0.0005528252\n",
      "epochs =  26 , step =  400 , loss_val =  5.263945e-06\n",
      "epochs =  26 , step =  500 , loss_val =  0.00198532\n",
      "epochs =  27 , step =  0 , loss_val =  9.373197e-05\n",
      "epochs =  27 , step =  100 , loss_val =  6.448186e-05\n",
      "epochs =  27 , step =  200 , loss_val =  0.00034950324\n",
      "epochs =  27 , step =  300 , loss_val =  0.00035466507\n",
      "epochs =  27 , step =  400 , loss_val =  4.401126e-05\n",
      "epochs =  27 , step =  500 , loss_val =  7.548854e-06\n",
      "epochs =  28 , step =  0 , loss_val =  6.919167e-05\n",
      "epochs =  28 , step =  100 , loss_val =  0.00015433421\n",
      "epochs =  28 , step =  200 , loss_val =  1.6736172e-06\n",
      "epochs =  28 , step =  300 , loss_val =  5.049124e-05\n",
      "epochs =  28 , step =  400 , loss_val =  5.0389226e-05\n",
      "epochs =  28 , step =  500 , loss_val =  2.880099e-05\n",
      "epochs =  29 , step =  0 , loss_val =  0.0020434773\n",
      "epochs =  29 , step =  100 , loss_val =  0.001054571\n",
      "epochs =  29 , step =  200 , loss_val =  7.3007086e-06\n",
      "epochs =  29 , step =  300 , loss_val =  0.00014305762\n",
      "epochs =  29 , step =  400 , loss_val =  1.1419991e-06\n",
      "epochs =  29 , step =  500 , loss_val =  0.00013512024\n",
      "\n",
      "Elapsed Time =>  0:19:04.232068\n",
      "\n",
      "Accuracy = 0.9906\n",
      "length of index_label_list =  10000\n",
      "false label count =  94\n",
      "\n",
      "length of index_label_false_list_1 94\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})   \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 3, 5], [115, 4, 9], [247, 4, 2], [259, 6, 0], [321, 2, 7], [445, 6, 0], [583, 2, 7], [619, 1, 8], [659, 2, 1], [716, 1, 7], [740, 4, 9], [813, 9, 8], [883, 3, 5], [938, 3, 5], [939, 2, 0], [956, 1, 5], [1014, 6, 5], [1039, 7, 1], [1182, 6, 5], [1232, 9, 4], [1247, 9, 5], [1319, 8, 0], [1527, 1, 5], [1621, 0, 6], [1709, 9, 5], [1790, 2, 8], [1901, 9, 4], [2018, 1, 8], [2035, 5, 3], [2130, 4, 9], [2135, 6, 1], [2266, 1, 5], [2293, 9, 4], [2387, 9, 1], [2414, 9, 4], [2454, 6, 5], [2462, 2, 0], [2589, 9, 0], [2597, 5, 3], [2648, 9, 5], [2654, 6, 1], [2720, 9, 4], [2896, 8, 0], [2939, 9, 5], [2953, 3, 5], [3023, 8, 5], [3073, 1, 2], [3225, 7, 9], [3422, 6, 0], [3475, 3, 7], [3534, 4, 8], [3558, 5, 0], [3601, 1, 6], [3796, 2, 8], [3806, 5, 8], [3808, 7, 8], [3943, 3, 5], [4176, 2, 7], [4201, 1, 7], [4224, 9, 7], [4256, 3, 2], [4284, 9, 5], [4497, 8, 7], [4507, 1, 8], [4536, 6, 5], [4571, 6, 8], [4740, 3, 5], [4761, 9, 8], [4823, 9, 4], [4860, 4, 9], [5127, 2, 7], [5634, 2, 8], [5654, 7, 2], [5801, 6, 0], [5955, 3, 8], [6555, 8, 9], [6560, 9, 5], [6576, 7, 1], [6597, 0, 7], [8059, 2, 1], [8094, 2, 8], [9071, 1, 8], [9540, 1, 8], [9642, 9, 7], [9664, 2, 7], [9692, 9, 7], [9729, 5, 6], [9768, 2, 0], [9770, 5, 0], [9792, 4, 9], [9811, 2, 8], [9828, 3, 5], [9839, 2, 7], [9904, 2, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\16일차_1124\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "Elapsed save time =>  0:00:27.234033\n",
      "Total  94  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATSElEQVR4nO3df/BVdZ3H8ecLxV9AAZJERlGpm+s26UriZOPWmIW2pe1Km9aII4VrsUWTmy7EZLOu1rrZONOoSytF4Q8qdCW2Vl38ibUp/owCBVkUAmGIUBB/oe/94x7q+vXez/1yf53L9/N6zNz53u9933PP+5zvfX3POffcc44iAjMb+AaV3YCZdYfDbpYJh90sEw67WSYcdrNMOOxmmcgi7JLWSPpgP58bkg5pcjxND5sDSXdI+kxx/1OSbmnydX4uaXJ7uxv4sgj7nkrSvpKulvSEpG2SHpR0Utl9tUNEXBMRH2r0PEkXSprXZ9iTImJu57rbPZJGSpovaXNxu0bS68ruqy+HvbftDawF/gp4PTAL+JGkcSX2BICkvcvuoYdcBIwA3g68AxgNXFhmQ7VkF3ZJx0j6paStkjZI+o6kffo87WRJq4v/0pdKGlQ1/NmSlkv6g6SbJb21U71GxLMRcWFErImIVyJiEfB/wNGdGF+xGfKFWtMu6SxJ90j6tqQtFG/m1PyQdKKkFZKelvQdQFW1syQtqfr9CEm3StoiaaOkGZImAjOAv5O0XdLDxXOrNwcGSfpqsfazSdIPJL2+qI0rpmmypCeLaZrZgVn3NuA/I+KZiHgauBE4ogPjaU1EDPgbsAb4YHH/aOBYKkvNccByYHrVcwO4HRgJvAV4DPhMUTsVWAUcXgz/VeAXfYY9pE4PVwBb69we6ed0jAaeB97ZofmUmvazgJ3APxTTvn9qfgCjgGeA04DBwJeK4atfb0lxfxiwAfgysF/x+4SidiEwr0+fd1S9ztlFD28HhgI3AD8sauOKafpu0e+7gReAw+tM/wWJv9HWxHz7a+BnVJbuI4Dbqt9TvXIrvYGuTGRV2GvUpgM39nnDT6z6/XPA4uL+z4EpVbVBwA7grVXD1gx7G6ZhMPA/wL93cD6lpv0s4Mk+z687P4Azgf+tqglYVyfspwMP1umpUdgXA5+rqv0Z8BJ/+mcewJur6vcCn2zzfHtT8bd5pbjdCuzTzfd4f245rsYfJmmRpKckPQNcTGUpVG1t1f0nqPwxofImvrzYBNgKbKHyJj64wz0PAn4IvAhM6+S4qD/tfWuQnh9vqn5+VFLRd/hdxgKPN9nvm4o+q3vem8pa0C5PVd3fQWUNoJ1+TGUtaBjwOirTMi85RAmyCztwJbACODQiXkdlm1B9njO26v5bgPXF/bXAORExvOq2f0T8otFIJV1VbHfWuv0mMZyAq6m8ef82Il7q/6Q2pd60Q2UpWS01PzZUv1YxHWOpbS2VD7ZqaXRY5noq/3Sqe94JbGww3GsUnxPU+xttTwz6biprXM9GxHbgKuDk3R1/p+UY9mFUtiW3S3oncG6N5/yjpBGSxgJfBOYXj18F/JOkIwAkvV7SpP6MNCL+PiKG1rmlPsy5kso28Ucj4rl+TiNFf++XtLvHMNeb9lpS8+O/gCMk/U3xyf0XgDfWeZ1FwBslTS92Nw6TNKGobQTGVX9I2sd1wJckvU3SUCpravMjYmd/J3iXiLg48TdKrQ3cB3xG0v6S9gemAg/v7vg7LcewnwecAWyj8sFNrTfzTcD9wENU3rRXA0TEjcA3geuLTYBlQMf2exefbJ8DHAk8VbWU+VQ/X2Is8MvdHG3Naa8lNT8iYjMwCfgG8HvgUOCeOq+zDTgR+CiVVe6VwAeK8o+Ln7+X9ECNwedQ2cS5i8qeiuepfIjYTWdT+XxgHfA7Kh8WntXlHhpS8QGDDUCS/gP4cUTc3M/nB5XNm1Wd7czK4LDbHznsA1uOq/FmWfKS3SwTXrKbZaKrBzM0sRvIzHZTRPT93gjQ4pJd0kRJj0paJemCVl7LzDqr6W12SXtR+YrgiVT2L94HnB4Rv00M4yW7WYd1Ysl+DLAqIlZHxIvA9cApLbyemXVQK2E/mFcf2LCOGgeESJoqaamkpS2My8xa1MoHdLVWFV6zmh4Rs4HZ4NV4szK1smRfx6uPYnozrz5Cysx6SCthvw84tDjaaB/gk8DC9rRlZu3W9Gp8ROyUNA24GdgLmBMRdY/LNrNydfXrst5mN+u8jnypxsz2HA67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLR9CWbzco2fPjwZH3mzJl1a/Pnz08Ou3Tp0qZ66mUthV3SGmAb8DKwMyLGt6MpM2u/dizZPxARm9vwOmbWQd5mN8tEq2EP4BZJ90uaWusJkqZKWipp4G0Eme1BWl2NPy4i1ks6CLhV0oqIuKv6CRExG5gNIClaHJ+ZNamlJXtErC9+bgJuBI5pR1Nm1n5Nh13SEEnDdt0HPgQsa1djZtZerazGjwZulLTrda6NiP9uS1eWhUMOOSRZ//SnP52sT5kyJVkfOXJk3dqiRYuSww5ETYc9IlYD725jL2bWQd71ZpYJh90sEw67WSYcdrNMOOxmmfAhrtaSvfdOv4VOOumkurV58+Ylhx06dGiyXuz2resjH/lI3dqyZemvhDSarp07dybrvchLdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sE4ro3sljfKaageeqq65K1j/72c92bNyN9rO38t6+8847k/VZs2Yl6/fcc0/T425VRNScMV6ym2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZ8H72zB133HHJ+pIlS5L1br5/+pozZ06yfvvtt9etDRs2LDnsxRdfnKw/+OCDyfoJJ5yQrHeS97ObZc5hN8uEw26WCYfdLBMOu1kmHHazTDjsZpnweeMHuH333TdZv+yyy5L1RvvRt23blqxff/31dWs/+clPksPef//9yfqWLVuS9ZRzzz03WR8yZEiyvmLFiqbHXZaGS3ZJcyRtkrSs6rGRkm6VtLL4OaKzbZpZq/qzGv99YGKfxy4AFkfEocDi4ncz62ENwx4RdwF915dOAeYW9+cCp7a5LzNrs2a32UdHxAaAiNgg6aB6T5Q0FZja5HjMrE06/gFdRMwGZoMPhDErU7O73jZKGgNQ/NzUvpbMrBOaDftCYHJxfzJwU3vaMbNOabgaL+k64P3AKEnrgK8B3wB+JGkK8CQwqZNNWvNeeOGFZH3hwoXJ+o4dO5L1KVOmJOurV69O1ssyffr0ZL3R9dl/+tOftrOdrmgY9og4vU6pvKPzzWy3+euyZplw2M0y4bCbZcJhN8uEw26WCZ9KeoAbNCj9//yAAw5I1rdv397Odrrq2GOPrVtbvHhxcthGuyzf+973JutlHgLrU0mbZc5hN8uEw26WCYfdLBMOu1kmHHazTDjsZpnwqaT3APPnz0/Whw4dWrc2ePDg5LCHH354sn7mmWcm66nLInfa+PHjk/U77rijbu35559PDvuxj30sWR+Qp5I2s4HBYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZ8H72fkpdwvf4449PDjtu3Lhk/YorrkjWu3nOgb5uu+22ZP2SSy5J1mfMmFG3ts8++ySHPeGE9AmMzzvvvGQ99foLFixIDrtkyZJkfU/kJbtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmfN76fpk2bVrd2+eWXJ4fdvHlzst5on+6ll16arD/22GPJeisa9f7SSy8l66lLI2/dujU57Lx585J1qebp0f/ooosuqlv7+te/nhz25ZdfTtZ7WdPnjZc0R9ImScuqHrtQ0u8kPVTcTm5ns2bWfv1Zjf8+MLHG49+OiCOL28/a25aZtVvDsEfEXcCWLvRiZh3Uygd00yQ9Uqzmj6j3JElTJS2VtLSFcZlZi5oN+5XAO4AjgQ3At+o9MSJmR8T4iEifHdDMOqqpsEfExoh4OSJeAb4LHNPetsys3ZoKu6QxVb9+HFhW77lm1hsa7meXdB3wfmAUsBH4WvH7kUAAa4BzImJDw5H18H72WbNmJeszZ86sW3vqqaeSw06YMCFZ37hxY7JepoceeihZf9e73pWsp/bDN9qXvd9++yXrEyfW2kn0J6lj8ffk/eiN1NvP3vDkFRFxeo2Hr265IzPrKn9d1iwTDrtZJhx2s0w47GaZcNjNMpHNIa6HHXZYsn7LLbck648++mjd2tSpU5PDPvHEE8l6Jw0alP5/PmJE3W86A7B8+fJk/cADD9ztnnZZt25dsj5p0qRk/d5772163ANZ04e4mtnA4LCbZcJhN8uEw26WCYfdLBMOu1kmHHazTGSzn/3uu+9O1hvth//whz9ct9boMNBWjRo1KllP9XbEEUckhz3//POT9Uana270/tm2bVvd2tFHH50c9vHHH0/WrTbvZzfLnMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMtHw7LIDxYsvvpisv+ENb0jWjzrqqLq1MWPG1K31xxlnnJGsn3baacn6vvvu2/S4ly5NX5Xr2muvTdYvueSSZH2vvfaqW9t772zefj3BS3azTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBP9uWTzWOAHwBuBV4DZEXG5pJHAfGAclcs2fyIi/tDgtUo7nv0rX/lKst5of3EnPf3008n6ihUrkvXUMeMLFixIDvu9730vWR8+fHiyvnLlymQ9dd7697znPclhU+fqt/paOZ59J/DliDgcOBb4vKQ/By4AFkfEocDi4ncz61ENwx4RGyLigeL+NmA5cDBwCjC3eNpc4NRONWlmrdutbXZJ44CjgF8BoyNiA1T+IQAHtbs5M2uffn85WdJQYAEwPSKeaXRusqrhpgLpi6GZWcf1a8kuaTCVoF8TETcUD2+UNKaojwE21Ro2ImZHxPiIGN+Ohs2sOQ3Drsoi/GpgeURcVlVaCEwu7k8Gbmp/e2bWLv3Z9fY+4G7g11R2vQHMoLLd/iPgLcCTwKSI2NLgtUrb9TZkyJBkvdXDVFuxY8eOZH39+vVd6uS1Gs23tWvXJusHHHBA3dqECROSwz788MPJutVWb9dbw232iFgC1NtAP6GVpsyse/wNOrNMOOxmmXDYzTLhsJtlwmE3y4TDbpaJbM7l++yzzybrq1at6lIne5ZGh7jOmTMnWX/uuefq1nxJ5u7ykt0sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y0TD49nbOrISj2c3y0Urp5I2swHAYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZaBh2SWMl3S5puaTfSPpi8fiFkn4n6aHidnLn2zWzZjU8eYWkMcCYiHhA0jDgfuBU4BPA9oj4t36PzCevMOu4eievaHhFmIjYAGwo7m+TtBw4uL3tmVmn7dY2u6RxwFHAr4qHpkl6RNIcSSPqDDNV0lJJS1vq1Mxa0u9z0EkaCtwJ/EtE3CBpNLAZCOCfqazqn93gNbwab9Zh9Vbj+xV2SYOBRcDNEXFZjfo4YFFE/EWD13HYzTqs6RNOShJwNbC8OujFB3e7fBxY1mqTZtY5/fk0/n3A3cCvgVeKh2cApwNHUlmNXwOcU3yYl3otL9nNOqyl1fh2cdjNOs/njTfLnMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZaHjCyTbbDDxR9fuo4rFe1Ku99Wpf4N6a1c7e3lqv0NXj2V8zcmlpRIwvrYGEXu2tV/sC99asbvXm1XizTDjsZpkoO+yzSx5/Sq/21qt9gXtrVld6K3Wb3cy6p+wlu5l1icNulolSwi5poqRHJa2SdEEZPdQjaY2kXxeXoS71+nTFNfQ2SVpW9dhISbdKWln8rHmNvZJ664nLeCcuM17qvCv78udd32aXtBfwGHAisA64Dzg9In7b1UbqkLQGGB8RpX8BQ9LxwHbgB7surSXpX4EtEfGN4h/liIg4v0d6u5DdvIx3h3qrd5nxsyhx3rXz8ufNKGPJfgywKiJWR8SLwPXAKSX00fMi4i5gS5+HTwHmFvfnUnmzdF2d3npCRGyIiAeK+9uAXZcZL3XeJfrqijLCfjCwtur3dfTW9d4DuEXS/ZKmlt1MDaN3XWar+HlQyf301fAy3t3U5zLjPTPvmrn8eavKCHutS9P00v6/4yLiL4GTgM8Xq6vWP1cC76ByDcANwLfKbKa4zPgCYHpEPFNmL9Vq9NWV+VZG2NcBY6t+fzOwvoQ+aoqI9cXPTcCNVDY7esnGXVfQLX5uKrmfP4qIjRHxckS8AnyXEuddcZnxBcA1EXFD8XDp865WX92ab2WE/T7gUElvk7QP8ElgYQl9vIakIcUHJ0gaAnyI3rsU9UJgcnF/MnBTib28Sq9cxrveZcYped6VfvnziOj6DTiZyifyjwMzy+ihTl9vBx4ubr8puzfgOiqrdS9RWSOaAhwILAZWFj9H9lBvP6Ryae9HqARrTEm9vY/KpuEjwEPF7eSy512ir67MN39d1iwT/gadWSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpaJ/wfYPGxqrf0aVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data_실습4_copy'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_1:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
