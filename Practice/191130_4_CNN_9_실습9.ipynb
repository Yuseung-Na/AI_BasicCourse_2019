{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-8b471cb9f1c7>:11: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
    "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
    "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
    "\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
    "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 0.001  # 학습율\n",
    "epochs = 30            # 반복횟수\n",
    "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28 X 28 X 1 (black/white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 5x5x32 필터 \n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층\n",
    "W3 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev=0.01))  \n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[64]))   \n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 64 \n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 64\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 3, pooling 없이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3번째 컨볼루션 층\n",
    "W4 = tf.Variable(tf.random_normal([5, 5, 64, 128], stddev=0.01))  \n",
    "b4 = tf.Variable(tf.constant(0.1, shape=[128]))   \n",
    "\n",
    "# 3번째 컨볼루션 연산을 통해 7 X 7 X 64 => 7 X 7 X 128\n",
    "C4 = tf.nn.conv2d(A3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "A4 = Z4 = tf.nn.relu(C4+b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2X2 크기를 가진 256개의 activation map을 flatten 시킴\n",
    "A4_flat = P4_flat = tf.reshape(A4, [-1, 128*7*7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 개의 노드 완전연결\n",
    "W5 = tf.Variable(tf.random_normal([128*7*7, 256], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "Z5 = tf.matmul(A4_flat, W5) + b5\n",
    "\n",
    "A5 = tf.nn.relu(Z5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W6 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "b6 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀  값 Z6, 즉 softmax 에 들어가는 입력 값\n",
    "Z6 = logits = tf.matmul(A5, W6) + b6    # 선형회귀 값 Z6\n",
    "\n",
    "y = A6 = tf.nn.softmax(Z6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z6, labels=T) )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal( tf.argmax(A6, 1), tf.argmax(T, 1) )\n",
    "\n",
    "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "# 예측값 처리\n",
    "predicted_list = tf.argmax(A6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.578572\n",
      "epochs =  0 , step =  100 , loss_val =  1.3596042\n",
      "epochs =  0 , step =  200 , loss_val =  0.3459197\n",
      "epochs =  0 , step =  300 , loss_val =  0.11688562\n",
      "epochs =  0 , step =  400 , loss_val =  0.1060114\n",
      "epochs =  0 , step =  500 , loss_val =  0.090657614\n",
      "epochs =  1 , step =  0 , loss_val =  0.050366692\n",
      "epochs =  1 , step =  100 , loss_val =  0.07055423\n",
      "epochs =  1 , step =  200 , loss_val =  0.07342895\n",
      "epochs =  1 , step =  300 , loss_val =  0.06614749\n",
      "epochs =  1 , step =  400 , loss_val =  0.033467893\n",
      "epochs =  1 , step =  500 , loss_val =  0.047052763\n",
      "epochs =  2 , step =  0 , loss_val =  0.043895945\n",
      "epochs =  2 , step =  100 , loss_val =  0.07474868\n",
      "epochs =  2 , step =  200 , loss_val =  0.0477523\n",
      "epochs =  2 , step =  300 , loss_val =  0.10548714\n",
      "epochs =  2 , step =  400 , loss_val =  0.10081036\n",
      "epochs =  2 , step =  500 , loss_val =  0.11733855\n",
      "epochs =  3 , step =  0 , loss_val =  0.007955786\n",
      "epochs =  3 , step =  100 , loss_val =  0.0045762993\n",
      "epochs =  3 , step =  200 , loss_val =  0.036875714\n",
      "epochs =  3 , step =  300 , loss_val =  0.042533204\n",
      "epochs =  3 , step =  400 , loss_val =  0.026105225\n",
      "epochs =  3 , step =  500 , loss_val =  0.029436858\n",
      "epochs =  4 , step =  0 , loss_val =  0.022089764\n",
      "epochs =  4 , step =  100 , loss_val =  0.00072965416\n",
      "epochs =  4 , step =  200 , loss_val =  0.07488923\n",
      "epochs =  4 , step =  300 , loss_val =  0.013570411\n",
      "epochs =  4 , step =  400 , loss_val =  0.0057992674\n",
      "epochs =  4 , step =  500 , loss_val =  0.00070110353\n",
      "epochs =  5 , step =  0 , loss_val =  0.0046873675\n",
      "epochs =  5 , step =  100 , loss_val =  0.030482942\n",
      "epochs =  5 , step =  200 , loss_val =  0.01515111\n",
      "epochs =  5 , step =  300 , loss_val =  0.016294323\n",
      "epochs =  5 , step =  400 , loss_val =  0.024765678\n",
      "epochs =  5 , step =  500 , loss_val =  0.09066118\n",
      "epochs =  6 , step =  0 , loss_val =  0.015858764\n",
      "epochs =  6 , step =  100 , loss_val =  0.017218001\n",
      "epochs =  6 , step =  200 , loss_val =  0.0019383262\n",
      "epochs =  6 , step =  300 , loss_val =  0.012512028\n",
      "epochs =  6 , step =  400 , loss_val =  0.004292506\n",
      "epochs =  6 , step =  500 , loss_val =  0.047850545\n",
      "epochs =  7 , step =  0 , loss_val =  0.0011241185\n",
      "epochs =  7 , step =  100 , loss_val =  0.03544216\n",
      "epochs =  7 , step =  200 , loss_val =  0.0012575942\n",
      "epochs =  7 , step =  300 , loss_val =  0.031291243\n",
      "epochs =  7 , step =  400 , loss_val =  0.03862206\n",
      "epochs =  7 , step =  500 , loss_val =  0.07568498\n",
      "epochs =  8 , step =  0 , loss_val =  0.006072187\n",
      "epochs =  8 , step =  100 , loss_val =  0.0020566233\n",
      "epochs =  8 , step =  200 , loss_val =  0.12085975\n",
      "epochs =  8 , step =  300 , loss_val =  0.0014961839\n",
      "epochs =  8 , step =  400 , loss_val =  0.008640855\n",
      "epochs =  8 , step =  500 , loss_val =  3.4795434e-05\n",
      "epochs =  9 , step =  0 , loss_val =  0.018329695\n",
      "epochs =  9 , step =  100 , loss_val =  0.0011801493\n",
      "epochs =  9 , step =  200 , loss_val =  0.03848813\n",
      "epochs =  9 , step =  300 , loss_val =  0.045190074\n",
      "epochs =  9 , step =  400 , loss_val =  0.010778788\n",
      "epochs =  9 , step =  500 , loss_val =  0.0021877333\n",
      "epochs =  10 , step =  0 , loss_val =  0.012897257\n",
      "epochs =  10 , step =  100 , loss_val =  0.000738496\n",
      "epochs =  10 , step =  200 , loss_val =  0.046356734\n",
      "epochs =  10 , step =  300 , loss_val =  0.0041453354\n",
      "epochs =  10 , step =  400 , loss_val =  0.0068928\n",
      "epochs =  10 , step =  500 , loss_val =  0.005478023\n",
      "epochs =  11 , step =  0 , loss_val =  0.010568525\n",
      "epochs =  11 , step =  100 , loss_val =  0.0053929854\n",
      "epochs =  11 , step =  200 , loss_val =  0.00029762968\n",
      "epochs =  11 , step =  300 , loss_val =  0.00022006179\n",
      "epochs =  11 , step =  400 , loss_val =  0.004990539\n",
      "epochs =  11 , step =  500 , loss_val =  0.00064664497\n",
      "epochs =  12 , step =  0 , loss_val =  0.0098057985\n",
      "epochs =  12 , step =  100 , loss_val =  0.0050306027\n",
      "epochs =  12 , step =  200 , loss_val =  0.0015695697\n",
      "epochs =  12 , step =  300 , loss_val =  0.003916182\n",
      "epochs =  12 , step =  400 , loss_val =  0.00054010475\n",
      "epochs =  12 , step =  500 , loss_val =  0.0010247387\n",
      "epochs =  13 , step =  0 , loss_val =  0.00039737063\n",
      "epochs =  13 , step =  100 , loss_val =  0.0014960988\n",
      "epochs =  13 , step =  200 , loss_val =  0.0017793732\n",
      "epochs =  13 , step =  300 , loss_val =  0.0024517681\n",
      "epochs =  13 , step =  400 , loss_val =  0.038630534\n",
      "epochs =  13 , step =  500 , loss_val =  0.0002453142\n",
      "epochs =  14 , step =  0 , loss_val =  0.00086738577\n",
      "epochs =  14 , step =  100 , loss_val =  0.0001707961\n",
      "epochs =  14 , step =  200 , loss_val =  0.00011963064\n",
      "epochs =  14 , step =  300 , loss_val =  2.5420482e-05\n",
      "epochs =  14 , step =  400 , loss_val =  0.009056438\n",
      "epochs =  14 , step =  500 , loss_val =  0.0141294645\n",
      "epochs =  15 , step =  0 , loss_val =  0.00074260356\n",
      "epochs =  15 , step =  100 , loss_val =  0.010620312\n",
      "epochs =  15 , step =  200 , loss_val =  0.009666803\n",
      "epochs =  15 , step =  300 , loss_val =  0.011684627\n",
      "epochs =  15 , step =  400 , loss_val =  5.3597138e-05\n",
      "epochs =  15 , step =  500 , loss_val =  0.00054974156\n",
      "epochs =  16 , step =  0 , loss_val =  0.0029749053\n",
      "epochs =  16 , step =  100 , loss_val =  5.2726115e-05\n",
      "epochs =  16 , step =  200 , loss_val =  0.002297037\n",
      "epochs =  16 , step =  300 , loss_val =  0.0010684639\n",
      "epochs =  16 , step =  400 , loss_val =  0.005588711\n",
      "epochs =  16 , step =  500 , loss_val =  5.283373e-05\n",
      "epochs =  17 , step =  0 , loss_val =  1.8326135e-05\n",
      "epochs =  17 , step =  100 , loss_val =  1.177272e-05\n",
      "epochs =  17 , step =  200 , loss_val =  6.9169e-05\n",
      "epochs =  17 , step =  300 , loss_val =  0.00024385098\n",
      "epochs =  17 , step =  400 , loss_val =  9.813038e-06\n",
      "epochs =  17 , step =  500 , loss_val =  0.008638928\n",
      "epochs =  18 , step =  0 , loss_val =  0.0013538484\n",
      "epochs =  18 , step =  100 , loss_val =  0.00087175623\n",
      "epochs =  18 , step =  200 , loss_val =  0.0053644995\n",
      "epochs =  18 , step =  300 , loss_val =  0.00011844667\n",
      "epochs =  18 , step =  400 , loss_val =  8.13501e-05\n",
      "epochs =  18 , step =  500 , loss_val =  0.0005343124\n",
      "epochs =  19 , step =  0 , loss_val =  0.0009782086\n",
      "epochs =  19 , step =  100 , loss_val =  8.954796e-05\n",
      "epochs =  19 , step =  200 , loss_val =  0.0001345378\n",
      "epochs =  19 , step =  300 , loss_val =  0.01994955\n",
      "epochs =  19 , step =  400 , loss_val =  0.00022174536\n",
      "epochs =  19 , step =  500 , loss_val =  0.05446383\n",
      "epochs =  20 , step =  0 , loss_val =  0.00017245312\n",
      "epochs =  20 , step =  100 , loss_val =  1.460683e-05\n",
      "epochs =  20 , step =  200 , loss_val =  8.586096e-05\n",
      "epochs =  20 , step =  300 , loss_val =  0.026251195\n",
      "epochs =  20 , step =  400 , loss_val =  2.8842194e-05\n",
      "epochs =  20 , step =  500 , loss_val =  0.00014554475\n",
      "epochs =  21 , step =  0 , loss_val =  0.0003211128\n",
      "epochs =  21 , step =  100 , loss_val =  2.86146e-05\n",
      "epochs =  21 , step =  200 , loss_val =  8.848372e-05\n",
      "epochs =  21 , step =  300 , loss_val =  0.014308495\n",
      "epochs =  21 , step =  400 , loss_val =  2.7069766e-05\n",
      "epochs =  21 , step =  500 , loss_val =  0.004471127\n",
      "epochs =  22 , step =  0 , loss_val =  3.5166585e-07\n",
      "epochs =  22 , step =  100 , loss_val =  0.001736078\n",
      "epochs =  22 , step =  200 , loss_val =  0.0024319247\n",
      "epochs =  22 , step =  300 , loss_val =  0.00017526433\n",
      "epochs =  22 , step =  400 , loss_val =  0.031015811\n",
      "epochs =  22 , step =  500 , loss_val =  4.5451572e-05\n",
      "epochs =  23 , step =  0 , loss_val =  0.0013079847\n",
      "epochs =  23 , step =  100 , loss_val =  0.0005115824\n",
      "epochs =  23 , step =  200 , loss_val =  0.00016394338\n",
      "epochs =  23 , step =  300 , loss_val =  9.016678e-05\n",
      "epochs =  23 , step =  400 , loss_val =  0.01100335\n",
      "epochs =  23 , step =  500 , loss_val =  0.0002464754\n",
      "epochs =  24 , step =  0 , loss_val =  0.0001144301\n",
      "epochs =  24 , step =  100 , loss_val =  1.9218673e-05\n",
      "epochs =  24 , step =  200 , loss_val =  3.7015518e-05\n",
      "epochs =  24 , step =  300 , loss_val =  0.00026340422\n",
      "epochs =  24 , step =  400 , loss_val =  0.00016468763\n",
      "epochs =  24 , step =  500 , loss_val =  2.1399586e-05\n",
      "epochs =  25 , step =  0 , loss_val =  0.00010980255\n",
      "epochs =  25 , step =  100 , loss_val =  1.4517299e-05\n",
      "epochs =  25 , step =  200 , loss_val =  9.104022e-06\n",
      "epochs =  25 , step =  300 , loss_val =  4.2100117e-05\n",
      "epochs =  25 , step =  400 , loss_val =  0.000563354\n",
      "epochs =  25 , step =  500 , loss_val =  5.6436867e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  26 , step =  0 , loss_val =  0.00076248107\n",
      "epochs =  26 , step =  100 , loss_val =  1.6693819e-05\n",
      "epochs =  26 , step =  200 , loss_val =  3.125891e-05\n",
      "epochs =  26 , step =  300 , loss_val =  0.0012818887\n",
      "epochs =  26 , step =  400 , loss_val =  4.16729e-06\n",
      "epochs =  26 , step =  500 , loss_val =  0.0006491989\n",
      "epochs =  27 , step =  0 , loss_val =  0.0007726215\n",
      "epochs =  27 , step =  100 , loss_val =  0.00033478302\n",
      "epochs =  27 , step =  200 , loss_val =  3.528582e-07\n",
      "epochs =  27 , step =  300 , loss_val =  1.0488522e-05\n",
      "epochs =  27 , step =  400 , loss_val =  2.1651764e-05\n",
      "epochs =  27 , step =  500 , loss_val =  6.760452e-05\n",
      "epochs =  28 , step =  0 , loss_val =  0.0022396094\n",
      "epochs =  28 , step =  100 , loss_val =  5.773193e-06\n",
      "epochs =  28 , step =  200 , loss_val =  0.0010005046\n",
      "epochs =  28 , step =  300 , loss_val =  7.249549e-05\n",
      "epochs =  28 , step =  400 , loss_val =  0.0029843256\n",
      "epochs =  28 , step =  500 , loss_val =  0.013192865\n",
      "epochs =  29 , step =  0 , loss_val =  1.4347894e-05\n",
      "epochs =  29 , step =  100 , loss_val =  0.000159612\n",
      "epochs =  29 , step =  200 , loss_val =  0.01632241\n",
      "epochs =  29 , step =  300 , loss_val =  7.246938e-05\n",
      "epochs =  29 , step =  400 , loss_val =  0.0015887847\n",
      "epochs =  29 , step =  500 , loss_val =  0.0010467658\n",
      "\n",
      "elapsed time =  0:02:09.962139\n",
      "\n",
      "Accuracy =  0.9925\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  75\n",
      "W2_val.shape =  (5, 5, 1, 32) , W3_val.shape =  (5, 5, 32, 64) , W4_val.shape =  (5, 5, 64, 128)\n",
      "C2_val.shape =  (10000, 28, 28, 32) , C3_val.shape =  (10000, 14, 14, 64) , C4_val.shape =  (10000, 7, 7, 128)\n",
      "\n",
      "length of index_label_false_list 75\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_label_prediction_list = []\n",
    "\n",
    "with  tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):    # 30 번 반복수행\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
    "\n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "      \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now() \n",
    "    \n",
    "    print(\"\\nelapsed time = \", end_time - start_time) \n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images    # 10000 X 784\n",
    "    test_t_data = mnist.test.labels    # 10000 X 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    W2_val, W3_val, W4_val = sess.run([W2, W3, W4], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    C2_val, C3_val, C4_val = sess.run([C2, C3, C4], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    print('W2_val.shape = ', W2_val.shape, ', W3_val.shape = ', W3_val.shape, ', W4_val.shape = ', W4_val.shape)\n",
    "    print('C2_val.shape = ', C2_val.shape, ', C3_val.shape = ', C3_val.shape, ', C4_val.shape = ', C4_val.shape)\n",
    "        \n",
    "    plt.imshow(C2_val[0, :, :, 12]) # C2에서 0번째 index image의 12번째 filter에 의한 그림 출력 (filter는 32개 있음)\n",
    "    \n",
    "    # numpy type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_prediction_list.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x282422b08c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_x_data[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115, 4, 9], [247, 4, 2], [340, 5, 3], [448, 9, 3], [582, 8, 2], [646, 2, 6], [659, 2, 1], [936, 8, 6], [947, 8, 9], [1014, 6, 5], [1033, 8, 1], [1112, 4, 6], [1128, 3, 7], [1232, 9, 4], [1260, 7, 1], [1393, 5, 3], [1414, 9, 7], [1554, 9, 7], [1901, 9, 8], [2035, 5, 3], [2043, 4, 8], [2109, 3, 2], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2293, 9, 4], [2387, 9, 1], [2414, 9, 4], [2462, 2, 0], [2582, 9, 7], [2597, 5, 3], [2654, 6, 1], [2678, 4, 9], [2720, 9, 8], [2896, 8, 0], [2939, 9, 5], [2953, 3, 5], [3225, 7, 9], [3343, 8, 2], [3422, 6, 0], [3475, 3, 7], [3520, 6, 4], [3558, 5, 0], [3808, 7, 2], [4163, 9, 7], [4176, 2, 7], [4207, 8, 2], [4497, 8, 2], [4500, 9, 1], [4504, 2, 7], [4699, 6, 1], [4731, 8, 7], [4823, 9, 4], [4860, 4, 9], [4874, 9, 0], [5654, 7, 2], [5655, 7, 2], [5937, 5, 3], [5955, 3, 8], [5997, 5, 9], [6166, 9, 5], [6173, 9, 8], [6576, 7, 1], [6597, 0, 7], [8065, 8, 0], [8520, 4, 9], [8527, 4, 9], [9505, 7, 2], [9619, 8, 2], [9642, 9, 7], [9664, 2, 7], [9669, 4, 1], [9700, 2, 8], [9729, 5, 6], [9792, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# index_label_prediction_list\n",
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
