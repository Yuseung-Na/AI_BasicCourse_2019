{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1 3x3 32개 -> 5x5 32개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 3x3x32 필터 \n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "b2 = tf.Variable(tf.random_normal([32]))\n",
    "## b2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 2 3x3 32개 -> 5x5 64개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층, 3x3x32 필터 \n",
    "W3 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev=0.01)) ## 데이터 1개에 대해 필터를 거쳐 특징의 종류가 32개\n",
    "## 32 개 통로로 들어오는 각각의 데이터에 대해 5 x 5 64개 필터를 적용함\n",
    "\n",
    "b3 = tf.Variable(tf.random_normal([64]))\n",
    "## b3 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 x 14 x 32 => 14 x 14 x 64 \n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 1번째 max pooling을 통해 14 x 14 x 64 => 7 x 7 x 64\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 x 7 크기를 가진 32개의 activation map을 flatten 시킴\n",
    "A3_flat = P3_flat = tf.reshape(A3, [-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W4 = tf.Variable(tf.random_normal([7*7*64, 10], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀 값 Z4, 즉 softmax 에 들어가는 입력 값\n",
    "Z4 = logits = tf.matmul(A3_flat, W4) + b4\n",
    "\n",
    "y = A4 = tf.nn.softmax(Z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z4, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A4, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.5644913\n",
      "epochs =  0 , step =  100 , loss_val =  1.6795496\n",
      "epochs =  0 , step =  200 , loss_val =  0.34544814\n",
      "epochs =  0 , step =  300 , loss_val =  0.21441732\n",
      "epochs =  0 , step =  400 , loss_val =  0.10442747\n",
      "epochs =  0 , step =  500 , loss_val =  0.14969708\n",
      "epochs =  1 , step =  0 , loss_val =  0.08363062\n",
      "epochs =  1 , step =  100 , loss_val =  0.07350081\n",
      "epochs =  1 , step =  200 , loss_val =  0.16348366\n",
      "epochs =  1 , step =  300 , loss_val =  0.2565182\n",
      "epochs =  1 , step =  400 , loss_val =  0.035714902\n",
      "epochs =  1 , step =  500 , loss_val =  0.034971803\n",
      "epochs =  2 , step =  0 , loss_val =  0.069787584\n",
      "epochs =  2 , step =  100 , loss_val =  0.078500405\n",
      "epochs =  2 , step =  200 , loss_val =  0.07703281\n",
      "epochs =  2 , step =  300 , loss_val =  0.07332486\n",
      "epochs =  2 , step =  400 , loss_val =  0.031199927\n",
      "epochs =  2 , step =  500 , loss_val =  0.0368712\n",
      "epochs =  3 , step =  0 , loss_val =  0.042048052\n",
      "epochs =  3 , step =  100 , loss_val =  0.029728593\n",
      "epochs =  3 , step =  200 , loss_val =  0.027035307\n",
      "epochs =  3 , step =  300 , loss_val =  0.03461493\n",
      "epochs =  3 , step =  400 , loss_val =  0.044482898\n",
      "epochs =  3 , step =  500 , loss_val =  0.058241162\n",
      "epochs =  4 , step =  0 , loss_val =  0.03091339\n",
      "epochs =  4 , step =  100 , loss_val =  0.081421524\n",
      "epochs =  4 , step =  200 , loss_val =  0.06363194\n",
      "epochs =  4 , step =  300 , loss_val =  0.054055907\n",
      "epochs =  4 , step =  400 , loss_val =  0.0717617\n",
      "epochs =  4 , step =  500 , loss_val =  0.12911235\n",
      "epochs =  5 , step =  0 , loss_val =  0.035701875\n",
      "epochs =  5 , step =  100 , loss_val =  0.10961482\n",
      "epochs =  5 , step =  200 , loss_val =  0.052639198\n",
      "epochs =  5 , step =  300 , loss_val =  0.039547402\n",
      "epochs =  5 , step =  400 , loss_val =  0.026252974\n",
      "epochs =  5 , step =  500 , loss_val =  0.0306096\n",
      "epochs =  6 , step =  0 , loss_val =  0.0149681615\n",
      "epochs =  6 , step =  100 , loss_val =  0.04577429\n",
      "epochs =  6 , step =  200 , loss_val =  0.009249413\n",
      "epochs =  6 , step =  300 , loss_val =  0.03205029\n",
      "epochs =  6 , step =  400 , loss_val =  0.0065780003\n",
      "epochs =  6 , step =  500 , loss_val =  0.011308448\n",
      "epochs =  7 , step =  0 , loss_val =  0.015300745\n",
      "epochs =  7 , step =  100 , loss_val =  0.014453874\n",
      "epochs =  7 , step =  200 , loss_val =  0.011260287\n",
      "epochs =  7 , step =  300 , loss_val =  0.019965762\n",
      "epochs =  7 , step =  400 , loss_val =  0.02629771\n",
      "epochs =  7 , step =  500 , loss_val =  0.017560842\n",
      "epochs =  8 , step =  0 , loss_val =  0.0068486724\n",
      "epochs =  8 , step =  100 , loss_val =  0.030782884\n",
      "epochs =  8 , step =  200 , loss_val =  0.0070246947\n",
      "epochs =  8 , step =  300 , loss_val =  0.03753131\n",
      "epochs =  8 , step =  400 , loss_val =  0.0018493986\n",
      "epochs =  8 , step =  500 , loss_val =  0.04458618\n",
      "epochs =  9 , step =  0 , loss_val =  0.05177071\n",
      "epochs =  9 , step =  100 , loss_val =  0.015777474\n",
      "epochs =  9 , step =  200 , loss_val =  0.011923976\n",
      "epochs =  9 , step =  300 , loss_val =  0.04911113\n",
      "epochs =  9 , step =  400 , loss_val =  0.0314611\n",
      "epochs =  9 , step =  500 , loss_val =  0.049402744\n",
      "epochs =  10 , step =  0 , loss_val =  0.0075732474\n",
      "epochs =  10 , step =  100 , loss_val =  0.022972701\n",
      "epochs =  10 , step =  200 , loss_val =  0.05029467\n",
      "epochs =  10 , step =  300 , loss_val =  0.094203405\n",
      "epochs =  10 , step =  400 , loss_val =  0.033926137\n",
      "epochs =  10 , step =  500 , loss_val =  0.026829302\n",
      "epochs =  11 , step =  0 , loss_val =  0.008052325\n",
      "epochs =  11 , step =  100 , loss_val =  0.054536074\n",
      "epochs =  11 , step =  200 , loss_val =  0.0052137543\n",
      "epochs =  11 , step =  300 , loss_val =  0.0022512884\n",
      "epochs =  11 , step =  400 , loss_val =  0.008563771\n",
      "epochs =  11 , step =  500 , loss_val =  0.03578485\n",
      "epochs =  12 , step =  0 , loss_val =  0.026123794\n",
      "epochs =  12 , step =  100 , loss_val =  0.013882115\n",
      "epochs =  12 , step =  200 , loss_val =  0.005945214\n",
      "epochs =  12 , step =  300 , loss_val =  0.013243752\n",
      "epochs =  12 , step =  400 , loss_val =  0.012794651\n",
      "epochs =  12 , step =  500 , loss_val =  0.01647025\n",
      "epochs =  13 , step =  0 , loss_val =  0.06653234\n",
      "epochs =  13 , step =  100 , loss_val =  0.020256706\n",
      "epochs =  13 , step =  200 , loss_val =  0.0039214827\n",
      "epochs =  13 , step =  300 , loss_val =  0.0010167365\n",
      "epochs =  13 , step =  400 , loss_val =  0.11051409\n",
      "epochs =  13 , step =  500 , loss_val =  0.010851308\n",
      "epochs =  14 , step =  0 , loss_val =  0.027696012\n",
      "epochs =  14 , step =  100 , loss_val =  0.0010707821\n",
      "epochs =  14 , step =  200 , loss_val =  0.013523664\n",
      "epochs =  14 , step =  300 , loss_val =  0.005859811\n",
      "epochs =  14 , step =  400 , loss_val =  0.08868865\n",
      "epochs =  14 , step =  500 , loss_val =  0.015622138\n",
      "epochs =  15 , step =  0 , loss_val =  0.027586188\n",
      "epochs =  15 , step =  100 , loss_val =  0.02573818\n",
      "epochs =  15 , step =  200 , loss_val =  0.007458534\n",
      "epochs =  15 , step =  300 , loss_val =  0.011328193\n",
      "epochs =  15 , step =  400 , loss_val =  0.027486408\n",
      "epochs =  15 , step =  500 , loss_val =  0.017315557\n",
      "epochs =  16 , step =  0 , loss_val =  0.025002306\n",
      "epochs =  16 , step =  100 , loss_val =  0.14055318\n",
      "epochs =  16 , step =  200 , loss_val =  0.004678834\n",
      "epochs =  16 , step =  300 , loss_val =  0.0058885906\n",
      "epochs =  16 , step =  400 , loss_val =  0.014510362\n",
      "epochs =  16 , step =  500 , loss_val =  0.006434537\n",
      "epochs =  17 , step =  0 , loss_val =  0.04153892\n",
      "epochs =  17 , step =  100 , loss_val =  0.048532497\n",
      "epochs =  17 , step =  200 , loss_val =  0.0012131445\n",
      "epochs =  17 , step =  300 , loss_val =  0.014159378\n",
      "epochs =  17 , step =  400 , loss_val =  0.07828985\n",
      "epochs =  17 , step =  500 , loss_val =  0.03394467\n",
      "epochs =  18 , step =  0 , loss_val =  0.01917775\n",
      "epochs =  18 , step =  100 , loss_val =  0.0069246595\n",
      "epochs =  18 , step =  200 , loss_val =  0.009126115\n",
      "epochs =  18 , step =  300 , loss_val =  0.0060665715\n",
      "epochs =  18 , step =  400 , loss_val =  0.005255699\n",
      "epochs =  18 , step =  500 , loss_val =  0.06017966\n",
      "epochs =  19 , step =  0 , loss_val =  0.011010073\n",
      "epochs =  19 , step =  100 , loss_val =  0.008713306\n",
      "epochs =  19 , step =  200 , loss_val =  0.010551255\n",
      "epochs =  19 , step =  300 , loss_val =  0.01647912\n",
      "epochs =  19 , step =  400 , loss_val =  0.006294455\n",
      "epochs =  19 , step =  500 , loss_val =  0.0070908936\n",
      "epochs =  20 , step =  0 , loss_val =  0.04997977\n",
      "epochs =  20 , step =  100 , loss_val =  0.0035068155\n",
      "epochs =  20 , step =  200 , loss_val =  0.031812817\n",
      "epochs =  20 , step =  300 , loss_val =  0.009059102\n",
      "epochs =  20 , step =  400 , loss_val =  0.03550783\n",
      "epochs =  20 , step =  500 , loss_val =  0.0014021454\n",
      "epochs =  21 , step =  0 , loss_val =  0.0025685618\n",
      "epochs =  21 , step =  100 , loss_val =  0.001218113\n",
      "epochs =  21 , step =  200 , loss_val =  0.023534395\n",
      "epochs =  21 , step =  300 , loss_val =  0.018129556\n",
      "epochs =  21 , step =  400 , loss_val =  0.013454543\n",
      "epochs =  21 , step =  500 , loss_val =  0.025204394\n",
      "epochs =  22 , step =  0 , loss_val =  0.010427146\n",
      "epochs =  22 , step =  100 , loss_val =  0.0051747262\n",
      "epochs =  22 , step =  200 , loss_val =  0.0014627092\n",
      "epochs =  22 , step =  300 , loss_val =  0.0007565072\n",
      "epochs =  22 , step =  400 , loss_val =  0.0021518269\n",
      "epochs =  22 , step =  500 , loss_val =  0.004842173\n",
      "epochs =  23 , step =  0 , loss_val =  0.0068522007\n",
      "epochs =  23 , step =  100 , loss_val =  0.0010674264\n",
      "epochs =  23 , step =  200 , loss_val =  0.0041370057\n",
      "epochs =  23 , step =  300 , loss_val =  0.036938597\n",
      "epochs =  23 , step =  400 , loss_val =  5.7737278e-05\n",
      "epochs =  23 , step =  500 , loss_val =  0.0032558693\n",
      "epochs =  24 , step =  0 , loss_val =  0.008084596\n",
      "epochs =  24 , step =  100 , loss_val =  0.0027673128\n",
      "epochs =  24 , step =  200 , loss_val =  0.029613629\n",
      "epochs =  24 , step =  300 , loss_val =  0.0019470055\n",
      "epochs =  24 , step =  400 , loss_val =  0.00087803206\n",
      "epochs =  24 , step =  500 , loss_val =  0.0052662264\n",
      "epochs =  25 , step =  0 , loss_val =  0.0023377556\n",
      "epochs =  25 , step =  100 , loss_val =  0.0022279115\n",
      "epochs =  25 , step =  200 , loss_val =  0.00092497113\n",
      "epochs =  25 , step =  300 , loss_val =  0.031225357\n",
      "epochs =  25 , step =  400 , loss_val =  0.00047206425\n",
      "epochs =  25 , step =  500 , loss_val =  0.06307652\n",
      "epochs =  26 , step =  0 , loss_val =  0.012901341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  26 , step =  100 , loss_val =  0.013110106\n",
      "epochs =  26 , step =  200 , loss_val =  0.003151434\n",
      "epochs =  26 , step =  300 , loss_val =  0.0045787864\n",
      "epochs =  26 , step =  400 , loss_val =  0.0007008843\n",
      "epochs =  26 , step =  500 , loss_val =  0.013793596\n",
      "epochs =  27 , step =  0 , loss_val =  0.002181731\n",
      "epochs =  27 , step =  100 , loss_val =  0.00659194\n",
      "epochs =  27 , step =  200 , loss_val =  0.008791451\n",
      "epochs =  27 , step =  300 , loss_val =  0.004924037\n",
      "epochs =  27 , step =  400 , loss_val =  0.00648095\n",
      "epochs =  27 , step =  500 , loss_val =  0.003438614\n",
      "epochs =  28 , step =  0 , loss_val =  0.022680122\n",
      "epochs =  28 , step =  100 , loss_val =  6.7973146e-05\n",
      "epochs =  28 , step =  200 , loss_val =  0.0005137474\n",
      "epochs =  28 , step =  300 , loss_val =  0.003573421\n",
      "epochs =  28 , step =  400 , loss_val =  0.00039270942\n",
      "epochs =  28 , step =  500 , loss_val =  0.00097082404\n",
      "epochs =  29 , step =  0 , loss_val =  0.0036345078\n",
      "epochs =  29 , step =  100 , loss_val =  0.0011935271\n",
      "epochs =  29 , step =  200 , loss_val =  3.1816147e-05\n",
      "epochs =  29 , step =  300 , loss_val =  0.00043664203\n",
      "epochs =  29 , step =  400 , loss_val =  0.009332891\n",
      "epochs =  29 , step =  500 , loss_val =  0.006362296\n",
      "\n",
      "Elapsed Time =>  0:28:29.696139\n",
      "\n",
      "Accuracy = 0.9892\n",
      "length of index_label_list =  10000\n",
      "false label count =  108\n",
      "\n",
      "length of index_label_false_list_1 108\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})   \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62, 9, 5], [115, 4, 9], [247, 4, 2], [259, 6, 0], [321, 2, 7], [340, 5, 3], [445, 6, 0], [447, 4, 7], [582, 8, 2], [583, 2, 7], [674, 5, 3], [939, 2, 0], [947, 8, 9], [1014, 6, 0], [1039, 7, 3], [1112, 4, 6], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1319, 8, 0], [1393, 5, 3], [1459, 2, 7], [1641, 5, 9], [1709, 9, 5], [1737, 5, 2], [1790, 2, 7], [1865, 4, 7], [1899, 8, 7], [1901, 9, 4], [1982, 6, 5], [2035, 5, 3], [2040, 5, 8], [2098, 2, 0], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2293, 9, 4], [2387, 9, 1], [2406, 9, 4], [2414, 9, 4], [2597, 5, 3], [2654, 6, 1], [2720, 9, 4], [2760, 9, 4], [2927, 3, 7], [2939, 9, 5], [2953, 3, 5], [3005, 9, 8], [3030, 6, 0], [3073, 1, 2], [3225, 7, 9], [3336, 5, 9], [3337, 2, 7], [3384, 2, 6], [3422, 6, 0], [3475, 3, 7], [3503, 9, 1], [3520, 6, 4], [3534, 4, 8], [3558, 5, 0], [3794, 8, 3], [3808, 7, 8], [3853, 6, 0], [3985, 9, 4], [4007, 7, 4], [4075, 8, 0], [4176, 2, 7], [4205, 2, 8], [4224, 9, 7], [4248, 2, 7], [4497, 8, 7], [4507, 1, 9], [4536, 6, 5], [4571, 6, 0], [4639, 8, 9], [4740, 3, 5], [4761, 9, 8], [4807, 8, 0], [4823, 9, 4], [4860, 4, 9], [4956, 8, 4], [5127, 2, 7], [5457, 1, 4], [5749, 8, 2], [5937, 5, 3], [5981, 5, 9], [5997, 5, 9], [6555, 8, 9], [6571, 9, 7], [6576, 7, 1], [6597, 0, 3], [6721, 2, 7], [6755, 8, 9], [7849, 3, 9], [8059, 2, 1], [8094, 2, 8], [8107, 4, 9], [8339, 8, 5], [8408, 8, 5], [8527, 4, 9], [9679, 6, 2], [9698, 6, 1], [9729, 5, 6], [9768, 2, 8], [9770, 5, 0], [9779, 2, 8], [9792, 4, 9], [9850, 0, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUSEUNG\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\16일차_1124\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "100 image is saved now\n",
      "Elapsed save time =>  0:00:40.718547\n",
      "Total  108  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data_실습4'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_1:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
