{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 은닉층 2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid 함수\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes1, hidden_nodes2, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes1 = hidden_nodes1\n",
    "        self.hidden_nodes2 = hidden_nodes2\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # 은닉층 가중치  W2  Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes1) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes1)      \n",
    "        \n",
    "        # 은닉층 가중치  W3  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes1, self.hidden_nodes2) / np.sqrt(self.hidden_nodes1/2)\n",
    "        self.b3 = np.random.rand(self.hidden_nodes2)\n",
    "        \n",
    "        # 출력층 가중치는 W4  Xavier/He 방법으로 self.W4 가중치 초기화\n",
    "        self.W4 = np.random.randn(self.hidden_nodes2, self.output_nodes) / np.sqrt(self.hidden_nodes2/2)\n",
    "        self.b4 = np.random.rand(self.output_nodes)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z4, 출력값 A4 정의 (모두 행렬로 표시)\n",
    "        self.Z4 = np.zeros([1,output_nodes])\n",
    "        self.A4 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,hidden_nodes2])\n",
    "        self.A3 = np.zeros([1,hidden_nodes2])\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes1])\n",
    "        self.A2 = np.zeros([1,hidden_nodes1])\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])  \n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        return  -np.sum( self.target_data*np.log(self.A4 + delta) + (1-self.target_data)*np.log((1 - self.A4)+delta ) )    \n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        return  -np.sum( self.target_data*np.log(self.A4 + delta) + (1-self.target_data)*np.log((1 - self.A4)+delta ) )  \n",
    "   \n",
    "    def predict(self, input_data):        # input_data 는 행렬로 입력됨 즉, (1, 784) shape 을 가짐        \n",
    "        \n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        Z4 = np.dot(A3, self.W4) + self.b4\n",
    "        A4 = sigmoid(Z4)\n",
    "        \n",
    "        predicted_num = np.argmax(A4)\n",
    "    \n",
    "        return predicted_num\n",
    "    \n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, input_data, target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        # list which contains (index, label, prediction) value\n",
    "        index_label_prediction_list = []\n",
    "        \n",
    "        # temp list which contains label and prediction in sequence\n",
    "        temp_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "                        \n",
    "            label = int(target_data[index])\n",
    "                        \n",
    "            # one-hot encoding을 위한 데이터 정규화 (data normalize)\n",
    "            data = (input_data[index, :] / 255.0 * 0.99) + 0.01\n",
    "            \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌            \n",
    "            predicted_num = self.predict(np.array(data, ndmin=2))\n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                temp_list.append(index)\n",
    "                temp_list.append(label)\n",
    "                temp_list.append(predicted_num)\n",
    "                \n",
    "                index_label_prediction_list.append(temp_list)\n",
    "                \n",
    "                temp_list = []\n",
    "                \n",
    "        print(\"Current Accuracy = \", len(matched_list)/(len(input_data)) )\n",
    "        \n",
    "        return matched_list, not_matched_list, index_label_prediction_list\n",
    "    \n",
    "        \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self, input_data, target_data):\n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()\n",
    "        \n",
    "        # 출력층 loss 인 loss_4 구함\n",
    "        loss_4 = (self.A4-self.target_data) * self.A4 * (1-self.A4)\n",
    "        \n",
    "        # 출력층 가중치 W4, 출력층 바이어스 b4 업데이트\n",
    "        self.W4 = self.W4 - self.learning_rate * np.dot(self.A3.T, loss_4)          \n",
    "        self.b4 = self.b4 - self.learning_rate * loss_4  \n",
    "        \n",
    "        # 은닉층 loss 인 loss_3 구함\n",
    "        loss_3 = np.dot(loss_4, self.W4.T) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        # 은닉층 가중치 W3, 은닉층 바이어스 b3 업데이트\n",
    "        self.W3 = self.W3 - self.learning_rate * np.dot(self.A2.T, loss_3)          \n",
    "        self.b3 = self.b3 - self.learning_rate * loss_3  \n",
    "        \n",
    "        # 은닉층 loss 인 loss_2 구함        \n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        # 은닉층 가중치 W2, 은닉층 바이어스 b2 업데이트\n",
    "        self.W2 = self.W2 - self.learning_rate * np.dot(self.A1.T, loss_2)         \n",
    "        self.b2 = self.b2 - self.learning_rate * loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n",
      "training_data[0,0] =  5.0 , len(training_data[0]) =  785\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 training data 읽어옴\n",
    "training_data = np.loadtxt('./(191116)mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape)\n",
    "print(\"training_data[0,0] = \", training_data[0,0], \", len(training_data[0]) = \", len(training_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차역전파를 이용한 NeuralNetwork class 구현 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , current loss_val =  10.311529663278236\n",
      "epochs =  0 , step =  1000 , current loss_val =  3.0509613736458188\n",
      "epochs =  0 , step =  2000 , current loss_val =  3.201461685134657\n",
      "epochs =  0 , step =  3000 , current loss_val =  3.8728844594017886\n",
      "epochs =  0 , step =  4000 , current loss_val =  2.1303041995336396\n",
      "epochs =  0 , step =  5000 , current loss_val =  1.5099588957590182\n",
      "epochs =  0 , step =  6000 , current loss_val =  1.0812397034324894\n",
      "epochs =  0 , step =  7000 , current loss_val =  1.9378381529671662\n",
      "epochs =  0 , step =  8000 , current loss_val =  0.8902341596885978\n",
      "epochs =  0 , step =  9000 , current loss_val =  1.0411735924453622\n",
      "epochs =  0 , step =  10000 , current loss_val =  0.7922830838886279\n",
      "epochs =  0 , step =  11000 , current loss_val =  0.795068334727032\n",
      "epochs =  0 , step =  12000 , current loss_val =  1.0244654928679673\n",
      "epochs =  0 , step =  13000 , current loss_val =  1.1697255486758897\n",
      "epochs =  0 , step =  14000 , current loss_val =  0.6961899405561711\n",
      "epochs =  0 , step =  15000 , current loss_val =  1.1202077955705296\n",
      "epochs =  0 , step =  16000 , current loss_val =  0.7928144989121981\n",
      "epochs =  0 , step =  17000 , current loss_val =  0.8015647925559117\n",
      "epochs =  0 , step =  18000 , current loss_val =  0.9296870163135893\n",
      "epochs =  0 , step =  19000 , current loss_val =  1.0239301830769199\n",
      "epochs =  0 , step =  20000 , current loss_val =  0.7747132069587179\n",
      "epochs =  0 , step =  21000 , current loss_val =  1.0999037371232352\n",
      "epochs =  0 , step =  22000 , current loss_val =  0.9348185521082184\n",
      "epochs =  0 , step =  23000 , current loss_val =  0.6790346390747336\n",
      "epochs =  0 , step =  24000 , current loss_val =  0.7496677573257677\n",
      "epochs =  0 , step =  25000 , current loss_val =  1.150281742594017\n",
      "epochs =  0 , step =  26000 , current loss_val =  0.7002663131862944\n",
      "epochs =  0 , step =  27000 , current loss_val =  1.1922033609794602\n",
      "epochs =  0 , step =  28000 , current loss_val =  0.6794592661609258\n",
      "epochs =  0 , step =  29000 , current loss_val =  0.6848936938555859\n",
      "epochs =  0 , step =  30000 , current loss_val =  0.6304488908701771\n",
      "epochs =  0 , step =  31000 , current loss_val =  1.6286457955062725\n",
      "epochs =  0 , step =  32000 , current loss_val =  0.6460365626200603\n",
      "epochs =  0 , step =  33000 , current loss_val =  0.9307802130091216\n",
      "epochs =  0 , step =  34000 , current loss_val =  0.871860656333308\n",
      "epochs =  0 , step =  35000 , current loss_val =  0.6904194922216997\n",
      "epochs =  0 , step =  36000 , current loss_val =  0.9455300455297093\n",
      "epochs =  0 , step =  37000 , current loss_val =  0.6971733526024397\n",
      "epochs =  0 , step =  38000 , current loss_val =  0.7317041023354982\n",
      "epochs =  0 , step =  39000 , current loss_val =  1.0053455702579317\n",
      "epochs =  0 , step =  40000 , current loss_val =  0.6616121417799761\n",
      "epochs =  0 , step =  41000 , current loss_val =  0.6855903128547804\n",
      "epochs =  0 , step =  42000 , current loss_val =  0.6470148669550002\n",
      "epochs =  0 , step =  43000 , current loss_val =  1.0962189371800894\n",
      "epochs =  0 , step =  44000 , current loss_val =  0.7127025176485313\n",
      "epochs =  0 , step =  45000 , current loss_val =  0.7736924865449734\n",
      "epochs =  0 , step =  46000 , current loss_val =  0.7951181134107692\n",
      "epochs =  0 , step =  47000 , current loss_val =  0.6973452080542708\n",
      "epochs =  0 , step =  48000 , current loss_val =  0.7575882650559689\n",
      "epochs =  0 , step =  49000 , current loss_val =  0.6935585369008733\n",
      "epochs =  0 , step =  50000 , current loss_val =  0.7408403342542116\n",
      "epochs =  0 , step =  51000 , current loss_val =  0.7907388989552586\n",
      "epochs =  0 , step =  52000 , current loss_val =  0.7591899181482743\n",
      "epochs =  0 , step =  53000 , current loss_val =  0.7799231065247736\n",
      "epochs =  0 , step =  54000 , current loss_val =  0.9045718112162862\n",
      "epochs =  0 , step =  55000 , current loss_val =  0.6919571851122833\n",
      "epochs =  0 , step =  56000 , current loss_val =  0.7157595079692727\n",
      "epochs =  0 , step =  57000 , current loss_val =  0.710083758806952\n",
      "epochs =  0 , step =  58000 , current loss_val =  0.771246045826658\n",
      "epochs =  0 , step =  59000 , current loss_val =  0.7699333487066419\n",
      "epochs =  1 , step =  0 , current loss_val =  0.8752969885012316\n",
      "epochs =  1 , step =  1000 , current loss_val =  0.7367225447261533\n",
      "epochs =  1 , step =  2000 , current loss_val =  1.932081716652688\n",
      "epochs =  1 , step =  3000 , current loss_val =  0.8601503824676507\n",
      "epochs =  1 , step =  4000 , current loss_val =  0.7459469554382195\n",
      "epochs =  1 , step =  5000 , current loss_val =  1.1003465479651504\n",
      "epochs =  1 , step =  6000 , current loss_val =  0.7090644437593366\n",
      "epochs =  1 , step =  7000 , current loss_val =  0.8655477650240309\n",
      "epochs =  1 , step =  8000 , current loss_val =  0.6928197847250042\n",
      "epochs =  1 , step =  9000 , current loss_val =  0.7259675710189171\n",
      "epochs =  1 , step =  10000 , current loss_val =  0.6826330961405108\n",
      "epochs =  1 , step =  11000 , current loss_val =  0.6941256199729228\n",
      "epochs =  1 , step =  12000 , current loss_val =  1.7622199543031853\n",
      "epochs =  1 , step =  13000 , current loss_val =  0.9400756343467586\n",
      "epochs =  1 , step =  14000 , current loss_val =  0.6965878652456886\n",
      "epochs =  1 , step =  15000 , current loss_val =  0.6704286752982709\n",
      "epochs =  1 , step =  16000 , current loss_val =  0.6715980741923813\n",
      "epochs =  1 , step =  17000 , current loss_val =  0.690383100007513\n",
      "epochs =  1 , step =  18000 , current loss_val =  0.7891416952130034\n",
      "epochs =  1 , step =  19000 , current loss_val =  0.7243663839980107\n",
      "epochs =  1 , step =  20000 , current loss_val =  0.6619674438981654\n",
      "epochs =  1 , step =  21000 , current loss_val =  0.927410882185602\n",
      "epochs =  1 , step =  22000 , current loss_val =  0.7957742361269238\n",
      "epochs =  1 , step =  23000 , current loss_val =  0.7445018639244619\n",
      "epochs =  1 , step =  24000 , current loss_val =  0.6719933344835894\n",
      "epochs =  1 , step =  25000 , current loss_val =  0.9744193150897581\n",
      "epochs =  1 , step =  26000 , current loss_val =  0.698498400262186\n",
      "epochs =  1 , step =  27000 , current loss_val =  0.8942338126968976\n",
      "epochs =  1 , step =  28000 , current loss_val =  0.6935169323354347\n",
      "epochs =  1 , step =  29000 , current loss_val =  0.7079954228398823\n",
      "epochs =  1 , step =  30000 , current loss_val =  0.6847963525311431\n",
      "epochs =  1 , step =  31000 , current loss_val =  1.0766997061804815\n",
      "epochs =  1 , step =  32000 , current loss_val =  0.6630934312388006\n",
      "epochs =  1 , step =  33000 , current loss_val =  0.9371187785089394\n",
      "epochs =  1 , step =  34000 , current loss_val =  0.7804574758199805\n",
      "epochs =  1 , step =  35000 , current loss_val =  0.7556365951094665\n",
      "epochs =  1 , step =  36000 , current loss_val =  0.8423897472331714\n",
      "epochs =  1 , step =  37000 , current loss_val =  0.7347211439388921\n",
      "epochs =  1 , step =  38000 , current loss_val =  0.6993301614260901\n",
      "epochs =  1 , step =  39000 , current loss_val =  0.8682325747146147\n",
      "epochs =  1 , step =  40000 , current loss_val =  0.7286931633480436\n",
      "epochs =  1 , step =  41000 , current loss_val =  0.7293005537244732\n",
      "epochs =  1 , step =  42000 , current loss_val =  0.7027499119436046\n",
      "epochs =  1 , step =  43000 , current loss_val =  0.9294404161990022\n",
      "epochs =  1 , step =  44000 , current loss_val =  0.7293999059915068\n",
      "epochs =  1 , step =  45000 , current loss_val =  0.7168164378548282\n",
      "epochs =  1 , step =  46000 , current loss_val =  0.7643767179264402\n",
      "epochs =  1 , step =  47000 , current loss_val =  0.692538289511414\n",
      "epochs =  1 , step =  48000 , current loss_val =  0.78938480295562\n",
      "epochs =  1 , step =  49000 , current loss_val =  0.7263290533872108\n",
      "epochs =  1 , step =  50000 , current loss_val =  0.7139634096341613\n",
      "epochs =  1 , step =  51000 , current loss_val =  0.8188055803748564\n",
      "epochs =  1 , step =  52000 , current loss_val =  0.736913245251871\n",
      "epochs =  1 , step =  53000 , current loss_val =  0.7734295408313053\n",
      "epochs =  1 , step =  54000 , current loss_val =  0.8047530841786209\n",
      "epochs =  1 , step =  55000 , current loss_val =  0.702376678186918\n",
      "epochs =  1 , step =  56000 , current loss_val =  0.7212288229124584\n",
      "epochs =  1 , step =  57000 , current loss_val =  0.7345988189129421\n",
      "epochs =  1 , step =  58000 , current loss_val =  0.7290426191111733\n",
      "epochs =  1 , step =  59000 , current loss_val =  0.7623066600462074\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time =  0:00:23.309551\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 30     # hidden 1 nodes\n",
    "h2_nodes = 30\n",
    "o_nodes = 10       # output nodes\n",
    "lr = 0.1           # learning rate\n",
    "epochs = 2         # epochs\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성\n",
    "loss_val_list = []\n",
    "\n",
    "nn = NeuralNetwork(i_nodes, h1_nodes, h2_nodes, o_nodes, lr)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize        \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \", current loss_val = \", nn.loss_val())\n",
    "        \n",
    "        # 손실함수 값 저장\n",
    "        loss_val_list.append(nn.loss_val())        \n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "test_data = np.loadtxt('./(191116)mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "test_input_data = test_data[ : , 1: ]\n",
    "test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy =  0.9421\n"
     ]
    }
   ],
   "source": [
    "# measure accuracy\n",
    "(true_list, false_list, index_label_prediction_list) = nn.accuracy(test_input_data, test_target_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실함수 추세 확인\n",
    "Y_DATA_LIST = []\n",
    "\n",
    "for index in range(0, len(loss_val_list), 500):\n",
    "    Y_DATA_LIST.append(loss_val_list[index])\n",
    "    \n",
    "plt.title('MNIST Loss Value Trend')\n",
    "plt.xlabel('data index ( X 500 )')\n",
    "plt.ylabel('loss value')\n",
    "plt.grid()\n",
    "plt.plot(Y_DATA_LIST, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
