{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 3x3x32 필터\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 x 14 크기를 가진 32개의 activation map을 flatten 시킴\n",
    "A2_flat = P2_flat = tf.reshape(A2, [-1, 14*14*32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W3 = tf.Variable(tf.random_normal([14*14*32, 10], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀 값 Z3, 즉 softmax 에 들어가는 입력 값\n",
    "Z3 = logits = tf.matmul(A2_flat, W3) + b3\n",
    "\n",
    "y = A3 = tf.nn.softmax(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z3, labels = T))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A3, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.887351\n",
      "epochs =  0 , step =  100 , loss_val =  2.3025444\n",
      "epochs =  0 , step =  200 , loss_val =  2.3240218\n",
      "epochs =  0 , step =  300 , loss_val =  2.3052788\n",
      "epochs =  0 , step =  400 , loss_val =  2.3335454\n",
      "epochs =  0 , step =  500 , loss_val =  2.3147907\n",
      "epochs =  1 , step =  0 , loss_val =  2.310917\n",
      "epochs =  1 , step =  100 , loss_val =  2.346927\n",
      "epochs =  1 , step =  200 , loss_val =  2.2917118\n",
      "epochs =  1 , step =  300 , loss_val =  2.2809\n",
      "epochs =  1 , step =  400 , loss_val =  2.2820055\n",
      "epochs =  1 , step =  500 , loss_val =  2.283679\n",
      "epochs =  2 , step =  0 , loss_val =  2.2836971\n",
      "epochs =  2 , step =  100 , loss_val =  2.2694738\n",
      "epochs =  2 , step =  200 , loss_val =  2.2541814\n",
      "epochs =  2 , step =  300 , loss_val =  2.2384717\n",
      "epochs =  2 , step =  400 , loss_val =  2.1949968\n",
      "epochs =  2 , step =  500 , loss_val =  2.1725283\n",
      "epochs =  3 , step =  0 , loss_val =  2.1553648\n",
      "epochs =  3 , step =  100 , loss_val =  2.1147654\n",
      "epochs =  3 , step =  200 , loss_val =  2.0313718\n",
      "epochs =  3 , step =  300 , loss_val =  1.9943126\n",
      "epochs =  3 , step =  400 , loss_val =  1.8898813\n",
      "epochs =  3 , step =  500 , loss_val =  1.7496121\n",
      "epochs =  4 , step =  0 , loss_val =  1.7740558\n",
      "epochs =  4 , step =  100 , loss_val =  1.627982\n",
      "epochs =  4 , step =  200 , loss_val =  1.3910326\n",
      "epochs =  4 , step =  300 , loss_val =  1.3076957\n",
      "epochs =  4 , step =  400 , loss_val =  1.308718\n",
      "epochs =  4 , step =  500 , loss_val =  1.1783438\n",
      "epochs =  5 , step =  0 , loss_val =  1.1798333\n",
      "epochs =  5 , step =  100 , loss_val =  0.9444874\n",
      "epochs =  5 , step =  200 , loss_val =  0.916696\n",
      "epochs =  5 , step =  300 , loss_val =  0.7945508\n",
      "epochs =  5 , step =  400 , loss_val =  0.8175692\n",
      "epochs =  5 , step =  500 , loss_val =  0.8297855\n",
      "epochs =  6 , step =  0 , loss_val =  0.854909\n",
      "epochs =  6 , step =  100 , loss_val =  0.739396\n",
      "epochs =  6 , step =  200 , loss_val =  0.7587942\n",
      "epochs =  6 , step =  300 , loss_val =  0.6623755\n",
      "epochs =  6 , step =  400 , loss_val =  0.67929053\n",
      "epochs =  6 , step =  500 , loss_val =  0.6513814\n",
      "epochs =  7 , step =  0 , loss_val =  0.6055329\n",
      "epochs =  7 , step =  100 , loss_val =  0.5186162\n",
      "epochs =  7 , step =  200 , loss_val =  0.5629336\n",
      "epochs =  7 , step =  300 , loss_val =  0.56725466\n",
      "epochs =  7 , step =  400 , loss_val =  0.562602\n",
      "epochs =  7 , step =  500 , loss_val =  0.5095695\n",
      "epochs =  8 , step =  0 , loss_val =  0.43105638\n",
      "epochs =  8 , step =  100 , loss_val =  0.48588496\n",
      "epochs =  8 , step =  200 , loss_val =  0.548359\n",
      "epochs =  8 , step =  300 , loss_val =  0.53492266\n",
      "epochs =  8 , step =  400 , loss_val =  0.5053565\n",
      "epochs =  8 , step =  500 , loss_val =  0.585191\n",
      "epochs =  9 , step =  0 , loss_val =  0.48551834\n",
      "epochs =  9 , step =  100 , loss_val =  0.46518984\n",
      "epochs =  9 , step =  200 , loss_val =  0.38690177\n",
      "epochs =  9 , step =  300 , loss_val =  0.42274067\n",
      "epochs =  9 , step =  400 , loss_val =  0.51083964\n",
      "epochs =  9 , step =  500 , loss_val =  0.49016446\n",
      "epochs =  10 , step =  0 , loss_val =  0.38873178\n",
      "epochs =  10 , step =  100 , loss_val =  0.39035937\n",
      "epochs =  10 , step =  200 , loss_val =  0.46005383\n",
      "epochs =  10 , step =  300 , loss_val =  0.4235228\n",
      "epochs =  10 , step =  400 , loss_val =  0.25818992\n",
      "epochs =  10 , step =  500 , loss_val =  0.4476941\n",
      "epochs =  11 , step =  0 , loss_val =  0.3805902\n",
      "epochs =  11 , step =  100 , loss_val =  0.37208423\n",
      "epochs =  11 , step =  200 , loss_val =  0.40514296\n",
      "epochs =  11 , step =  300 , loss_val =  0.47165793\n",
      "epochs =  11 , step =  400 , loss_val =  0.3997592\n",
      "epochs =  11 , step =  500 , loss_val =  0.42068717\n",
      "epochs =  12 , step =  0 , loss_val =  0.32327145\n",
      "epochs =  12 , step =  100 , loss_val =  0.62456924\n",
      "epochs =  12 , step =  200 , loss_val =  0.41548485\n",
      "epochs =  12 , step =  300 , loss_val =  0.33392128\n",
      "epochs =  12 , step =  400 , loss_val =  0.30518147\n",
      "epochs =  12 , step =  500 , loss_val =  0.46510628\n",
      "epochs =  13 , step =  0 , loss_val =  0.35672504\n",
      "epochs =  13 , step =  100 , loss_val =  0.51196903\n",
      "epochs =  13 , step =  200 , loss_val =  0.29043758\n",
      "epochs =  13 , step =  300 , loss_val =  0.3066749\n",
      "epochs =  13 , step =  400 , loss_val =  0.49279374\n",
      "epochs =  13 , step =  500 , loss_val =  0.41467938\n",
      "epochs =  14 , step =  0 , loss_val =  0.4409985\n",
      "epochs =  14 , step =  100 , loss_val =  0.43325722\n",
      "epochs =  14 , step =  200 , loss_val =  0.49524802\n",
      "epochs =  14 , step =  300 , loss_val =  0.38063085\n",
      "epochs =  14 , step =  400 , loss_val =  0.3075576\n",
      "epochs =  14 , step =  500 , loss_val =  0.26879677\n",
      "epochs =  15 , step =  0 , loss_val =  0.41587886\n",
      "epochs =  15 , step =  100 , loss_val =  0.3290819\n",
      "epochs =  15 , step =  200 , loss_val =  0.38092366\n",
      "epochs =  15 , step =  300 , loss_val =  0.40045938\n",
      "epochs =  15 , step =  400 , loss_val =  0.40629745\n",
      "epochs =  15 , step =  500 , loss_val =  0.44642016\n",
      "epochs =  16 , step =  0 , loss_val =  0.3687793\n",
      "epochs =  16 , step =  100 , loss_val =  0.3004787\n",
      "epochs =  16 , step =  200 , loss_val =  0.35656545\n",
      "epochs =  16 , step =  300 , loss_val =  0.44697815\n",
      "epochs =  16 , step =  400 , loss_val =  0.28674313\n",
      "epochs =  16 , step =  500 , loss_val =  0.5777019\n",
      "epochs =  17 , step =  0 , loss_val =  0.37223476\n",
      "epochs =  17 , step =  100 , loss_val =  0.42907807\n",
      "epochs =  17 , step =  200 , loss_val =  0.41930065\n",
      "epochs =  17 , step =  300 , loss_val =  0.28491336\n",
      "epochs =  17 , step =  400 , loss_val =  0.31833652\n",
      "epochs =  17 , step =  500 , loss_val =  0.4101434\n",
      "epochs =  18 , step =  0 , loss_val =  0.5140653\n",
      "epochs =  18 , step =  100 , loss_val =  0.6689933\n",
      "epochs =  18 , step =  200 , loss_val =  0.33368027\n",
      "epochs =  18 , step =  300 , loss_val =  0.3355962\n",
      "epochs =  18 , step =  400 , loss_val =  0.33195236\n",
      "epochs =  18 , step =  500 , loss_val =  0.40471146\n",
      "epochs =  19 , step =  0 , loss_val =  0.31309184\n",
      "epochs =  19 , step =  100 , loss_val =  0.2658935\n",
      "epochs =  19 , step =  200 , loss_val =  0.3097477\n",
      "epochs =  19 , step =  300 , loss_val =  0.28628144\n",
      "epochs =  19 , step =  400 , loss_val =  0.35195103\n",
      "epochs =  19 , step =  500 , loss_val =  0.5075924\n",
      "epochs =  20 , step =  0 , loss_val =  0.4256094\n",
      "epochs =  20 , step =  100 , loss_val =  0.3419833\n",
      "epochs =  20 , step =  200 , loss_val =  0.39425418\n",
      "epochs =  20 , step =  300 , loss_val =  0.4115833\n",
      "epochs =  20 , step =  400 , loss_val =  0.44851846\n",
      "epochs =  20 , step =  500 , loss_val =  0.27923092\n",
      "epochs =  21 , step =  0 , loss_val =  0.2938503\n",
      "epochs =  21 , step =  100 , loss_val =  0.38860986\n",
      "epochs =  21 , step =  200 , loss_val =  0.37770042\n",
      "epochs =  21 , step =  300 , loss_val =  0.3145945\n",
      "epochs =  21 , step =  400 , loss_val =  0.27506953\n",
      "epochs =  21 , step =  500 , loss_val =  0.3040473\n",
      "epochs =  22 , step =  0 , loss_val =  0.39689565\n",
      "epochs =  22 , step =  100 , loss_val =  0.44680974\n",
      "epochs =  22 , step =  200 , loss_val =  0.33449012\n",
      "epochs =  22 , step =  300 , loss_val =  0.3671239\n",
      "epochs =  22 , step =  400 , loss_val =  0.34161177\n",
      "epochs =  22 , step =  500 , loss_val =  0.26028705\n",
      "epochs =  23 , step =  0 , loss_val =  0.25933683\n",
      "epochs =  23 , step =  100 , loss_val =  0.48009086\n",
      "epochs =  23 , step =  200 , loss_val =  0.2866339\n",
      "epochs =  23 , step =  300 , loss_val =  0.3162795\n",
      "epochs =  23 , step =  400 , loss_val =  0.4624606\n",
      "epochs =  23 , step =  500 , loss_val =  0.298077\n",
      "epochs =  24 , step =  0 , loss_val =  0.25779316\n",
      "epochs =  24 , step =  100 , loss_val =  0.39486146\n",
      "epochs =  24 , step =  200 , loss_val =  0.34576318\n",
      "epochs =  24 , step =  300 , loss_val =  0.23758808\n",
      "epochs =  24 , step =  400 , loss_val =  0.25691986\n",
      "epochs =  24 , step =  500 , loss_val =  0.28475893\n",
      "epochs =  25 , step =  0 , loss_val =  0.4449383\n",
      "epochs =  25 , step =  100 , loss_val =  0.33051926\n",
      "epochs =  25 , step =  200 , loss_val =  0.26920122\n",
      "epochs =  25 , step =  300 , loss_val =  0.42719007\n",
      "epochs =  25 , step =  400 , loss_val =  0.2078283\n",
      "epochs =  25 , step =  500 , loss_val =  0.23429999\n",
      "epochs =  26 , step =  0 , loss_val =  0.3252103\n",
      "epochs =  26 , step =  100 , loss_val =  0.35928714\n",
      "epochs =  26 , step =  200 , loss_val =  0.43354285\n",
      "epochs =  26 , step =  300 , loss_val =  0.32158637\n",
      "epochs =  26 , step =  400 , loss_val =  0.41481444\n",
      "epochs =  26 , step =  500 , loss_val =  0.34119263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  27 , step =  0 , loss_val =  0.40261537\n",
      "epochs =  27 , step =  100 , loss_val =  0.38758212\n",
      "epochs =  27 , step =  200 , loss_val =  0.36291993\n",
      "epochs =  27 , step =  300 , loss_val =  0.3488189\n",
      "epochs =  27 , step =  400 , loss_val =  0.27479348\n",
      "epochs =  27 , step =  500 , loss_val =  0.29905853\n",
      "epochs =  28 , step =  0 , loss_val =  0.2922034\n",
      "epochs =  28 , step =  100 , loss_val =  0.35282287\n",
      "epochs =  28 , step =  200 , loss_val =  0.42266577\n",
      "epochs =  28 , step =  300 , loss_val =  0.41609368\n",
      "epochs =  28 , step =  400 , loss_val =  0.33746532\n",
      "epochs =  28 , step =  500 , loss_val =  0.2113461\n",
      "epochs =  29 , step =  0 , loss_val =  0.38832852\n",
      "epochs =  29 , step =  100 , loss_val =  0.29747167\n",
      "epochs =  29 , step =  200 , loss_val =  0.40909123\n",
      "epochs =  29 , step =  300 , loss_val =  0.27978513\n",
      "epochs =  29 , step =  400 , loss_val =  0.3123561\n",
      "epochs =  29 , step =  500 , loss_val =  0.33984944\n",
      "\n",
      "Elapsed Time =>  0:07:17.162524\n",
      "\n",
      "Accuracy = 0.9109\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
