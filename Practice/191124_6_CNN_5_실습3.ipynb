{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 3x3x32 필터 \n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "b2 = tf.Variable(tf.random_normal([32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층, 3x3x32 필터 \n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 32, 32], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([32]))\n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 x 14 x 32 => 14 x 14 x 32 \n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 1번째 max pooling을 통해 14 x 14 x 32 => 7 x 7 x 32\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 x 7 크기를 가진 32개의 activation map을 flatten 시킴\n",
    "A3_flat = P3_flat = tf.reshape(A3, [-1, 7*7*32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W4 = tf.Variable(tf.random_normal([7*7*32, 10], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀 값 Z4, 즉 softmax 에 들어가는 입력 값\n",
    "Z4 = logits = tf.matmul(A3_flat, W4) + b4\n",
    "\n",
    "y = A4 = tf.nn.softmax(Z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z4, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A4, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.493673\n",
      "epochs =  0 , step =  100 , loss_val =  2.2801538\n",
      "epochs =  0 , step =  200 , loss_val =  0.6573056\n",
      "epochs =  0 , step =  300 , loss_val =  0.42214835\n",
      "epochs =  0 , step =  400 , loss_val =  0.29988348\n",
      "epochs =  0 , step =  500 , loss_val =  0.16096729\n",
      "epochs =  1 , step =  0 , loss_val =  0.12485569\n",
      "epochs =  1 , step =  100 , loss_val =  0.32852763\n",
      "epochs =  1 , step =  200 , loss_val =  0.09119329\n",
      "epochs =  1 , step =  300 , loss_val =  0.14299092\n",
      "epochs =  1 , step =  400 , loss_val =  0.094876826\n",
      "epochs =  1 , step =  500 , loss_val =  0.15803787\n",
      "epochs =  2 , step =  0 , loss_val =  0.11226136\n",
      "epochs =  2 , step =  100 , loss_val =  0.061765295\n",
      "epochs =  2 , step =  200 , loss_val =  0.101638444\n",
      "epochs =  2 , step =  300 , loss_val =  0.054650165\n",
      "epochs =  2 , step =  400 , loss_val =  0.106807366\n",
      "epochs =  2 , step =  500 , loss_val =  0.03568222\n",
      "epochs =  3 , step =  0 , loss_val =  0.050348412\n",
      "epochs =  3 , step =  100 , loss_val =  0.056707293\n",
      "epochs =  3 , step =  200 , loss_val =  0.05288665\n",
      "epochs =  3 , step =  300 , loss_val =  0.058709268\n",
      "epochs =  3 , step =  400 , loss_val =  0.07317145\n",
      "epochs =  3 , step =  500 , loss_val =  0.036515094\n",
      "epochs =  4 , step =  0 , loss_val =  0.07042406\n",
      "epochs =  4 , step =  100 , loss_val =  0.06717705\n",
      "epochs =  4 , step =  200 , loss_val =  0.04422871\n",
      "epochs =  4 , step =  300 , loss_val =  0.10510774\n",
      "epochs =  4 , step =  400 , loss_val =  0.047212884\n",
      "epochs =  4 , step =  500 , loss_val =  0.03464321\n",
      "epochs =  5 , step =  0 , loss_val =  0.011194613\n",
      "epochs =  5 , step =  100 , loss_val =  0.067765795\n",
      "epochs =  5 , step =  200 , loss_val =  0.055058412\n",
      "epochs =  5 , step =  300 , loss_val =  0.03657803\n",
      "epochs =  5 , step =  400 , loss_val =  0.08564507\n",
      "epochs =  5 , step =  500 , loss_val =  0.037141576\n",
      "epochs =  6 , step =  0 , loss_val =  0.13744925\n",
      "epochs =  6 , step =  100 , loss_val =  0.027167888\n",
      "epochs =  6 , step =  200 , loss_val =  0.029772544\n",
      "epochs =  6 , step =  300 , loss_val =  0.011541139\n",
      "epochs =  6 , step =  400 , loss_val =  0.022153182\n",
      "epochs =  6 , step =  500 , loss_val =  0.053993884\n",
      "epochs =  7 , step =  0 , loss_val =  0.017113173\n",
      "epochs =  7 , step =  100 , loss_val =  0.090911515\n",
      "epochs =  7 , step =  200 , loss_val =  0.062137965\n",
      "epochs =  7 , step =  300 , loss_val =  0.037615456\n",
      "epochs =  7 , step =  400 , loss_val =  0.06195035\n",
      "epochs =  7 , step =  500 , loss_val =  0.066524595\n",
      "epochs =  8 , step =  0 , loss_val =  0.007831824\n",
      "epochs =  8 , step =  100 , loss_val =  0.046354704\n",
      "epochs =  8 , step =  200 , loss_val =  0.08103664\n",
      "epochs =  8 , step =  300 , loss_val =  0.009066936\n",
      "epochs =  8 , step =  400 , loss_val =  0.016126195\n",
      "epochs =  8 , step =  500 , loss_val =  0.010978818\n",
      "epochs =  9 , step =  0 , loss_val =  0.02323901\n",
      "epochs =  9 , step =  100 , loss_val =  0.002901053\n",
      "epochs =  9 , step =  200 , loss_val =  0.013971013\n",
      "epochs =  9 , step =  300 , loss_val =  0.14655443\n",
      "epochs =  9 , step =  400 , loss_val =  0.038950827\n",
      "epochs =  9 , step =  500 , loss_val =  0.03174055\n",
      "epochs =  10 , step =  0 , loss_val =  0.02957936\n",
      "epochs =  10 , step =  100 , loss_val =  0.08524298\n",
      "epochs =  10 , step =  200 , loss_val =  0.037137333\n",
      "epochs =  10 , step =  300 , loss_val =  0.060396384\n",
      "epochs =  10 , step =  400 , loss_val =  0.014088893\n",
      "epochs =  10 , step =  500 , loss_val =  0.0684861\n",
      "epochs =  11 , step =  0 , loss_val =  0.019263342\n",
      "epochs =  11 , step =  100 , loss_val =  0.025970649\n",
      "epochs =  11 , step =  200 , loss_val =  0.06883615\n",
      "epochs =  11 , step =  300 , loss_val =  0.06675479\n",
      "epochs =  11 , step =  400 , loss_val =  0.024287067\n",
      "epochs =  11 , step =  500 , loss_val =  0.03789145\n",
      "epochs =  12 , step =  0 , loss_val =  0.01816304\n",
      "epochs =  12 , step =  100 , loss_val =  0.006574147\n",
      "epochs =  12 , step =  200 , loss_val =  0.03071561\n",
      "epochs =  12 , step =  300 , loss_val =  0.026072407\n",
      "epochs =  12 , step =  400 , loss_val =  0.02609929\n",
      "epochs =  12 , step =  500 , loss_val =  0.039977327\n",
      "epochs =  13 , step =  0 , loss_val =  0.020461459\n",
      "epochs =  13 , step =  100 , loss_val =  0.024514789\n",
      "epochs =  13 , step =  200 , loss_val =  0.02805367\n",
      "epochs =  13 , step =  300 , loss_val =  0.0130138695\n",
      "epochs =  13 , step =  400 , loss_val =  0.04407236\n",
      "epochs =  13 , step =  500 , loss_val =  0.013219851\n",
      "epochs =  14 , step =  0 , loss_val =  0.014603033\n",
      "epochs =  14 , step =  100 , loss_val =  0.025344977\n",
      "epochs =  14 , step =  200 , loss_val =  0.008640703\n",
      "epochs =  14 , step =  300 , loss_val =  0.023880169\n",
      "epochs =  14 , step =  400 , loss_val =  0.017973563\n",
      "epochs =  14 , step =  500 , loss_val =  0.056929484\n",
      "epochs =  15 , step =  0 , loss_val =  0.00994994\n",
      "epochs =  15 , step =  100 , loss_val =  0.008762744\n",
      "epochs =  15 , step =  200 , loss_val =  0.020387702\n",
      "epochs =  15 , step =  300 , loss_val =  0.010665582\n",
      "epochs =  15 , step =  400 , loss_val =  0.002943506\n",
      "epochs =  15 , step =  500 , loss_val =  0.010077163\n",
      "epochs =  16 , step =  0 , loss_val =  0.025719803\n",
      "epochs =  16 , step =  100 , loss_val =  0.006390072\n",
      "epochs =  16 , step =  200 , loss_val =  0.0041269623\n",
      "epochs =  16 , step =  300 , loss_val =  0.036417615\n",
      "epochs =  16 , step =  400 , loss_val =  0.035791237\n",
      "epochs =  16 , step =  500 , loss_val =  0.003708698\n",
      "epochs =  17 , step =  0 , loss_val =  0.0031089867\n",
      "epochs =  17 , step =  100 , loss_val =  0.037422832\n",
      "epochs =  17 , step =  200 , loss_val =  0.019218441\n",
      "epochs =  17 , step =  300 , loss_val =  0.006095439\n",
      "epochs =  17 , step =  400 , loss_val =  0.0071185892\n",
      "epochs =  17 , step =  500 , loss_val =  0.05055151\n",
      "epochs =  18 , step =  0 , loss_val =  0.0023099096\n",
      "epochs =  18 , step =  100 , loss_val =  0.060046215\n",
      "epochs =  18 , step =  200 , loss_val =  0.0014005706\n",
      "epochs =  18 , step =  300 , loss_val =  0.035228964\n",
      "epochs =  18 , step =  400 , loss_val =  0.046726365\n",
      "epochs =  18 , step =  500 , loss_val =  0.0025287336\n",
      "epochs =  19 , step =  0 , loss_val =  0.06501856\n",
      "epochs =  19 , step =  100 , loss_val =  0.0048295674\n",
      "epochs =  19 , step =  200 , loss_val =  0.009830084\n",
      "epochs =  19 , step =  300 , loss_val =  0.045563567\n",
      "epochs =  19 , step =  400 , loss_val =  0.010663457\n",
      "epochs =  19 , step =  500 , loss_val =  0.018182686\n",
      "epochs =  20 , step =  0 , loss_val =  0.025453148\n",
      "epochs =  20 , step =  100 , loss_val =  0.01820611\n",
      "epochs =  20 , step =  200 , loss_val =  0.04361457\n",
      "epochs =  20 , step =  300 , loss_val =  0.011023259\n",
      "epochs =  20 , step =  400 , loss_val =  0.08351063\n",
      "epochs =  20 , step =  500 , loss_val =  0.09267985\n",
      "epochs =  21 , step =  0 , loss_val =  0.0018283718\n",
      "epochs =  21 , step =  100 , loss_val =  0.019985171\n",
      "epochs =  21 , step =  200 , loss_val =  0.018910011\n",
      "epochs =  21 , step =  300 , loss_val =  0.031054702\n",
      "epochs =  21 , step =  400 , loss_val =  0.034918558\n",
      "epochs =  21 , step =  500 , loss_val =  0.04319014\n",
      "epochs =  22 , step =  0 , loss_val =  0.023155687\n",
      "epochs =  22 , step =  100 , loss_val =  0.0061937682\n",
      "epochs =  22 , step =  200 , loss_val =  0.022118885\n",
      "epochs =  22 , step =  300 , loss_val =  0.03596793\n",
      "epochs =  22 , step =  400 , loss_val =  0.056071967\n",
      "epochs =  22 , step =  500 , loss_val =  0.003519022\n",
      "epochs =  23 , step =  0 , loss_val =  0.011905867\n",
      "epochs =  23 , step =  100 , loss_val =  0.017227843\n",
      "epochs =  23 , step =  200 , loss_val =  0.012925604\n",
      "epochs =  23 , step =  300 , loss_val =  0.012798047\n",
      "epochs =  23 , step =  400 , loss_val =  0.003275136\n",
      "epochs =  23 , step =  500 , loss_val =  0.0009233866\n",
      "epochs =  24 , step =  0 , loss_val =  0.022824228\n",
      "epochs =  24 , step =  100 , loss_val =  0.0015485141\n",
      "epochs =  24 , step =  200 , loss_val =  0.0046461304\n",
      "epochs =  24 , step =  300 , loss_val =  0.04213938\n",
      "epochs =  24 , step =  400 , loss_val =  0.002174167\n",
      "epochs =  24 , step =  500 , loss_val =  0.007449224\n",
      "epochs =  25 , step =  0 , loss_val =  0.0019423325\n",
      "epochs =  25 , step =  100 , loss_val =  0.005424676\n",
      "epochs =  25 , step =  200 , loss_val =  0.0146598015\n",
      "epochs =  25 , step =  300 , loss_val =  0.04215409\n",
      "epochs =  25 , step =  400 , loss_val =  0.017407017\n",
      "epochs =  25 , step =  500 , loss_val =  0.04663484\n",
      "epochs =  26 , step =  0 , loss_val =  0.017910741\n",
      "epochs =  26 , step =  100 , loss_val =  0.006436093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  26 , step =  200 , loss_val =  0.04081489\n",
      "epochs =  26 , step =  300 , loss_val =  0.051287815\n",
      "epochs =  26 , step =  400 , loss_val =  0.0038058893\n",
      "epochs =  26 , step =  500 , loss_val =  0.008454365\n",
      "epochs =  27 , step =  0 , loss_val =  0.016415946\n",
      "epochs =  27 , step =  100 , loss_val =  0.0057496154\n",
      "epochs =  27 , step =  200 , loss_val =  0.00045703896\n",
      "epochs =  27 , step =  300 , loss_val =  0.02190488\n",
      "epochs =  27 , step =  400 , loss_val =  0.008788327\n",
      "epochs =  27 , step =  500 , loss_val =  0.0021050223\n",
      "epochs =  28 , step =  0 , loss_val =  0.0032110813\n",
      "epochs =  28 , step =  100 , loss_val =  0.0051063085\n",
      "epochs =  28 , step =  200 , loss_val =  0.0077796625\n",
      "epochs =  28 , step =  300 , loss_val =  0.009795031\n",
      "epochs =  28 , step =  400 , loss_val =  0.0021701537\n",
      "epochs =  28 , step =  500 , loss_val =  0.007594654\n",
      "epochs =  29 , step =  0 , loss_val =  0.0018860048\n",
      "epochs =  29 , step =  100 , loss_val =  0.0011606656\n",
      "epochs =  29 , step =  200 , loss_val =  0.0074025514\n",
      "epochs =  29 , step =  300 , loss_val =  0.0063950703\n",
      "epochs =  29 , step =  400 , loss_val =  0.042379297\n",
      "epochs =  29 , step =  500 , loss_val =  0.0038370702\n",
      "\n",
      "Elapsed Time =>  0:19:21.774160\n",
      "\n",
      "Accuracy = 0.9832\n",
      "length of index_label_list =  10000\n",
      "false label count =  168\n",
      "\n",
      "length of index_label_false_list_1 168\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})   \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184, 8, 3], [321, 2, 7], [340, 5, 3], [404, 2, 7], [445, 6, 0], [449, 3, 5], [583, 2, 7], [659, 2, 7], [674, 5, 3], [684, 7, 3], [740, 4, 9], [813, 9, 8], [938, 3, 5], [947, 8, 9], [965, 6, 0], [1003, 5, 3], [1014, 6, 5], [1039, 7, 3], [1082, 5, 3], [1112, 4, 6], [1178, 4, 0], [1182, 6, 8], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1319, 8, 0], [1393, 5, 3], [1459, 2, 7], [1522, 7, 9], [1527, 1, 4], [1530, 8, 7], [1709, 9, 5], [1773, 1, 6], [1790, 2, 7], [1878, 8, 3], [1901, 9, 4], [1909, 1, 7], [1993, 1, 7], [2018, 1, 7], [2035, 5, 3], [2053, 4, 9], [2098, 2, 0], [2109, 3, 7], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2148, 4, 9], [2293, 9, 0], [2369, 5, 8], [2437, 2, 7], [2454, 6, 5], [2488, 2, 4], [2532, 6, 1], [2582, 9, 7], [2597, 5, 3], [2654, 6, 1], [2760, 9, 4], [2836, 4, 9], [2896, 8, 0], [2939, 9, 5], [2995, 6, 8], [3030, 6, 0], [3060, 9, 7], [3289, 8, 9], [3336, 5, 7], [3337, 2, 7], [3422, 6, 0], [3474, 2, 1], [3490, 4, 9], [3503, 9, 8], [3520, 6, 4], [3534, 4, 8], [3558, 5, 0], [3559, 8, 5], [3662, 8, 0], [3688, 6, 5], [3726, 4, 9], [3727, 8, 9], [3756, 5, 9], [3794, 8, 3], [3796, 2, 8], [3808, 7, 8], [3850, 9, 4], [3869, 9, 4], [3906, 1, 3], [4007, 7, 4], [4078, 9, 3], [4163, 9, 7], [4176, 2, 7], [4193, 6, 4], [4194, 4, 9], [4224, 9, 7], [4248, 2, 0], [4269, 4, 6], [4284, 9, 5], [4306, 3, 7], [4359, 5, 9], [4360, 5, 3], [4400, 7, 1], [4497, 8, 7], [4504, 2, 7], [4536, 6, 5], [4548, 5, 6], [4571, 6, 0], [4639, 8, 9], [4740, 3, 5], [4783, 4, 9], [4814, 6, 0], [4823, 9, 4], [4860, 4, 9], [4997, 2, 3], [5127, 2, 7], [5331, 1, 6], [5457, 1, 4], [5634, 2, 8], [5676, 4, 7], [5734, 3, 7], [5749, 8, 2], [5757, 9, 7], [5877, 6, 0], [5888, 4, 2], [5936, 4, 9], [5937, 5, 3], [5955, 3, 8], [5973, 3, 8], [5982, 5, 3], [5985, 5, 8], [5997, 5, 3], [6053, 5, 3], [6071, 9, 3], [6166, 9, 3], [6168, 9, 3], [6400, 0, 4], [6558, 6, 5], [6560, 9, 3], [6571, 9, 7], [6597, 0, 3], [6651, 0, 8], [6783, 1, 6], [6847, 6, 4], [6981, 5, 3], [7154, 2, 7], [7216, 0, 6], [7434, 4, 8], [7492, 2, 7], [7545, 8, 9], [7822, 1, 8], [7847, 1, 2], [7857, 2, 4], [7874, 9, 7], [8059, 2, 1], [8094, 2, 8], [8520, 4, 9], [8527, 4, 8], [9530, 9, 8], [9664, 2, 7], [9679, 6, 4], [9692, 9, 7], [9729, 5, 6], [9741, 9, 7], [9749, 5, 0], [9768, 2, 9], [9770, 5, 0], [9779, 2, 8], [9792, 4, 7], [9839, 2, 7], [9904, 2, 8], [9905, 3, 7]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUSEUNG\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\16일차_1124\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "100 image is saved now\n",
      "110 image is saved now\n",
      "120 image is saved now\n",
      "130 image is saved now\n",
      "140 image is saved now\n",
      "150 image is saved now\n",
      "160 image is saved now\n",
      "Elapsed save time =>  0:05:06.698746\n",
      "Total  168  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data_실습3'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_1:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
