{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1 5x5 32개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 5x5x32 필터 \n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 x 5 크기를 가진 32개의 activation map을 flatten 시킴\n",
    "A2_flat = P2_flat = tf.reshape(A2, [-1, 14*14*32])  # 행이 몇게가 오든 열 개수만 맞춰서 나중에 y는 최종적으로 (?, 10) 의 shape가 됨\n",
    "\n",
    "# 은닉층\n",
    "W3 = tf.Variable(tf.random_normal([14*14*32, 256], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "Z3 = tf.matmul(A2_flat, W3) + b3\n",
    "\n",
    "A3 = tf.nn.relu(Z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀  값 Z4, 즉 softmax 에 들어가는 입력 값\n",
    "Z4 = logits = tf.matmul(A3, W4) + b4\n",
    "\n",
    "y = A4 = tf.nn.softmax(Z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z4, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A4, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  3.001625\n",
      "epochs =  0 , step =  100 , loss_val =  0.4168327\n",
      "epochs =  0 , step =  200 , loss_val =  0.1578634\n",
      "epochs =  0 , step =  300 , loss_val =  0.21369287\n",
      "epochs =  0 , step =  400 , loss_val =  0.28838563\n",
      "epochs =  0 , step =  500 , loss_val =  0.099891044\n",
      "epochs =  1 , step =  0 , loss_val =  0.0688131\n",
      "epochs =  1 , step =  100 , loss_val =  0.04921338\n",
      "epochs =  1 , step =  200 , loss_val =  0.11635217\n",
      "epochs =  1 , step =  300 , loss_val =  0.035960566\n",
      "epochs =  1 , step =  400 , loss_val =  0.12707753\n",
      "epochs =  1 , step =  500 , loss_val =  0.10507302\n",
      "epochs =  2 , step =  0 , loss_val =  0.08515879\n",
      "epochs =  2 , step =  100 , loss_val =  0.01818411\n",
      "epochs =  2 , step =  200 , loss_val =  0.027092127\n",
      "epochs =  2 , step =  300 , loss_val =  0.0656172\n",
      "epochs =  2 , step =  400 , loss_val =  0.007654901\n",
      "epochs =  2 , step =  500 , loss_val =  0.016052192\n",
      "epochs =  3 , step =  0 , loss_val =  0.011870658\n",
      "epochs =  3 , step =  100 , loss_val =  0.009611975\n",
      "epochs =  3 , step =  200 , loss_val =  0.016596107\n",
      "epochs =  3 , step =  300 , loss_val =  0.059847765\n",
      "epochs =  3 , step =  400 , loss_val =  0.03722975\n",
      "epochs =  3 , step =  500 , loss_val =  0.016902981\n",
      "epochs =  4 , step =  0 , loss_val =  0.06417116\n",
      "epochs =  4 , step =  100 , loss_val =  0.020000523\n",
      "epochs =  4 , step =  200 , loss_val =  0.061883256\n",
      "epochs =  4 , step =  300 , loss_val =  0.02938425\n",
      "epochs =  4 , step =  400 , loss_val =  0.0076918514\n",
      "epochs =  4 , step =  500 , loss_val =  0.00872465\n",
      "epochs =  5 , step =  0 , loss_val =  0.09179047\n",
      "epochs =  5 , step =  100 , loss_val =  0.03233824\n",
      "epochs =  5 , step =  200 , loss_val =  0.018110175\n",
      "epochs =  5 , step =  300 , loss_val =  0.03573207\n",
      "epochs =  5 , step =  400 , loss_val =  0.012418373\n",
      "epochs =  5 , step =  500 , loss_val =  0.0049086316\n",
      "epochs =  6 , step =  0 , loss_val =  0.027596107\n",
      "epochs =  6 , step =  100 , loss_val =  0.041651864\n",
      "epochs =  6 , step =  200 , loss_val =  0.018935954\n",
      "epochs =  6 , step =  300 , loss_val =  0.003959636\n",
      "epochs =  6 , step =  400 , loss_val =  0.014298923\n",
      "epochs =  6 , step =  500 , loss_val =  0.022616813\n",
      "epochs =  7 , step =  0 , loss_val =  0.006800276\n",
      "epochs =  7 , step =  100 , loss_val =  0.016910696\n",
      "epochs =  7 , step =  200 , loss_val =  0.015416827\n",
      "epochs =  7 , step =  300 , loss_val =  0.0043007843\n",
      "epochs =  7 , step =  400 , loss_val =  0.017148096\n",
      "epochs =  7 , step =  500 , loss_val =  0.024418756\n",
      "epochs =  8 , step =  0 , loss_val =  0.054550152\n",
      "epochs =  8 , step =  100 , loss_val =  0.018557504\n",
      "epochs =  8 , step =  200 , loss_val =  0.018903304\n",
      "epochs =  8 , step =  300 , loss_val =  0.0026153903\n",
      "epochs =  8 , step =  400 , loss_val =  0.001083739\n",
      "epochs =  8 , step =  500 , loss_val =  0.023971232\n",
      "epochs =  9 , step =  0 , loss_val =  0.0013011219\n",
      "epochs =  9 , step =  100 , loss_val =  0.0059609683\n",
      "epochs =  9 , step =  200 , loss_val =  0.024736615\n",
      "epochs =  9 , step =  300 , loss_val =  0.0012352407\n",
      "epochs =  9 , step =  400 , loss_val =  0.008521883\n",
      "epochs =  9 , step =  500 , loss_val =  0.0075916266\n",
      "epochs =  10 , step =  0 , loss_val =  0.0012336877\n",
      "epochs =  10 , step =  100 , loss_val =  0.0021933548\n",
      "epochs =  10 , step =  200 , loss_val =  0.0076340605\n",
      "epochs =  10 , step =  300 , loss_val =  0.00046235227\n",
      "epochs =  10 , step =  400 , loss_val =  0.00749496\n",
      "epochs =  10 , step =  500 , loss_val =  0.0030731466\n",
      "epochs =  11 , step =  0 , loss_val =  0.00032562486\n",
      "epochs =  11 , step =  100 , loss_val =  0.00049411645\n",
      "epochs =  11 , step =  200 , loss_val =  0.0037974727\n",
      "epochs =  11 , step =  300 , loss_val =  0.00206203\n",
      "epochs =  11 , step =  400 , loss_val =  0.018066708\n",
      "epochs =  11 , step =  500 , loss_val =  0.0006143974\n",
      "epochs =  12 , step =  0 , loss_val =  0.00074641523\n",
      "epochs =  12 , step =  100 , loss_val =  5.5821114e-05\n",
      "epochs =  12 , step =  200 , loss_val =  0.0015343657\n",
      "epochs =  12 , step =  300 , loss_val =  0.016148778\n",
      "epochs =  12 , step =  400 , loss_val =  0.0013222126\n",
      "epochs =  12 , step =  500 , loss_val =  0.017767131\n",
      "epochs =  13 , step =  0 , loss_val =  0.004057516\n",
      "epochs =  13 , step =  100 , loss_val =  0.0003360324\n",
      "epochs =  13 , step =  200 , loss_val =  0.009017389\n",
      "epochs =  13 , step =  300 , loss_val =  0.019794345\n",
      "epochs =  13 , step =  400 , loss_val =  0.053925287\n",
      "epochs =  13 , step =  500 , loss_val =  0.0034104562\n",
      "epochs =  14 , step =  0 , loss_val =  0.000113376576\n",
      "epochs =  14 , step =  100 , loss_val =  0.0021330102\n",
      "epochs =  14 , step =  200 , loss_val =  0.02252106\n",
      "epochs =  14 , step =  300 , loss_val =  0.0010036298\n",
      "epochs =  14 , step =  400 , loss_val =  0.00035657152\n",
      "epochs =  14 , step =  500 , loss_val =  0.0011505098\n",
      "epochs =  15 , step =  0 , loss_val =  0.004099484\n",
      "epochs =  15 , step =  100 , loss_val =  0.0001375542\n",
      "epochs =  15 , step =  200 , loss_val =  0.0004677449\n",
      "epochs =  15 , step =  300 , loss_val =  0.03228072\n",
      "epochs =  15 , step =  400 , loss_val =  0.018613417\n",
      "epochs =  15 , step =  500 , loss_val =  0.0008618559\n",
      "epochs =  16 , step =  0 , loss_val =  0.007462224\n",
      "epochs =  16 , step =  100 , loss_val =  0.0003083962\n",
      "epochs =  16 , step =  200 , loss_val =  0.00015962275\n",
      "epochs =  16 , step =  300 , loss_val =  0.00036460336\n",
      "epochs =  16 , step =  400 , loss_val =  0.0033456185\n",
      "epochs =  16 , step =  500 , loss_val =  0.00024656826\n",
      "epochs =  17 , step =  0 , loss_val =  0.0016801615\n",
      "epochs =  17 , step =  100 , loss_val =  0.01672457\n",
      "epochs =  17 , step =  200 , loss_val =  0.0016060498\n",
      "epochs =  17 , step =  300 , loss_val =  0.0008463858\n",
      "epochs =  17 , step =  400 , loss_val =  0.04521784\n",
      "epochs =  17 , step =  500 , loss_val =  0.0018344154\n",
      "epochs =  18 , step =  0 , loss_val =  0.0013514713\n",
      "epochs =  18 , step =  100 , loss_val =  0.0019986725\n",
      "epochs =  18 , step =  200 , loss_val =  0.00016613911\n",
      "epochs =  18 , step =  300 , loss_val =  0.0001718515\n",
      "epochs =  18 , step =  400 , loss_val =  8.891729e-05\n",
      "epochs =  18 , step =  500 , loss_val =  0.00020954346\n",
      "epochs =  19 , step =  0 , loss_val =  0.0005481646\n",
      "epochs =  19 , step =  100 , loss_val =  4.5617177e-05\n",
      "epochs =  19 , step =  200 , loss_val =  0.006984524\n",
      "epochs =  19 , step =  300 , loss_val =  0.002345943\n",
      "epochs =  19 , step =  400 , loss_val =  0.00016342483\n",
      "epochs =  19 , step =  500 , loss_val =  0.0003837384\n",
      "epochs =  20 , step =  0 , loss_val =  0.0056697624\n",
      "epochs =  20 , step =  100 , loss_val =  0.00016666083\n",
      "epochs =  20 , step =  200 , loss_val =  9.914244e-05\n",
      "epochs =  20 , step =  300 , loss_val =  0.004885149\n",
      "epochs =  20 , step =  400 , loss_val =  7.391572e-05\n",
      "epochs =  20 , step =  500 , loss_val =  0.0008102376\n",
      "epochs =  21 , step =  0 , loss_val =  0.013511743\n",
      "epochs =  21 , step =  100 , loss_val =  0.00033647142\n",
      "epochs =  21 , step =  200 , loss_val =  0.00028826628\n",
      "epochs =  21 , step =  300 , loss_val =  0.00041645355\n",
      "epochs =  21 , step =  400 , loss_val =  0.00016996486\n",
      "epochs =  21 , step =  500 , loss_val =  0.0016731004\n",
      "epochs =  22 , step =  0 , loss_val =  0.000112198984\n",
      "epochs =  22 , step =  100 , loss_val =  9.4193594e-05\n",
      "epochs =  22 , step =  200 , loss_val =  0.0011030122\n",
      "epochs =  22 , step =  300 , loss_val =  0.0043817027\n",
      "epochs =  22 , step =  400 , loss_val =  0.0013842068\n",
      "epochs =  22 , step =  500 , loss_val =  1.8493502e-05\n",
      "epochs =  23 , step =  0 , loss_val =  0.0018207976\n",
      "epochs =  23 , step =  100 , loss_val =  0.009712062\n",
      "epochs =  23 , step =  200 , loss_val =  0.00013328524\n",
      "epochs =  23 , step =  300 , loss_val =  0.00042525958\n",
      "epochs =  23 , step =  400 , loss_val =  0.005110305\n",
      "epochs =  23 , step =  500 , loss_val =  0.0002436208\n",
      "epochs =  24 , step =  0 , loss_val =  8.588951e-05\n",
      "epochs =  24 , step =  100 , loss_val =  3.3671884e-06\n",
      "epochs =  24 , step =  200 , loss_val =  0.00073310157\n",
      "epochs =  24 , step =  300 , loss_val =  0.000287331\n",
      "epochs =  24 , step =  400 , loss_val =  0.024488525\n",
      "epochs =  24 , step =  500 , loss_val =  0.0003055592\n",
      "epochs =  25 , step =  0 , loss_val =  0.00055656425\n",
      "epochs =  25 , step =  100 , loss_val =  0.00017456988\n",
      "epochs =  25 , step =  200 , loss_val =  0.04073056\n",
      "epochs =  25 , step =  300 , loss_val =  0.00020920472\n",
      "epochs =  25 , step =  400 , loss_val =  0.0006010819\n",
      "epochs =  25 , step =  500 , loss_val =  0.0005169232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  26 , step =  0 , loss_val =  2.3918592e-05\n",
      "epochs =  26 , step =  100 , loss_val =  6.461652e-05\n",
      "epochs =  26 , step =  200 , loss_val =  0.0010828816\n",
      "epochs =  26 , step =  300 , loss_val =  0.0011622364\n",
      "epochs =  26 , step =  400 , loss_val =  0.0019320026\n",
      "epochs =  26 , step =  500 , loss_val =  0.031969048\n",
      "epochs =  27 , step =  0 , loss_val =  0.006352576\n",
      "epochs =  27 , step =  100 , loss_val =  8.574289e-05\n",
      "epochs =  27 , step =  200 , loss_val =  0.00016445149\n",
      "epochs =  27 , step =  300 , loss_val =  0.00557054\n",
      "epochs =  27 , step =  400 , loss_val =  4.4550943e-05\n",
      "epochs =  27 , step =  500 , loss_val =  0.004915953\n",
      "epochs =  28 , step =  0 , loss_val =  0.0009831644\n",
      "epochs =  28 , step =  100 , loss_val =  0.0005264451\n",
      "epochs =  28 , step =  200 , loss_val =  0.0005189429\n",
      "epochs =  28 , step =  300 , loss_val =  0.13080058\n",
      "epochs =  28 , step =  400 , loss_val =  0.0073313294\n",
      "epochs =  28 , step =  500 , loss_val =  8.189981e-05\n",
      "epochs =  29 , step =  0 , loss_val =  3.7048187e-05\n",
      "epochs =  29 , step =  100 , loss_val =  2.169944e-05\n",
      "epochs =  29 , step =  200 , loss_val =  0.013202832\n",
      "epochs =  29 , step =  300 , loss_val =  2.0467526e-06\n",
      "epochs =  29 , step =  400 , loss_val =  0.00046629773\n",
      "epochs =  29 , step =  500 , loss_val =  9.4096715e-05\n",
      "\n",
      "Elapsed Time =>  0:01:04.479948\n",
      "\n",
      "Accuracy = 0.9873\n",
      "length of index_label_list =  10000\n",
      "false label count =  127\n",
      "\n",
      "length of index_label_false_list_1 127\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})   \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115, 4, 9], [211, 5, 3], [247, 4, 6], [321, 2, 7], [340, 5, 3], [445, 6, 0], [492, 2, 8], [543, 8, 3], [582, 8, 2], [583, 2, 7], [619, 1, 8], [646, 2, 6], [659, 2, 1], [684, 7, 3], [839, 8, 3], [844, 8, 7], [900, 1, 3], [947, 8, 9], [956, 1, 3], [1014, 6, 5], [1033, 8, 1], [1039, 7, 3], [1112, 4, 6], [1182, 6, 5], [1187, 2, 1], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1260, 7, 1], [1319, 8, 3], [1393, 5, 3], [1500, 7, 3], [1522, 7, 9], [1530, 8, 7], [1553, 9, 3], [1709, 9, 3], [1790, 2, 7], [1878, 8, 3], [1901, 9, 4], [2035, 5, 3], [2070, 7, 9], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2293, 9, 4], [2369, 5, 3], [2437, 2, 1], [2488, 2, 4], [2582, 9, 3], [2597, 5, 3], [2648, 9, 8], [2654, 6, 1], [2810, 5, 3], [2896, 8, 0], [2921, 3, 2], [2939, 9, 5], [2953, 3, 5], [2970, 5, 3], [2995, 6, 5], [3100, 5, 3], [3289, 8, 9], [3451, 7, 9], [3503, 9, 1], [3520, 6, 4], [3534, 4, 8], [3558, 5, 3], [3626, 8, 3], [3662, 8, 3], [3681, 2, 3], [3727, 8, 3], [3794, 8, 3], [3808, 7, 8], [3902, 5, 3], [4163, 9, 7], [4176, 2, 7], [4201, 1, 7], [4248, 2, 1], [4256, 3, 2], [4265, 4, 3], [4360, 5, 3], [4497, 8, 7], [4536, 6, 5], [4740, 3, 5], [4761, 9, 8], [4807, 8, 0], [4823, 9, 4], [5749, 8, 5], [5887, 7, 0], [5937, 5, 3], [5972, 5, 3], [5981, 5, 3], [5982, 5, 3], [5997, 5, 3], [6042, 5, 3], [6071, 9, 3], [6091, 9, 5], [6166, 9, 3], [6173, 9, 8], [6560, 9, 5], [6571, 9, 3], [6574, 2, 6], [6576, 7, 1], [6597, 0, 9], [6603, 8, 7], [6625, 8, 2], [6651, 0, 8], [7240, 5, 3], [8059, 2, 1], [8069, 2, 1], [8094, 2, 8], [8325, 0, 6], [8527, 4, 9], [9015, 7, 2], [9280, 8, 5], [9540, 1, 8], [9587, 9, 4], [9634, 0, 8], [9638, 9, 7], [9664, 2, 7], [9679, 6, 3], [9692, 9, 7], [9698, 6, 1], [9729, 5, 6], [9770, 5, 0], [9792, 4, 9], [9839, 2, 7], [9982, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUSEUNG\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\16일차_1124\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "Elapsed save time =>  0:00:16.261903\n",
      "Total  62  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data_실습5'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_1:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
