{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1 4x4 32개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 4x4x32 필터 \n",
    "W2 = tf.Variable(tf.random_normal([4, 4, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 2 4x4 64개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층, 4x4x64 필터 \n",
    "W3 = tf.Variable(tf.random_normal([4, 4, 32, 64], stddev=0.01))\n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 x 14 x 32 => 14 x 14 x 64 \n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 2번째 max pooling을 통해 14 x 14 x 64 => 7 x 7 x 64\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 3 4x4 128개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3번째 컨볼루션 층, 4x4x128 필터 \n",
    "W4 = tf.Variable(tf.random_normal([4, 4, 64, 128], stddev=0.01))\n",
    "b4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "\n",
    "# 3번째 컨볼루션 연산을 통해 7 x 7 x 64 => 7 x 7 x 128 \n",
    "C4 = tf.nn.conv2d(A3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z4 = tf.nn.relu(C4+b4)\n",
    "\n",
    "# 3번째 max pooling을 통해 7 x 7 x 128 => 4 x 4 x 128\n",
    "A4 = P4 = tf.nn.max_pool(Z4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 x 4 크기를 가진 128개의 activation map을 flatten 시킴\n",
    "A4_flat = P4_flat = tf.reshape(A4, [-1, 4*4*128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W5 = tf.Variable(tf.random_normal([4*4*128, 10], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀 값 Z5, 즉 softmax 에 들어가는 입력 값\n",
    "Z5 = logits = tf.matmul(A4_flat, W5) + b5\n",
    "\n",
    "y = A5 = tf.nn.softmax(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z5, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A5, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.6809683\n",
      "epochs =  0 , step =  100 , loss_val =  1.2978102\n",
      "epochs =  0 , step =  200 , loss_val =  0.17151552\n",
      "epochs =  0 , step =  300 , loss_val =  0.13452484\n",
      "epochs =  0 , step =  400 , loss_val =  0.13709478\n",
      "epochs =  0 , step =  500 , loss_val =  0.051813297\n",
      "epochs =  1 , step =  0 , loss_val =  0.07210831\n",
      "epochs =  1 , step =  100 , loss_val =  0.032120187\n",
      "epochs =  1 , step =  200 , loss_val =  0.110356614\n",
      "epochs =  1 , step =  300 , loss_val =  0.08407688\n",
      "epochs =  1 , step =  400 , loss_val =  0.04305974\n",
      "epochs =  1 , step =  500 , loss_val =  0.025317773\n",
      "epochs =  2 , step =  0 , loss_val =  0.028169045\n",
      "epochs =  2 , step =  100 , loss_val =  0.05298093\n",
      "epochs =  2 , step =  200 , loss_val =  0.021319175\n",
      "epochs =  2 , step =  300 , loss_val =  0.033619244\n",
      "epochs =  2 , step =  400 , loss_val =  0.1135024\n",
      "epochs =  2 , step =  500 , loss_val =  0.03850429\n",
      "epochs =  3 , step =  0 , loss_val =  0.018911982\n",
      "epochs =  3 , step =  100 , loss_val =  0.027933182\n",
      "epochs =  3 , step =  200 , loss_val =  0.017033592\n",
      "epochs =  3 , step =  300 , loss_val =  0.055263247\n",
      "epochs =  3 , step =  400 , loss_val =  0.016943946\n",
      "epochs =  3 , step =  500 , loss_val =  0.02426048\n",
      "epochs =  4 , step =  0 , loss_val =  0.04209943\n",
      "epochs =  4 , step =  100 , loss_val =  0.0040380172\n",
      "epochs =  4 , step =  200 , loss_val =  0.001440538\n",
      "epochs =  4 , step =  300 , loss_val =  0.034382787\n",
      "epochs =  4 , step =  400 , loss_val =  0.03742549\n",
      "epochs =  4 , step =  500 , loss_val =  0.027017707\n",
      "epochs =  5 , step =  0 , loss_val =  0.013263058\n",
      "epochs =  5 , step =  100 , loss_val =  0.044000365\n",
      "epochs =  5 , step =  200 , loss_val =  0.0026653002\n",
      "epochs =  5 , step =  300 , loss_val =  0.013555039\n",
      "epochs =  5 , step =  400 , loss_val =  0.013123869\n",
      "epochs =  5 , step =  500 , loss_val =  0.03394059\n",
      "epochs =  6 , step =  0 , loss_val =  0.0014264804\n",
      "epochs =  6 , step =  100 , loss_val =  0.002110363\n",
      "epochs =  6 , step =  200 , loss_val =  0.009410535\n",
      "epochs =  6 , step =  300 , loss_val =  0.00060821715\n",
      "epochs =  6 , step =  400 , loss_val =  0.03946403\n",
      "epochs =  6 , step =  500 , loss_val =  0.038219716\n",
      "epochs =  7 , step =  0 , loss_val =  0.018469237\n",
      "epochs =  7 , step =  100 , loss_val =  0.00047921418\n",
      "epochs =  7 , step =  200 , loss_val =  0.011484207\n",
      "epochs =  7 , step =  300 , loss_val =  0.02247249\n",
      "epochs =  7 , step =  400 , loss_val =  0.009509097\n",
      "epochs =  7 , step =  500 , loss_val =  0.000674716\n",
      "epochs =  8 , step =  0 , loss_val =  0.00085064175\n",
      "epochs =  8 , step =  100 , loss_val =  0.001553318\n",
      "epochs =  8 , step =  200 , loss_val =  0.011823455\n",
      "epochs =  8 , step =  300 , loss_val =  0.009019059\n",
      "epochs =  8 , step =  400 , loss_val =  0.007528657\n",
      "epochs =  8 , step =  500 , loss_val =  0.00072608615\n",
      "epochs =  9 , step =  0 , loss_val =  0.052150007\n",
      "epochs =  9 , step =  100 , loss_val =  0.015742587\n",
      "epochs =  9 , step =  200 , loss_val =  0.108311325\n",
      "epochs =  9 , step =  300 , loss_val =  0.00045750436\n",
      "epochs =  9 , step =  400 , loss_val =  0.0006229849\n",
      "epochs =  9 , step =  500 , loss_val =  0.0056536812\n",
      "epochs =  10 , step =  0 , loss_val =  0.0019958755\n",
      "epochs =  10 , step =  100 , loss_val =  0.018543018\n",
      "epochs =  10 , step =  200 , loss_val =  0.038264345\n",
      "epochs =  10 , step =  300 , loss_val =  0.00020373552\n",
      "epochs =  10 , step =  400 , loss_val =  0.015836252\n",
      "epochs =  10 , step =  500 , loss_val =  0.011678888\n",
      "epochs =  11 , step =  0 , loss_val =  0.003916562\n",
      "epochs =  11 , step =  100 , loss_val =  0.037607674\n",
      "epochs =  11 , step =  200 , loss_val =  0.0021727143\n",
      "epochs =  11 , step =  300 , loss_val =  1.9090623e-05\n",
      "epochs =  11 , step =  400 , loss_val =  0.0179898\n",
      "epochs =  11 , step =  500 , loss_val =  0.014169836\n",
      "epochs =  12 , step =  0 , loss_val =  0.00026481852\n",
      "epochs =  12 , step =  100 , loss_val =  0.009814982\n",
      "epochs =  12 , step =  200 , loss_val =  0.00070983596\n",
      "epochs =  12 , step =  300 , loss_val =  5.7509464e-05\n",
      "epochs =  12 , step =  400 , loss_val =  0.017212925\n",
      "epochs =  12 , step =  500 , loss_val =  0.00073479145\n",
      "epochs =  13 , step =  0 , loss_val =  0.00038437135\n",
      "epochs =  13 , step =  100 , loss_val =  0.00025536036\n",
      "epochs =  13 , step =  200 , loss_val =  0.0049556256\n",
      "epochs =  13 , step =  300 , loss_val =  0.00035861923\n",
      "epochs =  13 , step =  400 , loss_val =  0.00011241745\n",
      "epochs =  13 , step =  500 , loss_val =  0.0001540453\n",
      "epochs =  14 , step =  0 , loss_val =  0.005356707\n",
      "epochs =  14 , step =  100 , loss_val =  1.51076865e-05\n",
      "epochs =  14 , step =  200 , loss_val =  7.159428e-05\n",
      "epochs =  14 , step =  300 , loss_val =  0.0005125789\n",
      "epochs =  14 , step =  400 , loss_val =  0.00067069853\n",
      "epochs =  14 , step =  500 , loss_val =  5.3141437e-05\n",
      "epochs =  15 , step =  0 , loss_val =  0.0012675895\n",
      "epochs =  15 , step =  100 , loss_val =  3.4744407e-05\n",
      "epochs =  15 , step =  200 , loss_val =  0.02832725\n",
      "epochs =  15 , step =  300 , loss_val =  0.0006026923\n",
      "epochs =  15 , step =  400 , loss_val =  0.0007565103\n",
      "epochs =  15 , step =  500 , loss_val =  0.0003110365\n",
      "epochs =  16 , step =  0 , loss_val =  3.0892632e-05\n",
      "epochs =  16 , step =  100 , loss_val =  0.00028147417\n",
      "epochs =  16 , step =  200 , loss_val =  0.0015700855\n",
      "epochs =  16 , step =  300 , loss_val =  3.1875818e-05\n",
      "epochs =  16 , step =  400 , loss_val =  2.6949945e-05\n",
      "epochs =  16 , step =  500 , loss_val =  2.344874e-05\n",
      "epochs =  17 , step =  0 , loss_val =  0.01309755\n",
      "epochs =  17 , step =  100 , loss_val =  0.12616622\n",
      "epochs =  17 , step =  200 , loss_val =  0.00013379891\n",
      "epochs =  17 , step =  300 , loss_val =  0.0033677653\n",
      "epochs =  17 , step =  400 , loss_val =  0.0001509324\n",
      "epochs =  17 , step =  500 , loss_val =  0.02287907\n",
      "epochs =  18 , step =  0 , loss_val =  9.196984e-05\n",
      "epochs =  18 , step =  100 , loss_val =  0.0010458144\n",
      "epochs =  18 , step =  200 , loss_val =  1.6876731e-05\n",
      "epochs =  18 , step =  300 , loss_val =  0.00019372486\n",
      "epochs =  18 , step =  400 , loss_val =  0.00017033351\n",
      "epochs =  18 , step =  500 , loss_val =  0.00080013485\n",
      "epochs =  19 , step =  0 , loss_val =  0.0010776083\n",
      "epochs =  19 , step =  100 , loss_val =  0.021678144\n",
      "epochs =  19 , step =  200 , loss_val =  9.1375296e-05\n",
      "epochs =  19 , step =  300 , loss_val =  0.0031812184\n",
      "epochs =  19 , step =  400 , loss_val =  0.0006881152\n",
      "epochs =  19 , step =  500 , loss_val =  1.2887525e-05\n",
      "epochs =  20 , step =  0 , loss_val =  0.0026217594\n",
      "epochs =  20 , step =  100 , loss_val =  0.00090253085\n",
      "epochs =  20 , step =  200 , loss_val =  4.372244e-05\n",
      "epochs =  20 , step =  300 , loss_val =  0.00062114187\n",
      "epochs =  20 , step =  400 , loss_val =  0.00017649436\n",
      "epochs =  20 , step =  500 , loss_val =  6.0705424e-05\n",
      "epochs =  21 , step =  0 , loss_val =  0.007484228\n",
      "epochs =  21 , step =  100 , loss_val =  2.1183629e-05\n",
      "epochs =  21 , step =  200 , loss_val =  1.0907428e-06\n",
      "epochs =  21 , step =  300 , loss_val =  0.0002881239\n",
      "epochs =  21 , step =  400 , loss_val =  8.362156e-05\n",
      "epochs =  21 , step =  500 , loss_val =  0.0008139934\n",
      "epochs =  22 , step =  0 , loss_val =  1.2133299e-05\n",
      "epochs =  22 , step =  100 , loss_val =  2.0848188e-06\n",
      "epochs =  22 , step =  200 , loss_val =  0.016988385\n",
      "epochs =  22 , step =  300 , loss_val =  0.00011805544\n",
      "epochs =  22 , step =  400 , loss_val =  0.004575037\n",
      "epochs =  22 , step =  500 , loss_val =  0.00023366277\n",
      "epochs =  23 , step =  0 , loss_val =  0.0021205689\n",
      "epochs =  23 , step =  100 , loss_val =  2.2990469e-05\n",
      "epochs =  23 , step =  200 , loss_val =  0.00023758347\n",
      "epochs =  23 , step =  300 , loss_val =  6.856371e-05\n",
      "epochs =  23 , step =  400 , loss_val =  5.7955833e-05\n",
      "epochs =  23 , step =  500 , loss_val =  0.00010764854\n",
      "epochs =  24 , step =  0 , loss_val =  0.00024751612\n",
      "epochs =  24 , step =  100 , loss_val =  1.816283e-05\n",
      "epochs =  24 , step =  200 , loss_val =  8.6902435e-07\n",
      "epochs =  24 , step =  300 , loss_val =  0.0019911074\n",
      "epochs =  24 , step =  400 , loss_val =  4.766337e-06\n",
      "epochs =  24 , step =  500 , loss_val =  1.3327284e-06\n",
      "epochs =  25 , step =  0 , loss_val =  1.6408125e-05\n",
      "epochs =  25 , step =  100 , loss_val =  2.9484434e-05\n",
      "epochs =  25 , step =  200 , loss_val =  2.189771e-06\n",
      "epochs =  25 , step =  300 , loss_val =  8.39888e-05\n",
      "epochs =  25 , step =  400 , loss_val =  2.5868212e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  25 , step =  500 , loss_val =  0.0018290709\n",
      "epochs =  26 , step =  0 , loss_val =  0.00015769366\n",
      "epochs =  26 , step =  100 , loss_val =  7.2127614e-06\n",
      "epochs =  26 , step =  200 , loss_val =  6.951968e-05\n",
      "epochs =  26 , step =  300 , loss_val =  0.013126451\n",
      "epochs =  26 , step =  400 , loss_val =  1.8932291e-05\n",
      "epochs =  26 , step =  500 , loss_val =  0.00010076033\n",
      "epochs =  27 , step =  0 , loss_val =  6.778843e-05\n",
      "epochs =  27 , step =  100 , loss_val =  0.025026023\n",
      "epochs =  27 , step =  200 , loss_val =  0.00025821952\n",
      "epochs =  27 , step =  300 , loss_val =  0.00037729132\n",
      "epochs =  27 , step =  400 , loss_val =  0.026374137\n",
      "epochs =  27 , step =  500 , loss_val =  2.6376314e-05\n",
      "epochs =  28 , step =  0 , loss_val =  0.014242364\n",
      "epochs =  28 , step =  100 , loss_val =  1.3446136e-06\n",
      "epochs =  28 , step =  200 , loss_val =  0.013837142\n",
      "epochs =  28 , step =  300 , loss_val =  6.0796694e-08\n",
      "epochs =  28 , step =  400 , loss_val =  6.6075063e-06\n",
      "epochs =  28 , step =  500 , loss_val =  9.965489e-06\n",
      "epochs =  29 , step =  0 , loss_val =  3.042953e-06\n",
      "epochs =  29 , step =  100 , loss_val =  1.3589832e-07\n",
      "epochs =  29 , step =  200 , loss_val =  6.489585e-05\n",
      "epochs =  29 , step =  300 , loss_val =  0.0003096488\n",
      "epochs =  29 , step =  400 , loss_val =  0.006709991\n",
      "epochs =  29 , step =  500 , loss_val =  0.000109738074\n",
      "\n",
      "Elapsed Time =>  0:03:27.446491\n",
      "\n",
      "Accuracy = 0.9918\n",
      "length of index_label_list =  10000\n",
      "false label count =  82\n",
      "\n",
      "length of index_label_false_list_1 82\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})   \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115, 4, 9], [321, 2, 7], [340, 5, 3], [445, 6, 0], [582, 8, 2], [659, 2, 7], [674, 5, 3], [716, 1, 7], [726, 7, 3], [846, 7, 9], [947, 8, 9], [1014, 6, 0], [1039, 7, 1], [1112, 4, 6], [1224, 2, 1], [1393, 5, 3], [1414, 9, 4], [1459, 2, 3], [1500, 7, 3], [1709, 9, 3], [1790, 2, 7], [1878, 8, 3], [1901, 9, 4], [2035, 5, 3], [2043, 4, 8], [2070, 7, 9], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2182, 1, 3], [2225, 8, 9], [2293, 9, 4], [2314, 7, 4], [2343, 1, 7], [2447, 4, 9], [2597, 5, 3], [2654, 6, 1], [2939, 9, 5], [2970, 5, 3], [3288, 4, 9], [3343, 8, 2], [3422, 6, 0], [3520, 6, 4], [3558, 5, 3], [3559, 8, 5], [3762, 6, 8], [3780, 4, 6], [3808, 7, 8], [3906, 1, 3], [4176, 2, 7], [4199, 7, 9], [4238, 7, 3], [4443, 3, 7], [4497, 8, 7], [4505, 9, 3], [4699, 6, 1], [4740, 3, 5], [4807, 8, 0], [4860, 4, 9], [5937, 5, 3], [5955, 3, 8], [5997, 5, 9], [6560, 9, 5], [6576, 7, 1], [6597, 0, 9], [6625, 8, 2], [7928, 1, 0], [8061, 4, 9], [8408, 8, 5], [8527, 4, 9], [9015, 7, 2], [9679, 6, 1], [9729, 5, 6], [9792, 4, 9], [9839, 2, 7]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\16일차_1124\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "Elapsed save time =>  0:00:17.712982\n",
      "Total  75  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data_실습5_copy'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_1:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
