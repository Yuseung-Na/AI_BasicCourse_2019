{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드 pd.read_csv(' ').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv_data.shape =  (891, 12) , type(train_csv_data) =  <class 'numpy.ndarray'>\n",
      "test_csv_data.shape =  (418, 11) , type(test_csv_data) =  <class 'numpy.ndarray'>\n",
      "test_csv_sub.shape =  (418, 2) , type(test_csv_sub) =  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Load Kaggle Data as matrix\n",
    "train_csv_data = pd.read_csv('./titanic_train.csv').values\n",
    "test_csv_data = pd.read_csv('./titanic_test.csv').values\n",
    "test_csv_sub = pd.read_csv('./titanic_gender_submission.csv').values\n",
    "\n",
    "print('train_csv_data.shape = ', train_csv_data.shape, ', type(train_csv_data) = ', type(train_csv_data))\n",
    "print('test_csv_data.shape = ', test_csv_data.shape, ', type(test_csv_data) = ', type(test_csv_data))\n",
    "print('test_csv_sub.shape = ', test_csv_sub.shape, ', type(test_csv_sub) = ', type(test_csv_sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 변환 (문자 -> 숫자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data 에서 male -> 1.0, female -> 0.0\n",
    "for i in range(len(train_csv_data)):\n",
    "    if train_csv_data[i, 4] == 'male':\n",
    "        train_csv_data[i, 4] = 1.0\n",
    "    else:\n",
    "        train_csv_data[i, 4] = 0.0\n",
    "        \n",
    "# test data 에서 male -> 1.0, female -> 0.0\n",
    "for i in range(len(test_csv_data)):\n",
    "    if test_csv_data[i, 3] == 'male':\n",
    "        test_csv_data[i, 3] = 1.0\n",
    "    else:\n",
    "        test_csv_data[i, 3] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data 에서 Embarked, Empty -> 0.0, S -> 1.0, C -> 2.0, Q -> 3.0\n",
    "for i in range(len(train_csv_data)):\n",
    "    if train_csv_data[i, 11] == 'S': \n",
    "        train_csv_data[i, 11] = 1.0   \n",
    "    elif train_csv_data[i, 11] == 'C':     \n",
    "        train_csv_data[i, 11] = 2.0     \n",
    "    elif train_csv_data[i, 11] == 'Q':    \n",
    "        train_csv_data[i, 11] = 3.0    \n",
    "        \n",
    "    if np.isnan(train_csv_data[i, 11]):  \n",
    "        train_csv_data[i, 11] = 0.0\n",
    "        \n",
    "\n",
    "# test data 에서 Embarked, Empty -> 0.0, S -> 1.0, C -> 2.0, Q -> 3.0\n",
    "for i in range(len(test_csv_data)):\n",
    "    if test_csv_data[i, 10] == 'S':    \n",
    "        test_csv_data[i, 10] = 1.0    \n",
    "    elif test_csv_data[i, 10] == 'C':   \n",
    "        test_csv_data[i, 10] = 2.0     \n",
    "    elif test_csv_data[i, 10] == 'Q':   \n",
    "        test_csv_data[i, 10] = 3.0\n",
    "        \n",
    "    if np.isnan(test_csv_data[i, 10]):    \n",
    "        test_csv_data[i, 10] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_data / training_data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_x_data.shape = (891, 5) , training_t_data.shape = (891, 1)\n",
      "test_x_data.shape = (418, 5) , test_t_data.shape = (418, 1)\n"
     ]
    }
   ],
   "source": [
    "training_x_data = train_csv_data[ : , [ 2, 4, 6, 7, 11 ] ]  # Pclass, Sex, SibSp, Parch, Embarked\n",
    "training_t_data = train_csv_data[ :, 1:2]\n",
    "\n",
    "test_x_data = test_csv_data[ : , [ 1, 3, 5, 6, 10 ] ]  # Pclass, Sex, SibSp, Parch, Embarked\n",
    "test_t_data = test_csv_sub[ :, 1:2]  # test_csv_sub 에서 데이터 가져옴. 주의 요함\n",
    "\n",
    "print(\"training_x_data.shape =\", training_x_data.shape, \", training_t_data.shape =\", training_t_data.shape)\n",
    "print(\"test_x_data.shape =\", test_x_data.shape, \", test_t_data.shape =\", test_t_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow - 노드 / 연산 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter Definition\n",
    "learning_rate = 1e-2\n",
    "input_nodes = training_x_data.shape[1]  \n",
    "hidden_1_nodes = 100\n",
    "output_nodes = 1\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 출력을 위한 플레이스홀더 정의\n",
    "X_DATA = tf.placeholder(tf.float32, [None, input_nodes])  \n",
    "T_DATA = tf.placeholder(tf.float32, [None, output_nodes])  \n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_1_nodes]))  # 은닉층 1가중치 노드\n",
    "b2 = tf.Variable(tf.random_normal([hidden_1_nodes]))               # 은닉층 1바이어스 노드\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([hidden_1_nodes, output_nodes])) # 출력층 가중치 노드\n",
    "b3 = tf.Variable(tf.random_normal([output_nodes]))               # 출력층 바이어스 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed forward\n",
    "Z2 = tf.matmul(X_DATA, W2) + b2\n",
    "A2 = tf.sigmoid(Z2)\n",
    "\n",
    "Z3 = tf.matmul(A2, W3) + b3  \n",
    "y = A3 = tf.sigmoid(Z3)    # 최종 계산값\n",
    "\n",
    "# 손실함수는 Cross-Entropy \n",
    "loss = -tf.reduce_mean( T_DATA*tf.log(y) + (1-T_DATA)*tf.log(1-y) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientDescent \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)  # 앞으로 이 부분만 바뀔 것임\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확성 검사, True if y > 0.5 else False\n",
    "predicted = tf.cast(y > 0.5, dtype=tf.float32)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, T_DATA), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow - 노드 / 연산 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  1.4571259\n",
      "epochs =  0 , step =  1000 , loss_val =  0.4562624\n",
      "epochs =  0 , step =  2000 , loss_val =  0.44368717\n",
      "epochs =  0 , step =  3000 , loss_val =  0.43834534\n",
      "epochs =  0 , step =  4000 , loss_val =  0.43500233\n",
      "epochs =  0 , step =  5000 , loss_val =  0.43253902\n",
      "epochs =  0 , step =  6000 , loss_val =  0.43058613\n",
      "epochs =  0 , step =  7000 , loss_val =  0.4289819\n",
      "epochs =  0 , step =  8000 , loss_val =  0.4276364\n",
      "epochs =  0 , step =  9000 , loss_val =  0.42649135\n",
      "epochs =  0 , step =  10000 , loss_val =  0.4255049\n",
      "\n",
      "Elapsed Time =>  0:00:09.434013\n",
      "\n",
      "y_val.shape (418, 1) , predicted_val = (418, 1)\n",
      "\n",
      "Accuracy = 0.9521531\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for step in range(10001):\n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X_DATA: training_x_data, T_DATA: training_t_data})    \n",
    "        \n",
    "            if step % 1000 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    y_val, predicted_val, accuracy_val = sess.run([y, predicted, accuracy], feed_dict={X_DATA: test_x_data, T_DATA: test_t_data})\n",
    "    \n",
    "    print(\"\\ny_val.shape\", y_val.shape, \", predicted_val =\", predicted_val.shape)\n",
    "    print(\"\\nAccuracy =\", accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
