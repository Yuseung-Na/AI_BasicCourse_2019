{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-baadd58151ab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\YUSEUNG\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "train.num = 55000 , test.num = 10000 , validation.num = 5000\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"train.num =\", mnist.train.num_examples,\n",
    "     \", test.num =\", mnist.test.num_examples,\n",
    "     \", validation.num =\", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "T = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])  # image 28 x 28 x 1 (black / white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 1 4x4 32개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 층, 4x4x32 필터 \n",
    "W2 = tf.Variable(tf.random_normal([4, 4, 1, 32], stddev=0.01))  # standard deviation 표준편차 0.01 이내로 뽑음 -> 더 정교한 데이터\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 x 28 x 1 => 28 x 28 x 32  흑백인 1개 층이 -> 32개 층을 거치게 됨\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 x 28 x 32 => 14 x 14 x 32  max pooling을 통해 4개를 1개로 묶어 가로 세로 2배씩 줄어들게 됨\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 2 4x4 64개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 층, 4x4x64 필터 \n",
    "W3 = tf.Variable(tf.random_normal([4, 4, 32, 64], stddev=0.01))  # conv2d 내에서 32번의 반복을 해야한다는 것을 알고있음\n",
    "## 참고로 for문 같은 반복이 아닌 register shift 방법을 통해 이루어짐\n",
    "\n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "\n",
    "# 2번째 컨볼루션 연산을 통해 14 x 14 x 32 => 14 x 14 x 64 \n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z3 = tf.nn.relu(C3+b3)\n",
    "\n",
    "# 2번째 max pooling을 통해 14 x 14 x 64 => 7 x 7 x 64\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션층 3 4x4 128개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3번째 컨볼루션 층, 4x4x128 필터 \n",
    "W4 = tf.Variable(tf.random_normal([4, 4, 64, 128], stddev=0.01))\n",
    "b4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "\n",
    "# 3번째 컨볼루션 연산을 통해 7 x 7 x 64 => 7 x 7 x 128 \n",
    "C4 = tf.nn.conv2d(A3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z4 = tf.nn.relu(C4+b4)\n",
    "\n",
    "# 3번째 max pooling을 통해 7 x 7 x 128 => 4 x 4 x 128\n",
    "A4 = P4 = tf.nn.max_pool(Z4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전연결층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 x 4 크기를 가진 128개의 activation map을 flatten 시킴\n",
    "A4_flat = P4_flat = tf.reshape(A4, [-1, 4*4*128])  # 행이 몇게가 오든 열 개수만 맞춰서 나중에 y는 최종적으로 (?, 10) 의 shape가 됨\n",
    "\n",
    "# ? 가 여러개 있는 것은 모두 평균을 내어 결과적으로 (1, 10) 의 모양이 되고, 이를 답과 비교하게 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "W5 = tf.Variable(tf.random_normal([4*4*128, 10], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 출력층 선형회귀 값 Z5, 즉 softmax 에 들어가는 입력 값\n",
    "Z5 = logits = tf.matmul(A4_flat, W5) + b5\n",
    "\n",
    "y = A5 = tf.nn.softmax(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z5, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A5, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(A5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  3.3666968\n",
      "epochs =  0 , step =  100 , loss_val =  1.8773061\n",
      "epochs =  0 , step =  200 , loss_val =  0.37230396\n",
      "epochs =  0 , step =  300 , loss_val =  0.09276349\n",
      "epochs =  0 , step =  400 , loss_val =  0.15296976\n",
      "epochs =  0 , step =  500 , loss_val =  0.124660656\n",
      "epochs =  1 , step =  0 , loss_val =  0.13695054\n",
      "epochs =  1 , step =  100 , loss_val =  0.105998375\n",
      "epochs =  1 , step =  200 , loss_val =  0.066910125\n",
      "epochs =  1 , step =  300 , loss_val =  0.045300726\n",
      "epochs =  1 , step =  400 , loss_val =  0.07957088\n",
      "epochs =  1 , step =  500 , loss_val =  0.013019707\n",
      "epochs =  2 , step =  0 , loss_val =  0.0148175815\n",
      "epochs =  2 , step =  100 , loss_val =  0.028643819\n",
      "epochs =  2 , step =  200 , loss_val =  0.0860154\n",
      "epochs =  2 , step =  300 , loss_val =  0.014010711\n",
      "epochs =  2 , step =  400 , loss_val =  0.030850157\n",
      "epochs =  2 , step =  500 , loss_val =  0.016237559\n",
      "epochs =  3 , step =  0 , loss_val =  0.022348799\n",
      "epochs =  3 , step =  100 , loss_val =  0.011000076\n",
      "epochs =  3 , step =  200 , loss_val =  0.007600044\n",
      "epochs =  3 , step =  300 , loss_val =  0.019733967\n",
      "epochs =  3 , step =  400 , loss_val =  0.015505164\n",
      "epochs =  3 , step =  500 , loss_val =  0.0065555666\n",
      "epochs =  4 , step =  0 , loss_val =  0.01375615\n",
      "epochs =  4 , step =  100 , loss_val =  0.102833785\n",
      "epochs =  4 , step =  200 , loss_val =  0.0012238822\n",
      "epochs =  4 , step =  300 , loss_val =  0.0107514225\n",
      "epochs =  4 , step =  400 , loss_val =  0.0050792904\n",
      "epochs =  4 , step =  500 , loss_val =  0.026984816\n",
      "epochs =  5 , step =  0 , loss_val =  0.003049166\n",
      "epochs =  5 , step =  100 , loss_val =  0.011670773\n",
      "epochs =  5 , step =  200 , loss_val =  0.044468664\n",
      "epochs =  5 , step =  300 , loss_val =  0.0057257875\n",
      "epochs =  5 , step =  400 , loss_val =  0.0038574934\n",
      "epochs =  5 , step =  500 , loss_val =  0.034852628\n",
      "epochs =  6 , step =  0 , loss_val =  0.009573414\n",
      "epochs =  6 , step =  100 , loss_val =  0.0040162234\n",
      "epochs =  6 , step =  200 , loss_val =  0.03055267\n",
      "epochs =  6 , step =  300 , loss_val =  0.012817592\n",
      "epochs =  6 , step =  400 , loss_val =  0.021428626\n",
      "epochs =  6 , step =  500 , loss_val =  0.045638293\n",
      "epochs =  7 , step =  0 , loss_val =  0.017894289\n",
      "epochs =  7 , step =  100 , loss_val =  0.06416442\n",
      "epochs =  7 , step =  200 , loss_val =  0.0014139771\n",
      "epochs =  7 , step =  300 , loss_val =  0.0002985286\n",
      "epochs =  7 , step =  400 , loss_val =  0.00086725474\n",
      "epochs =  7 , step =  500 , loss_val =  0.03851854\n",
      "epochs =  8 , step =  0 , loss_val =  0.010741731\n",
      "epochs =  8 , step =  100 , loss_val =  0.0007222935\n",
      "epochs =  8 , step =  200 , loss_val =  0.006800201\n",
      "epochs =  8 , step =  300 , loss_val =  0.00053732796\n",
      "epochs =  8 , step =  400 , loss_val =  0.009830922\n",
      "epochs =  8 , step =  500 , loss_val =  0.1620728\n",
      "epochs =  9 , step =  0 , loss_val =  0.007761642\n",
      "epochs =  9 , step =  100 , loss_val =  0.0054580807\n",
      "epochs =  9 , step =  200 , loss_val =  0.00089117733\n",
      "epochs =  9 , step =  300 , loss_val =  0.0017425758\n",
      "epochs =  9 , step =  400 , loss_val =  0.006890045\n",
      "epochs =  9 , step =  500 , loss_val =  0.009621597\n",
      "epochs =  10 , step =  0 , loss_val =  0.00031031176\n",
      "epochs =  10 , step =  100 , loss_val =  0.002393242\n",
      "epochs =  10 , step =  200 , loss_val =  0.005772014\n",
      "epochs =  10 , step =  300 , loss_val =  0.010264492\n",
      "epochs =  10 , step =  400 , loss_val =  0.0034333894\n",
      "epochs =  10 , step =  500 , loss_val =  0.00032314085\n",
      "epochs =  11 , step =  0 , loss_val =  0.0036229952\n",
      "epochs =  11 , step =  100 , loss_val =  0.00034942533\n",
      "epochs =  11 , step =  200 , loss_val =  0.0073887464\n",
      "epochs =  11 , step =  300 , loss_val =  0.00031410516\n",
      "epochs =  11 , step =  400 , loss_val =  0.01550189\n",
      "epochs =  11 , step =  500 , loss_val =  0.0052171694\n",
      "epochs =  12 , step =  0 , loss_val =  2.744348e-05\n",
      "epochs =  12 , step =  100 , loss_val =  9.909732e-05\n",
      "epochs =  12 , step =  200 , loss_val =  0.0014902449\n",
      "epochs =  12 , step =  300 , loss_val =  0.001409066\n",
      "epochs =  12 , step =  400 , loss_val =  0.06059815\n",
      "epochs =  12 , step =  500 , loss_val =  0.0001414516\n",
      "epochs =  13 , step =  0 , loss_val =  0.0026699132\n",
      "epochs =  13 , step =  100 , loss_val =  0.00045504657\n",
      "epochs =  13 , step =  200 , loss_val =  0.0017491232\n",
      "epochs =  13 , step =  300 , loss_val =  0.0021530436\n",
      "epochs =  13 , step =  400 , loss_val =  0.0034688155\n",
      "epochs =  13 , step =  500 , loss_val =  0.013588803\n",
      "epochs =  14 , step =  0 , loss_val =  7.3784395e-05\n",
      "epochs =  14 , step =  100 , loss_val =  0.017614134\n",
      "epochs =  14 , step =  200 , loss_val =  1.0797489e-05\n",
      "epochs =  14 , step =  300 , loss_val =  0.00018941912\n",
      "epochs =  14 , step =  400 , loss_val =  0.0043462655\n",
      "epochs =  14 , step =  500 , loss_val =  0.00048581633\n",
      "epochs =  15 , step =  0 , loss_val =  0.023219032\n",
      "epochs =  15 , step =  100 , loss_val =  0.0005823481\n",
      "epochs =  15 , step =  200 , loss_val =  0.0021667485\n",
      "epochs =  15 , step =  300 , loss_val =  0.0017742566\n",
      "epochs =  15 , step =  400 , loss_val =  0.00290914\n",
      "epochs =  15 , step =  500 , loss_val =  0.028382845\n",
      "epochs =  16 , step =  0 , loss_val =  0.001247528\n",
      "epochs =  16 , step =  100 , loss_val =  0.002061517\n",
      "epochs =  16 , step =  200 , loss_val =  3.339415e-05\n",
      "epochs =  16 , step =  300 , loss_val =  0.00064955594\n",
      "epochs =  16 , step =  400 , loss_val =  0.00839128\n",
      "epochs =  16 , step =  500 , loss_val =  0.0005626138\n",
      "epochs =  17 , step =  0 , loss_val =  0.00033263207\n",
      "epochs =  17 , step =  100 , loss_val =  7.311359e-05\n",
      "epochs =  17 , step =  200 , loss_val =  0.00013374655\n",
      "epochs =  17 , step =  300 , loss_val =  0.0026001034\n",
      "epochs =  17 , step =  400 , loss_val =  0.001046054\n",
      "epochs =  17 , step =  500 , loss_val =  0.00018445628\n",
      "epochs =  18 , step =  0 , loss_val =  0.0004793465\n",
      "epochs =  18 , step =  100 , loss_val =  0.024746394\n",
      "epochs =  18 , step =  200 , loss_val =  1.7739289e-05\n",
      "epochs =  18 , step =  300 , loss_val =  0.0001311087\n",
      "epochs =  18 , step =  400 , loss_val =  6.694472e-05\n",
      "epochs =  18 , step =  500 , loss_val =  0.0006695956\n",
      "epochs =  19 , step =  0 , loss_val =  4.583115e-06\n",
      "epochs =  19 , step =  100 , loss_val =  0.0015302163\n",
      "epochs =  19 , step =  200 , loss_val =  5.3160475e-05\n",
      "epochs =  19 , step =  300 , loss_val =  3.897003e-05\n",
      "epochs =  19 , step =  400 , loss_val =  0.0010417155\n",
      "epochs =  19 , step =  500 , loss_val =  0.00011278956\n",
      "epochs =  20 , step =  0 , loss_val =  6.537651e-05\n",
      "epochs =  20 , step =  100 , loss_val =  0.00013665034\n",
      "epochs =  20 , step =  200 , loss_val =  4.8660735e-05\n",
      "epochs =  20 , step =  300 , loss_val =  0.00055053626\n",
      "epochs =  20 , step =  400 , loss_val =  0.0005214431\n",
      "epochs =  20 , step =  500 , loss_val =  0.07233355\n",
      "epochs =  21 , step =  0 , loss_val =  0.0066441256\n",
      "epochs =  21 , step =  100 , loss_val =  0.00022784769\n",
      "epochs =  21 , step =  200 , loss_val =  0.00059835287\n",
      "epochs =  21 , step =  300 , loss_val =  0.00028242788\n",
      "epochs =  21 , step =  400 , loss_val =  6.961673e-05\n",
      "epochs =  21 , step =  500 , loss_val =  0.00024220486\n",
      "epochs =  22 , step =  0 , loss_val =  1.0586988e-05\n",
      "epochs =  22 , step =  100 , loss_val =  6.7116234e-05\n",
      "epochs =  22 , step =  200 , loss_val =  4.340867e-06\n",
      "epochs =  22 , step =  300 , loss_val =  3.8871247e-05\n",
      "epochs =  22 , step =  400 , loss_val =  4.9983788e-05\n",
      "epochs =  22 , step =  500 , loss_val =  0.00016610384\n",
      "epochs =  23 , step =  0 , loss_val =  0.012191528\n",
      "epochs =  23 , step =  100 , loss_val =  0.0008315537\n",
      "epochs =  23 , step =  200 , loss_val =  0.0057644593\n",
      "epochs =  23 , step =  300 , loss_val =  0.00024496202\n",
      "epochs =  23 , step =  400 , loss_val =  0.024419904\n",
      "epochs =  23 , step =  500 , loss_val =  0.0017070441\n",
      "epochs =  24 , step =  0 , loss_val =  1.14170725e-05\n",
      "epochs =  24 , step =  100 , loss_val =  3.5919118e-05\n",
      "epochs =  24 , step =  200 , loss_val =  0.00021845476\n",
      "epochs =  24 , step =  300 , loss_val =  0.0026559222\n",
      "epochs =  24 , step =  400 , loss_val =  1.6402779e-06\n",
      "epochs =  24 , step =  500 , loss_val =  6.3446532e-06\n",
      "epochs =  25 , step =  0 , loss_val =  0.0012529702\n",
      "epochs =  25 , step =  100 , loss_val =  1.5010417e-05\n",
      "epochs =  25 , step =  200 , loss_val =  0.00081164605\n",
      "epochs =  25 , step =  300 , loss_val =  0.004404194\n",
      "epochs =  25 , step =  400 , loss_val =  3.3758574e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  25 , step =  500 , loss_val =  0.000277489\n",
      "epochs =  26 , step =  0 , loss_val =  0.0042994623\n",
      "epochs =  26 , step =  100 , loss_val =  0.00014209801\n",
      "epochs =  26 , step =  200 , loss_val =  6.0787246e-05\n",
      "epochs =  26 , step =  300 , loss_val =  0.0017548065\n",
      "epochs =  26 , step =  400 , loss_val =  0.00079065247\n",
      "epochs =  26 , step =  500 , loss_val =  0.0014794387\n",
      "epochs =  27 , step =  0 , loss_val =  4.5663663e-05\n",
      "epochs =  27 , step =  100 , loss_val =  3.9889757e-05\n",
      "epochs =  27 , step =  200 , loss_val =  0.00024393108\n",
      "epochs =  27 , step =  300 , loss_val =  0.001496548\n",
      "epochs =  27 , step =  400 , loss_val =  9.9747385e-06\n",
      "epochs =  27 , step =  500 , loss_val =  0.0005395561\n",
      "epochs =  28 , step =  0 , loss_val =  0.00019002505\n",
      "epochs =  28 , step =  100 , loss_val =  5.3430595e-06\n",
      "epochs =  28 , step =  200 , loss_val =  0.00020264354\n",
      "epochs =  28 , step =  300 , loss_val =  0.026204646\n",
      "epochs =  28 , step =  400 , loss_val =  0.00029694766\n",
      "epochs =  28 , step =  500 , loss_val =  3.347084e-05\n",
      "epochs =  29 , step =  0 , loss_val =  4.344771e-06\n",
      "epochs =  29 , step =  100 , loss_val =  1.7877052e-05\n",
      "epochs =  29 , step =  200 , loss_val =  0.00038370385\n",
      "epochs =  29 , step =  300 , loss_val =  0.000108429274\n",
      "epochs =  29 , step =  400 , loss_val =  6.6353864e-06\n",
      "epochs =  29 , step =  500 , loss_val =  0.0013957858\n",
      "\n",
      "Elapsed Time =>  0:02:01.715838\n",
      "\n",
      "Accuracy = 0.9927\n",
      "length of index_label_list =  10000\n",
      "false label count =  73\n",
      "\n",
      "length of index_label_false_list_1 73\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "\n",
    "with tf.Session() as sess:  # with를 쓰면 close 하지 않아도 됨\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드 (tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):  # 30번 반복 수행\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})   \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time => \", end_time-start_time)\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images  # 10000 x 784\n",
    "    test_t_data = mnist.test.labels  # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy =\", accuracy_val)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # list type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_false_list_1.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_1\", len(index_label_false_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115, 4, 9], [247, 4, 2], [412, 5, 3], [445, 6, 0], [582, 8, 2], [646, 2, 6], [659, 2, 1], [674, 5, 3], [716, 1, 7], [947, 8, 9], [1014, 6, 0], [1039, 7, 1], [1182, 6, 5], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1260, 7, 1], [1393, 5, 3], [1429, 9, 4], [1459, 2, 3], [1500, 7, 3], [1709, 9, 5], [1878, 8, 3], [1901, 9, 4], [2118, 6, 0], [2129, 9, 8], [2130, 4, 9], [2414, 9, 4], [2447, 4, 9], [2582, 9, 7], [2597, 5, 3], [2654, 6, 1], [2678, 4, 9], [2921, 3, 8], [2939, 9, 5], [3073, 1, 2], [3225, 7, 9], [3422, 6, 0], [3520, 6, 4], [3558, 5, 0], [3767, 7, 2], [3808, 7, 8], [3853, 6, 0], [3869, 9, 4], [3926, 9, 3], [4176, 2, 7], [4199, 7, 9], [4359, 5, 9], [4369, 9, 4], [4740, 3, 5], [4761, 9, 8], [5331, 1, 6], [5457, 1, 4], [5654, 7, 2], [5802, 5, 9], [5937, 5, 3], [5955, 3, 8], [6576, 7, 1], [6597, 0, 7], [6625, 8, 2], [6783, 1, 6], [7732, 5, 8], [7928, 1, 0], [8094, 2, 8], [8376, 1, 4], [8408, 8, 5], [8527, 4, 9], [9015, 7, 2], [9664, 2, 3], [9700, 2, 8], [9729, 5, 6], [9850, 0, 8], [9904, 2, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUSEUNG\\OneDrive - konkuk.ac.kr\\DESKTOP\\AI 기본과정\\실습\\16일차_1124\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "Elapsed save time =>  0:00:16.261903\n",
      "Total  62  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image 저장할 디렉토리 생성. 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'false_data_실습5'\n",
    "save_dir_name = algorithm_name + '_' + str(now.year) + str(now.month) + str(now.day) + '_' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.chdir(curr_dir)\n",
    "os.mkdir(save_dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(save_dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_false_list_1:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
